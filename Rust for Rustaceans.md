# Rust for Rustaceans

## Rust

### 致谢

- 由于以前从未写过书，我对这个过程的期望很少。我天真地以为它会像写一系列博客文章，或者像写广泛的文档一样，但写一本书是完全不同的事情。我花费了无数个小时进行研究、规划、写作、重写、丢弃、反思和编辑。我非常感激我的女朋友Talia在我为这个项目工作的许多个深夜中所表现出的支持和耐心——没有你，写作体验会变得更加黯淡。这本书绝不可能没有令人难以置信的Rust开发者和社区的支持，他们开发了一门语言和生态系统，我继续发现与之互动是一种乐趣，并受到启发，以我最好的能力来传播和教授。同样感谢多年来观看我的直播的了不起的人们；如果没有你们持续的支持、鼓励和无尽的好奇心，我想我永远不会有机会首先写这本书。

- 如果没有David Tolnay作为本书的技术审查者，这本书也不会有一半的好处。David在找出理论和代码错误方面显然是无价的，但他的丰富经验、注重细节和爱好教学真正留下了深刻的印象。他的深思熟虑和富有洞察力的评论有时让我决定重写整个章节，但总是以比之前更好得多的方式进行。
- 同样感谢我的编辑Liz Chadwick和No Starch出版团队的其他成员。看到Liz在书的编写过程中的成长过程非常有趣；她在阅读过程中学习了Rust，并且当她的评论表明她真正理解了中级内容时，我感到非常高兴。每当她遇到不理解的地方时的讨论总是启发人，导致了更易理解和全面的解释。
- 我也不能不提到Steve Klabnik和Carol Nichols，他们是《Rust编程语言》的作者，这是我对Rust的第一次介绍。在我看来，这本书在很大程度上是他们书的续集，如果没有他们对Rust基础知识的出色解释和易于理解的工作，这本书是无法存在的。
最后，我要向你们致敬。是的，就是你们！写这本书是一个非常漫长的过程，而正是那些希望阅读它的人们的支持和鼓励使我一直坚持下去。正是像你们这样的人，无论是虚拟还是实体地阅读这本书，都希望提高自己的理解和技能，驱使我尽我所能为Rust教学资源的积累做出贡献。
谢谢大家！

### 介绍

- **无论使用哪种编程语言，入门教材所教授的知识与多年实践经验后所掌握的知识之间的差距总是很大。随着时间的推移，你会熟悉惯用法，对核心概念有更好的心智模型，了解哪些设计和模式有效，哪些无效，并发现周围生态系统中有用的库和工具。综合起来，这种经验使你能够在更短的时间内编写更好的代码**

- 通过这本书，我希望将我多年编写Rust代码的经验浓缩成一本易于理解的资源。《Rust for Rustaceans》是《Rust编程语言》（即Rust书）的延续，但适用于任何想要超越基础知识的Rust程序员，无论你是在哪里学习这门语言。本书深入探讨了诸如不安全代码、特质系统、no_std代码和宏等概念。它还涵盖了新领域，如异步I/O、测试、嵌入式开发和人性化的API设计。我旨在解释和揭示Rust的这些更高级和强大的特性，并使您能够构建更快、更人性化和更健壮的应用程序。

### What’s in the Book

- 本书既是指南，也是参考资料。各章节相对独立，因此您可以直接跳转到特别感兴趣的主题（或者当前困扰您的主题），或者从头到尾阅读本书以获得更全面的体验。尽管如此，我建议您从阅读第1章和第2章开始，因为它们为后续章节和日常Rust开发中的许多主题奠定了基础。以下是每个章节的简要介绍：
  - 第1章《基础知识》深入描述了Rust的基本概念，如变量、内存、所有权、借用和生命周期，您需要熟悉这些概念才能理解本书的其余部分。
  - 第2章《类型》类似地提供了关于Rust中类型和特质的更详尽解释，包括编译器如何推理它们、它们的特性和限制，以及一些高级应用。
  - 第3章《设计接口》介绍了如何设计直观、灵活和防止误用的API，包括如何命名事物、如何使用类型系统来强制执行API合约，以及何时使用泛型和特质对象。
  - 第4章《错误处理》探讨了两种主要类型的错误（枚举和不透明错误），以及何时使用每种类型的适当情况，以及如何定义、构造、传播和处理这些错误。
  - 第5章《项目结构》关注Rust项目的非代码部分，例如Cargo元数据和配置、crate特性和版本控制。
  - 第6章《测试》详细介绍了标准的Rust测试框架的工作原理，并介绍了一些超出标准单元测试和集成测试的测试工具和技术，例如模糊测试和性能测试。
  - 第7章《宏》涵盖了声明式和过程式宏，包括它们的编写方式、它们的用途以及一些注意事项。
  - 第8章《异步编程》介绍了同步和异步接口之间的区别，然后深入探讨了在Rust中如何表示异步性，包括Future和Pin的底层表示以及async和await的高级表示。该章还解释了异步执行器的作用以及它如何使整个异步机制协同工作。
  - 第9章《不安全代码》解释了unsafe关键字所解锁的强大功能以及随之而来的巨大责任。您将了解到在不安全代码中常见的陷阱，以及可以用来减少不正确不安全代码风险的工具和技术。
  - 第10章《并发（和并行）》介绍了Rust中如何表示并发以及为什么在正确性和性能方面很难做到正确。它涵盖了并发和异步性的关系（但并不相同），以及在接近硬件时并发如何工作，以及在尝试编写正确并发程序时如何保持理智。
  - 第11章《外部函数接口》教你如何使Rust与其他语言良好地协作，以及extern关键字等FFI原语的实际作用。
  - 第12章《无标准库的Rust》介绍了在无法使用完整标准库的情况下使用Rust的情况，例如在嵌入式设备或其他受限平台上，您只能使用核心和alloc模块提供的功能。
  - 第13章《Rust生态系统》不涵盖特定的Rust主题，而是旨在提供关于在Rust生态系统中工作的更广泛指导。它包含常见设计模式的描述，关于保持对语言添加和最佳实践的最新信息的建议，有用工具的提示以及我多年来积累的其他有用的琐事，这些信息在任何单一地方都没有描述。
该书有一个网站，网址为<https://rust-for-rustaceans.com，其中包含书中的资源链接、Future的勘误等。您还可以在No> Starch Press网站上的该书页面<https://nostarch.com/rust-rustaceans/找到这些信息。>
现在，所有这些都已经解释清楚了，只剩下一件事要做：

    ```rust
    fn main() {}
    ```

### 1 基础知识

- **当你深入研究Rust的更高级领域时，确保你对基础知识有扎实的理解非常重要。在Rust中，就像在任何编程语言中一样，各种关键字和概念的确切含义在你开始以更复杂的方式使用语言时变得重要**。在本章中，我们将详细介绍Rust的许多基本概念，试图更清楚地定义它们的含义、工作原理以及它们为什么恰好是这样。具体而言，我们将了解变量和值的区别，它们如何在内存中表示，以及程序所具有的不同内存区域。然后，我们将讨论一些关于所有权、借用和生命周期的细微差别，这些是您在继续阅读本书之前需要掌握的。
- 如果你愿意，你可以从头到尾阅读本章，或者你可以将其作为参考，复习你对其中一些概念不太确定的内容。我建议你只有在对本章内容感到完全舒适时再继续前进，因为对这些基本概念的误解会很快妨碍你理解更高级的主题，或者导致你错误地使用它们。

#### Talking About Memory

并非所有的内存都是相同的。在大多数编程环境中，你的程序可以访问堆栈、堆、寄存器、文本段、内存映射寄存器、内存映射文件，以及可能的非易失性RAM。你在特定情况下选择使用哪种内存区域会对你可以在其中存储什么、它能保持多长时间可访问以及你使用什么机制来访问它产生影响。这些内存区域的具体细节因平台而异，超出了本书的范围，但其中一些对于你如何推理Rust代码非常重要，因此值得关注。
covering here.

##### Memory Terminology

在我们深入研究内存区域之前，您首先需要了解值、变量和指针之间的区别。在Rust中，值是类型和该类型值域中的元素的组合。可以使用值的类型表示将值转换为字节序列，但单独来看，您可以将值视为您作为程序员所指的内容。例如，类型为u8的数字6是数学整数6的一个实例，其内存表示为字节0x06。类似地，字符串"Hello world"是所有字符串域中的一个值，其表示为其UTF-8编码。值的含义与存储这些字节的位置无关。
值存储在一个位置中，这是Rust术语中“可以容纳值的位置”。这个位置可以在堆栈、堆或其他位置上。存储值的最常见位置是变量，它是堆栈上的一个命名值槽。
指针是一个保存内存区域地址的值，因此指针指向一个位置。可以解引用指针以访问存储在其指向的内存位置中的值。我们可以将相同的指针存储在多个变量中，因此可以有多个间接引用相同内存位置和相同基础值的变量。
请考虑代码清单1-1中的代码，它说明了这三个元素。

```rust
let x = 42;
let y = 43;
let var1 = &x;
let mut var2 = &x;
1 var2 = &y;
```

Listing 1-1: Values, variables, and pointers

在这里，有四个不同的值：42（一个i32），43（一个i32），x的地址（一个指针）和y的地址（一个指针）。还有四个变量：x，y，var1和var2。后两个变量都保存指针类型的值，因为引用就是指针。虽然var1和var2最初存储相同的值，但它们存储了独立的副本；当我们改变var2中存储的值时，var1中的值不会改变。特别是，=运算符将右侧表达式的值存储在左侧命名的位置中。
在变量、值和指针之间的区别变得重要的一个有趣例子是这样一个语句：

```rust
let string = "Hello world";
```

即使我们将字符串值赋给变量string，实际上变量的值是指向字符串值"Hello world"中第一个字符的指针，而不是字符串值本身。此时你可能会说：“但是等等，那么字符串值存储在哪里？指针指向哪里？”如果是这样，你的观察力很敏锐，我们马上就会讨论这个问题。

**注意** 从技术上讲，变量string的值还包括字符串的长度。我们将在第2章讨论宽指针类型时详细介绍这一点。

##### 变量的深入理解

在高级模型中，我们不将变量视为保存字节的位置。相反，我们将它们仅视为在程序中实例化、移动和使用时赋予值的名称。当将一个值赋给一个变量时，该值从那时起就由该变量命名。当稍后访问一个变量时，你可以想象从该变量的先前访问到新访问之间画一条线，从而建立两个访问之间的依赖关系。如果变量中的值被移动，就不能再从它画线了。

- 在这个模型中，变量只存在于它持有合法值的时间内；你不能从一个值未初始化或已被移动的变量画线，所以它实际上不存在。使用这个模型，你的整个程序由许多这些依赖线组成，通常被称为流，每个流追踪一个特定值的生命周期。当存在分支时，流可以分叉和合并，每个分叉追踪该值的不同生命周期。编译器可以检查在程序的任何给定点，所有可以并行存在的流都是兼容的。例如，不能有两个并行流同时对一个值进行可变访问。也不能在没有拥有该值的流的情况下借用一个值。清单1-2展示了这两种情况的示例。

##### 高级模型

在高级模型中，我们不将变量视为保存字节的位置。相反，我们将它们仅视为在程序中实例化、移动和使用时赋予值的名称。当将一个值赋给一个变量时，该值从那时起就由该变量命名。当稍后访问一个变量时，你可以想象从该变量的先前访问到新访问之间画一条线，从而建立两个访问之间的依赖关系。如果变量中的值被移动，就不能再从它画线了。

- 在这个模型中，变量只存在于它持有合法值的时间内；你不能从一个值未初始化或已被移动的变量画线，所以它实际上不存在。使用这个模型，你的整个程序由许多这些依赖线组成，通常被称为流，每个流追踪一个特定值的生命周期。当存在分支时，流可以分叉和合并，每个分叉追踪该值的不同生命周期。编译器可以检查在程序的任何给定点，所有可以并行存在的流都是兼容的。例如，不能有两个并行流同时对一个值进行可变访问。也不能在没有拥有该值的流的情况下借用一个值。清单1-2展示了这两种情况的示例。

```rust
let mut x;
// this access would be illegal, nowhere to draw the flow from:
// assert_eq!(x, 42);
1 x = 42;
// this is okay, can draw a flow from the value assigned above:
2 let y = &x;
// this establishes a second, mutable flow from x:
3 x = 43;
// this continues the flow from y, which in turn draws from x.
// but that flow conflicts

```

清单1-2：借用检查器将捕获的非法流

- 首先，我们不能在初始化之前使用x，因为我们没有地方可以从中绘制流。只有当我们给x赋值时，我们才能从中绘制流。这段代码有两个流：一个是从1到3的独占(&mut)流，另一个是从1经过2到4的共享(&)流。借用检查器检查每个流的每个顶点，并检查是否存在其他不兼容的流同时存在。在这种情况下，当借用检查器检查3处的独占流时，它看到终止于4的共享流。由于不能同时对一个值进行独占和共享使用，借用检查器（正确地）拒绝了这段代码。请注意，如果4不存在，这段代码将编译成功！共享流将在2处终止，当检查3处的独占流时，不会存在冲突的流。
- 如果使用与先前变量相同的名称声明一个新变量，它们仍然被视为不同的变量。这被称为遮蔽，后面的变量通过相同的名称“遮蔽”了前面的变量。这两个变量共存，尽管后续的代码不再有办法命名前面的变量。这个模型大致符合编译器的工作方式，特别是借用检查器，实际上在编译器内部用于生成高效的代码。

##### 低级模型

变量是可能或可能不持有合法值的内存位置。您可以将变量视为“值槽”。当您对其赋值时，槽被填充，其旧值（如果有）被丢弃并替换。当您访问它时，编译器会检查槽是否为空，因为这意味着变量未初始化或其值已被移动。指向变量的指针指向变量的后备内存，并可以通过解引用来访问其值。例如，在语句let x: usize中，变量x是堆栈上的一个内存区域的名称，该区域可以容纳一个usize大小的值，尽管它没有定义明确的值（其槽为空）。如果您将一个值赋给该变量，例如x = 6，那么该内存区域将保存表示值6的位。当您对x进行赋值时，&x不会改变。如果您使用相同的名称声明多个变量，它们最终将具有不同的内存块支持。这个模型与C和C++以及许多其他低级语言使用的内存模型相匹配，并且在需要明确处理内存时非常有用。

##### 栈

栈是程序用作函数调用的临时空间的一段内存。每次调用函数时，栈的顶部都会分配一个连续的内存块，称为帧。在栈的底部附近是主函数的帧，当函数调用其他函数时，额外的帧会被推入栈中。一个函数的帧包含该函数内的所有变量，以及函数接受的任何参数。当函数返回时，它的栈帧会被回收。

- 构成函数局部变量值的字节不会立即被清除，但是不安全访问它们是不安全的，因为它们可能已经被后续的函数调用覆盖，这些函数的帧与被回收的帧重叠。即使它们没有被覆盖，它们可能包含不合法使用的值，例如在函数返回时移动的值。
- 栈帧以及它们最终消失的事实与Rust中的生命周期概念密切相关。存储在栈帧上的任何变量在该帧消失后无法访问，因此对它的任何引用的生命周期最长不能超过帧的生命周期。

##### 堆

堆是一个与程序当前调用栈无关的内存池。堆内存中的值会一直存在，直到显式释放。当您希望一个值的生命周期超过当前函数帧的生命周期时，这非常有用。如果该值是函数的返回值，调用函数可以在其堆栈上留出一些空间，以便被调用函数在返回之前将该值写入其中。但是，如果您想将该值发送到与当前线程可能完全不共享堆栈帧的其他线程，您可以将其存储在堆上。

- 堆允许您显式分配连续的内存段。当您这样做时，您会得到指向该内存段开头的指针。该内存段为您保留，直到您稍后将其释放；这个过程通常被称为释放，以C标准库中相应函数的名称命名。由于从堆分配的内存在函数返回时不会消失，因此您可以在一个地方为一个值分配内存，将指针传递给另一个线程，并且该线程可以安全地继续操作该值。或者，换句话说，当您在堆上分配内存时，得到的指针具有无约束的生命周期 - 只要您的程序保持其存活，它就可以使用。
- 在Rust中与堆交互的主要机制是Box类型。当您编写Box::new(value)时，该值被放置在堆上，而您得到的`（Box<T>）`是指向堆上该值的指针。当Box最终被丢弃时，该内存将被释放。
- 如果您忘记释放堆内存，它将永远存在，并且您的应用程序最终会占用机器上的所有内存。这被称为内存泄漏，通常是您要避免的情况。但是，有些情况下您明确希望泄漏内存。例如，假设您有一个只读配置，整个程序都应该能够访问。您可以在堆上分配它，并使用Box::leak显式泄漏它，以获得对它的'static引用。

##### 静态内存

静态内存实际上是一个统称，用于描述程序编译后所在文件中的几个相关区域。当程序执行时，这些区域会自动加载到程序的内存中。静态内存中的值在整个程序执行期间都存在。程序的静态内存包含程序的二进制代码，通常被映射为只读。当程序执行时，它会按照指令逐步遍历文本段中的二进制代码，并在调用函数时跳转。静态内存还保存了使用static关键字声明的变量的内存，以及代码中的某些常量值，比如字符串。

- 特殊的生命周期'static得名于静态内存区域，它将引用标记为“在静态内存存在的时间内有效”，即直到程序关闭。由于静态变量的内存在程序启动时分配，对静态内存中变量的引用在定义上是'static的，因为它在程序关闭之前不会被释放。反之则不成立——可能存在指向静态内存之外的'static引用，但这个名称仍然适用：一旦创建了具有静态生命周期的引用，对于程序的其余部分来说，它指向的内容就好像在静态内存中一样，可以在程序希望的任何时间内使用。

- 在使用Rust时，您会经常遇到'static生命周期，而不是真正的静态内存（例如通过static关键字）。这是因为在处理Rust时，'static经常出现在类型参数的trait约束中。类似于T: 'static这样的约束表示类型参数T能够在我们保留它的时间内存活，直到程序的剩余执行结束。实质上，这个约束要求T是拥有所有权且自给自足的，要么它不借用其他（非静态）值，要么它借用的任何值也是'static的，因此会一直存在直到程序结束。一个很好的'static约束的例子是std::thread::spawn函数，它创建一个新线程，要求传递给它的闭包是'static的。由于新线程可能比当前线程存在更长的时间，新线程不能引用旧线程堆栈上的任何内容。新线程只能引用在其整个生命周期内都存在的值，这可能是程序剩余时间的持续时间。

**注意** 你可能想知道const与static有什么区别。const关键字声明了以下项为常量。常量项可以在编译时完全计算，并且在编译期间，任何引用它们的代码都会被替换为常量的计算值。常量没有与之关联的内存或其他存储（它不是一个位置）。你可以将常量视为特定值的方便名称。

##### 所有权

Rust的内存模型以所有值都有一个单一所有者的概念为中心，也就是说，每个值都有一个负责最终释放它的位置（通常是一个作用域）。这是通过借用检查器来实现的。如果值被移动，例如通过将其赋值给一个新变量、将其推入向量或将其放置在堆上，那么该值的所有权将从旧位置移动到新位置。在那时，您不能再通过从原始所有者流动的变量访问该值，即使构成该值的位实际上仍然存在。相反，您必须通过引用其新位置的变量来访问移动的值。

- 有些类型是特例，不遵循这个规则。如果一个值的类型实现了特殊的Copy trait，即使它被重新分配到一个新的内存位置，该值也不被认为已经移动。相反，该值被复制，旧的和新的位置仍然可访问。实质上，在移动的目标位置构造了另一个相同的值的实例。Rust中的大多数原始类型，如整数和浮点类型，都是Copy的。要成为Copy，必须能够通过复制其位来复制类型的值。这排除了所有包含非Copy类型的类型，以及在值被丢弃时必须释放资源的任何类型。
- 为了看清楚，考虑一下如果Box这样的类型是Copy会发生什么。如果我们执行box2 = box1，那么box1和box2都会认为它们拥有为box分配的堆内存，并且它们都会在作用域结束时尝试释放它。释放内存两次可能会产生灾难性的后果。
当一个值的所有者不再使用它时，所有者有责任通过丢弃它来进行任何必要的清理。在Rust中，当保存值的变量不再在作用域内时，丢弃会自动发生。类型通常会递归地丢弃它们包含的值，因此丢弃一个复杂类型的变量可能导致许多值被丢弃。
- 由于Rust的离散所有权要求，我们不能意外地多次丢弃相同的值。持有对另一个值的引用的变量不拥有该值，因此当变量丢弃时，该值不会被丢弃。
清单1-3中的代码简要总结了所有权、移动和复制语义以及丢弃的规则。

```rust
let x1 = 42;
let y1 = Box::new(84);
{ // starts a new scope
1 let z = (x1, y1);
// z goes out of scope, and is dropped;
// it in turn drops the values from x1 and y1
2 }
// x1's value is Copy, so it was not moved into z
3 let x2 = x1;
// y1's value is not Copy, so it was moved into z
4 // let y2 = y1;
```

清单1-3：移动和复制语义
我们从两个值开始，一个是数字42，另一个是包含数字84的Box（一个堆分配的值）。前者是`Copy`，而后者不是。当我们将x1和y1放入元组z中时 1，x1被复制到z中，而y1被移动到z中。此时，x1仍然可以访问并可以再次使用 3。另一方面，一旦y1的值被移动 4，它就变得不可访问，任何尝试访问它的操作都会导致编译器错误。当z超出作用域时 2，它包含的元组值被丢弃，这同时也丢弃了从x1复制的值和从y1移动的值。当来自y1的`Box`被丢弃时，它也会释放用于存储y1值的堆内存。

##### 丢弃顺序

Rust会自动在值超出作用域时丢弃它们，比如在Listing 1-3的内部作用域中的x1和y1。丢弃的顺序规则相当简单：变量（包括函数参数）按照反向顺序丢弃，嵌套值按照源代码顺序丢弃。

- 这可能一开始听起来很奇怪——为什么会有这种差异？但如果我们仔细看，这其实很有道理。假设你写了一个函数，声明了一个字符串，然后将该字符串的引用插入到一个新的哈希表中。当函数返回时，必须先丢弃哈希表；如果先丢弃字符串，那么哈希表就会持有一个无效的引用！一般来说，后面的变量可能包含对前面值的引用，而反过来则不可能，这是由于Rust的生命周期规则。因此，Rust按照反向顺序丢弃变量。
- 现在，我们可以对嵌套值有相同的行为，比如元组、数组或结构体中的值，但这可能会让用户感到惊讶。如果你构造了一个包含两个值的数组，如果数组的最后一个元素先被丢弃，那就会显得很奇怪。同样的情况也适用于元组和结构体，最直观的行为是先丢弃第一个元组元素或字段，然后是第二个，依此类推。对于变量来说，没有必要在这种情况下反转丢弃顺序，因为Rust不允许在单个值中自引用。所以，Rust选择了直观的选项。

#### 借用和生命周期

Rust允许值的所有者通过引用将该值借给其他人，而不放弃所有权。引用是带有额外使用约定的指针，例如引用是否提供对引用值的独占访问，或者引用值是否还可以有其他引用指向它。

##### 共享引用

- 共享引用 &T 是一个可以共享的指针。可以存在任意数量的其他引用指向相同的值，并且每个共享引用都是可复制的，因此您可以轻松地创建更多的引用。
- 共享引用指向的值是不可变的；您不能修改或重新分配共享引用指向的值，也不能将共享引用转换为可变引用。
- Rust编译器可以假设共享引用指向的值在引用存在期间不会发生变化。例如，如果Rust编译器看到共享引用后面的值在函数中被多次读取，它有权只读取一次并重用该值。更具体地说，清单1-4中的断言应该永远不会失败。

```rust
fn cache(input: &i32, sum: &mut i32) {
  *sum = *input + *input;
  assert_eq!(*sum, 2 * *input);
}

```

清单1-4：Rust假设共享引用是不可变的。

编译器是否选择应用给定的优化几乎是无关紧要的。编译器的启发式算法会随时间而变化，因此通常希望根据编译器允许的操作来编写代码，而不是根据编译器在特定情况下的实际操作。

##### 可变引用

与共享引用相对应的是可变引用：&mut T。对于可变引用，Rust编译器再次可以充分利用引用所带来的约定：编译器假设没有其他线程通过共享引用或可变引用访问目标值。换句话说，它假设可变引用是独占的。这使得一些在其他语言中不容易实现的优化成为可能。例如，看一下清单1-5中的代码。

```rust
fn noalias(input: &i32, output: &mut i32) {
  if *input == 1 {
1   *output = 2;
  }
2 if *input != 1 {
    *output = 3;
  }
}
```

清单1-5：Rust假设可变引用是独占的。

- 在Rust中，编译器可以假设input和output不指向相同的内存。因此，在1处对output的重新赋值不会影响到2处的检查，整个函数可以编译为一个单独的if-else块。如果编译器不能依赖于独占可变性的约定，那么这个优化将是无效的，因为在类似`noalias(&x, &mut x)`的情况下，输入为1可能导致输出为3。
- 可变引用只允许您修改引用指向的内存位置。您是否可以修改超出直接引用的值取决于位于之间的类型提供的方法。通过一个例子可能更容易理解，所以请参考清单1-6。

```rust
let x = 42;
let mut y = &x; // y is of type &i32
let z = &mut y; // z is of type &mut &i32
```

清单1-6：可变性仅适用于直接引用的内存。

- 在这个例子中，你可以通过将指针y引用到不同的变量来改变指针的值（即不同的指针），但是你不能改变指针所指向的值（即x的值）。同样地，你可以通过z改变y的指针值，但是你不能改变z本身来持有不同的引用。
拥有一个值和拥有对它的可变引用之间的主要区别在于，当不再需要该值时，所有者负责丢弃该值。除此之外，通过可变引用，你可以做任何你拥有该值时可以做的事情，但有一个例外：如果你移动了可变引用后面的值，那么你必须留下另一个值来代替它。如果没有这样做，所有者仍然会认为它需要丢弃该值，但是没有值可供丢弃！

清单1-7展示了通过可变引用移动值的方式的示例。

```rust
fn replace_with_84(s: &mut Box<i32>) {
// this is not okay, as *s would be empty:
1 // let was = *s;
// but this is:
2 let was = std::mem::take(s);
// so is this:
3 *s = was;
// we can exchange values behind &mut:
let mut r = Box::new(84);
4 std::mem::swap(s, &mut r);
  assert_ne!(*r, 84);
}

let mut s = Box::new(42);
replace_with_84(&mut s);
5
```

清单1-7：通过可变引用访问必须留下一个值。

- 我添加了注释的行，表示非法操作。您不能简单地将值移出 1，因为调用者仍然认为它们拥有该值，并且会在5处再次释放它，导致双重释放。如果您只想留下一些有效的值，`std::mem::take 2`是一个很好的选择。它等同于`std::mem::replace(&mut value, Default::default())`；它将值从可变引用后面移出，但在其位置留下一个新的默认值。默认值是一个单独的拥有值，因此在作用域结束时，调用者可以安全地丢弃它。
- 或者，如果您不需要可变引用后面的旧值，可以用您已经拥有的值覆盖它 `3`，将其留给调用者稍后丢弃。当您这样做时，原来在可变引用后面的值将立即被丢弃。
- 最后，如果您有两个可变引用，可以交换它们的值 4，因为两个引用最终都会拥有一个合法的拥有值来释放。

##### 内部可变性

某些类型提供内部可变性，意味着它们允许您通过共享引用来修改值。这些类型通常依赖于附加机制（如原子CPU指令）或不变量来提供安全的可变性，而不依赖于独占引用的语义。这些类型通常分为两类：一类是通过共享引用获取可变引用的类型，另一类是通过共享引用替换值的类型。

- 第一类包括`Mutex`和`RefCell`等类型，它们包含安全机制，以确保对其提供可变引用的任何值一次只能存在一个可变引用（且没有共享引用）。在底层，这些类型（以及类似它们的类型）都依赖于一种称为`UnsafeCell`的类型，其名称应立即使您犹豫使用它。我们将在`第9章中更详细地介绍UnsafeCell`，但现在您应该知道它是通过共享引用进行变异的唯一正确方式。

- 提供内部可变性的其他类型类别是那些不提供对内部值的可变引用，而只提供用于就地操作该值的方法的类型。std::sync::atomic中的原子整数类型和std::cell::Cell类型属于此类别。您无法直接获取usize或i32类型的引用，但可以在给定时间点读取和替换其值。
**注意** 标准库中的Cell类型是通过不变量实现安全内部可变性的有趣示例。它不能在线程之间共享，并且从不提供对Cell中包含的值的引用。相反，所有方法要么完全替换值，要么返回包含的值的副本。由于无法存在对内部值的引用，因此始终可以安全地移动它。并且由于Cell不能在线程之间共享，即使通过共享引用进行变异，内部值也永远不会被同时变异。

##### 生命周期

如果您正在阅读本书，那么您可能已经熟悉生命周期的概念，可能是通过编译器关于生命周期规则违规的重复通知。这种程度的理解将对您编写的大多数Rust代码有所帮助，但是当我们深入研究Rust的更复杂部分时，您将需要一个更严格的心智模型来处理。

新手Rust开发人员通常被教导将生命周期视为与作用域对应的：当您引用某个变量时，生命周期开始，当该变量被移动或超出作用域时，生命周期结束。这通常是正确的，也通常很有用，但实际情况要复杂一些。
生命周期实际上是对某个引用必须有效的代码区域的名称。虽然生命周期通常与作用域重合，但它不一定要这样，我们将在本节后面看到。

**生命周期和借用检查器**
Rust生命周期的核心是借用检查器。每当使用一个带有某个生命周期'a的引用时，借用检查器会检查'a是否仍然有效。它通过追踪从使用点回溯到'a开始的路径（即引用被获取的地方），并检查沿该路径是否存在冲突的使用。这确保引用仍然指向一个可以安全访问的值。这类似于我们在本章前面讨论的高级“数据流”心智模型；编译器检查我们正在访问的引用的流动是否与其他并行流动冲突。
清单1-8展示了一个简单的代码示例，其中包含对引用x的生命周期注解。

```rust
let mut x = Box::new(42);
1 let r = &x; // 'a
if rand() > 0.5 {
2  *x = 84;
} else {
3   println!("{}", r); // 'a
}4
```

清单1-8：生命周期不需要连续。

- 当我们对x进行引用时，生命周期从1开始。在第一个分支2中，我们立即尝试通过将其值更改为84来修改x，这需要一个&mut x。借用检查器获取了对x的可变引用，并立即检查其使用情况。它发现在引用被获取和使用之间没有冲突的使用，因此接受了这段代码。如果您习惯于将生命周期视为作用域，这可能会让您感到惊讶，因为`r`在2处仍然在作用域内（它在4处超出作用域）。但是借用检查器足够聪明，能够意识到如果执行此分支，则r以后永远不会被使用，因此在这里对x进行可变访问是可以的。或者换句话说，从1开始创建的生命周期不延伸到此分支：从r到2没有流动，因此没有冲突的流动。然后，借用检查器在3处找到了对r的使用。它沿着路径返回到1，并没有发现冲突的使用（2不在该路径上），因此也接受了这个使用。
- 如果我们在清单1-8中的4处添加了对r的另一个使用，代码将无法编译。生命周期'a将从1一直持续到4（对r的最后一次使用），当借用检查器检查我们对r的新使用时，它将在2处发现冲突的使用。
- 生命周期可能变得非常复杂。在清单1-9中，您可以看到一个具有间断的生命周期示例，它在开始和最终结束之间是不有效的。

```rust

let mut x = Box::new(42);
1 let mut z = &x; // 'a
for i in 0..100 {
2  println!("{}", z); // 'a
3  x = Box::new(i);
4  z = &x; // 'a
}

println!("{}", z); // 'a
```

清单1-9：生命周期可以有空洞。

- 生命周期从1开始，当我们对x进行引用时。然后在3处移出x，结束了生命周期'a，因为它不再有效。借用检查器通过将'a结束于2处来接受此移动，这样在3处就没有冲突的流动了。然后，我们通过在4处更新z的引用来重新启动生命周期。无论代码现在是否循环回到2处还是继续到最后的打印语句，这两个使用现在都有一个有效的值可以流动，而且没有冲突的流动，因此借用检查器接受了这段代码！
- 再次强调，这与我们之前讨论的内存数据流模型完全一致。当x被移动时，z停止存在。当我们稍后重新分配z时，我们创建了一个完全新的变量，它只存在于那一点之后。恰好这个新变量也被命名为z。在这个模型中，这个例子并不奇怪。
**注意** 借用检查器是保守的，也必须是保守的。如果它不确定一个借用是否有效，它会拒绝它，因为允许一个无效的借用的后果可能是灾难性的。借用检查器不断变得更加智能，但有时它需要帮助来理解为什么一个借用是合法的。这就是为什么我们有不安全的Rust的一部分原因。
**泛型生命周期**
有时您需要在自己的类型中存储引用。这些引用需要有一个生命周期，以便在类型的各种方法中使用时，借用检查器可以检查它们的有效性。特别是，如果您希望类型的某个方法返回一个超出self引用的引用。
- Rust允许您使类型定义在一个或多个生命周期上泛型化，就像允许您使其在类型上泛型化一样。Steve Klabnik和Carol Nichols的《Rust编程语言》（No Starch Press，2018）对这个主题进行了详细介绍，所以我不会在这里重复基础知识。但是，当您编写更复杂的此类类型时，有两个关于此类类型和生命周期之间交互的细微差别需要注意。
- 首先，如果您的类型还实现了Drop，则删除您的类型将计为您的类型泛型生命周期或类型的使用。实际上，当删除您的类型的实例时，借用检查器将在删除之前检查您的类型的任何泛型生命周期是否仍然可以使用。这是必要的，以防您的删除代码确实使用了其中的任何引用。如果您的类型没有实现Drop，则删除该类型不计为使用，用户可以自由地忽略存储在该类型中的任何引用，只要他们不再使用它，就像我们在清单1-7中看到的那样。我们将在第9章中更详细地讨论有关删除的规则。
- 其次，虽然一个类型可以在多个生命周期上泛型化，但这样做通常只会使类型签名变得不必要复杂。通常情况下，一个类型在单个生命周期上泛型化就足够了，编译器将使用较短的生命周期作为插入到类型中的任何引用的生命周期。只有当您有一个包含多个引用的类型，并且其方法返回应与这些引用之一的生命周期相关联的引用时，才真正需要使用多个泛型生命周期参数。
- 考虑清单1-10中的类型，它为您提供了一个按特定其他字符串分隔的字符串的部分的迭代器。

```rust
struct StrSplit<'s, 'p> {
  delimiter: &'p str,
  document: &'s str,
}
impl<'s, 'p> Iterator for StrSplit<'s, 'p> {
  type Item = &'s str;
  fn next(&self) -> Option<Self::Item> {
     todo!()
  }
}
fn str_before(s: &str, c: char) -> Option<&str> {
   StrSplit { document: s, delimiter: &c.to_string() }.next()
}
```

清单1-10：需要在多个生命周期上泛型化的类型

- 当构造此类型时，您必须提供要搜索的分隔符和文档，两者都是对字符串值的引用。当您请求下一个字符串时，您会得到对文档的引用。考虑一下，如果在此类型中使用单个生命周期会发生什么。迭代器产生的值将与文档和分隔符的生命周期相关联。这将使得无法编写str_before函数：返回类型将具有与函数局部变量（通过to_string生成的String）相关联的生命周期，而借用检查器将拒绝该代码。

**生命周期的变异性**
变异性是程序员经常接触但很少知道名称的概念，因为它大多是不可见的。乍一看，变异性描述了哪些类型是其他类型的子类型，以及何时可以将子类型用于超类型（反之亦然）。广义上讲，如果类型A至少与类型B一样有用，则类型A是类型B的子类型。变异性是为什么在Java中，您可以将Turtle传递给接受Animal的函数，如果Turtle是Animal的子类型，或者为什么在Rust中，您可以将'静态str传递给接受' a str的函数。

- 虽然变异性通常隐藏在视线之外，但它经常出现，我们需要对其有一定的了解。`Turtle是Animal的子类型`，因为T`urtle比某个未指定的Animal`更“有用”-Turtle可以做任何Animal可以做的事情，可能还有更多。同样，'静态是'a的子类型，因为'静态的生命周期至少与任何'a一样长，因此更有用。或者更一般地说，如果'b：'a（'b的生命周期超过'a），那么'b是'a的子类型。这显然不是正式定义，但足够接近以实际使用。
- 所有类型都有一个变异性，它定义了可以在该类型的位置使用哪些其他类似类型。变异性有三种类型：协变、不变和逆变。如果您可以在类型的位置上使用子类型，那么该类型是协变的。例如，如果一个变量的类型是' a T，您可以为其提供类型为'静态T的值，因为' a T在'a上是协变的。' a T在T上也是协变的，因此您可以将`&Vec<&'静态str>传递给接受&Vec<&'a str>的函数`。
- 有些类型是不变的，这意味着您必须提供完全相同的类型。&mut T就是一个例子-如果一个函数接受&mut Vec<&'a str>，您不能将&mut `Vec<&'静态str>传递给它`。也就是说，&mut T在T上是不变的。如果可以，函数可以将一个短命的字符串放入Vec中，而调用者则会继续使用它，`认为它是Vec<&'静态str>`，因此包含的字符串是'静态的！任何提供可变性的类型通常都是不变的，原因是相同的-例如，`Cell<T>` 在T上是不变的。
- 最后一类逆变性出现在函数参数中。如果函数的参数越不“有用”，函数类型就越有用。如果将参数类型的变异性与其作为函数参数时的变异性进行对比，这一点就更清楚了：

```rust
let x: &'static str; // more useful, lives longer
let x: &'a str; // less useful, lives shorter
fn take_func1(&'static str) // stricter, so less useful
fn take_func2(&'a str) // less strict, more useful
```

- 这种翻转的关系表明Fn(T)在T上是逆变的。
- 那么为什么在涉及生命周期时需要学习变异性呢？
当您考虑泛型生命周期参数与借用检查器的交互时，变异性变得相关。考虑一个像清单1-11中所示的类型，它在单个字段中使用了多个生命周期。

```rust
struct MutStr<'a, 'b> {
s: &'a mut &'b str
}
let mut s = "hello";
1 *MutStr { s: &mut s }.s = "world";
println!("{}", s);
```

清单1-11：需要在多个生命周期上泛型化的类型

- 乍一看，这里使用两个生命周期似乎是不必要的——我们没有需要区分结构不同部分借用的方法，就像清单1-10中的StrSplit一样。但是，如果将这里的两个生命周期替换为单个'a，代码将无法编译！这完全是因为变异性。

**注意** 1处的语法可能看起来陌生。它等同于定义一个持有MutStr的变量x，然后写入*x.s = "world"，只是没有变量，因此MutStr立即被丢弃。

- 在1处，编译器必须确定生命周期参数（s）应设置为什么生命周期。如果有两个生命周期，'a 将设置为对s的借用的待确定生命周期，'b 将设置为'static，因为这是提供的字符串"hello"的生命周期。如果只有一个生命周期'a，编译器推断该生命周期必须是'static。
- 当我们稍后尝试通过共享引用访问字符串引用s以打印它时，编译器尝试缩短MutStr使用的s的可变借用，以允许对s的共享借用。
- 在双生命周期的情况下，'a 在println之前简单地结束，'b 保持不变。另一方面，在单生命周期的情况下，我们遇到了问题。编译器希望缩短对s的借用，但要做到这一点，它还必须缩短对str的借用。尽管 'static str 通常可以缩短为任何'a str（'a T在'a 上是协变的），但在这里它在&mut T后面，而&mut T在T上是不变的。不变性要求相关类型永远不会被替换为子类型或超类型，因此编译器缩短借用的尝试失败，并报告列表仍然被可变借用。糟糕！
- 由于不变性所施加的灵活性降低，您希望确保您的类型在尽可能多的泛型参数上保持协变（或在适当的情况下是逆变的）。如果这需要引入额外的生命周期参数，您需要仔细权衡添加另一个参数的认知成本与不变性的人体工程学成本。

#### 总结

本章的目标是建立一个坚实的共享基础，以便在接下来的章节中进行构建。到目前为止，我希望您感到对Rust的内存和所有权模型有了牢固的掌握，并且您可能从借用检查器中获得的错误似乎不再神秘。您可能已经知道我们在这里介绍的一些内容，但希望本章能给您一个更全面的整体形象，了解它们如何相互配合。在下一章中，我们将对类型进行类似的操作。我们将介绍类型在内存中的表示方式，了解泛型和特性如何生成运行代码，并查看Rust为更高级用例提供的一些特殊类型和特性构造。

### 2 类型

现在基础知识已经介绍完毕，我们将看一下Rust的类型系统。我们将跳过《Rust编程语言》中介绍的基础知识，而是直接深入探讨不同类型在内存中的布局、特性和特性限制、存在类型以及在跨crate边界使用类型的规则。

#### 类型在内存中的布局

每个Rust值都有一个类型。类型在Rust中有很多用途，正如我们在本章中所看到的，但其中最基本的作用之一是告诉您如何解释内存中的位。例如，位序列0b10111101（用十六进制表示为0xBD）本身并没有任何意义，直到您为其分配一个类型。当在类型u8下解释时，该位序列表示数字189。当在类型i8下解释时，它表示-67。当您定义自己的类型时，编译器的工作是确定定义类型的每个部分在内存中的表示位置。您的结构体的每个字段在位序列中的位置是什么？您的枚举的鉴别器存储在哪里？在编写更高级的Rust代码时，了解这个过程的工作原理非常重要，因为这些细节会影响代码的正确性和性能。

##### 对齐

- 在我们讨论如何确定类型的内存表示之前，我们首先需要讨论对齐的概念，它决定了类型的字节可以存储在哪里。一旦确定了类型的表示，您可能会认为可以将任意内存位置视为该类型并解释存储在那里的字节。虽然从理论上讲这是正确的，但在实践中，硬件也限制了给定类型可以放置的位置。最明显的例子是指针指向字节而不是位。如果您将类型T的值放置在计算机内存的第4位开始的位置，您将无法引用其位置；您只能创建一个指向字节0或字节1（第8位）的指针。因此，无论其类型如何，所有值都必须从字节边界开始。我们说所有值至少需要字节对齐-它们必须放置在8位的倍数地址上。
- 有些值的对齐规则比仅仅字节对齐更严格。在CPU和内存系统中，内存通常以大于单个字节的块进行访问。例如，在64位CPU上，大多数值以8字节（64位）的块进行访问，每个操作都从8字节对齐的地址开始。这被称为CPU的字长。然后，CPU使用一些巧妙的方法来处理读取和写入较小的值，或者跨越这些块边界的值。
- 在可能的情况下，您希望确保硬件可以在其“本机”对齐方式下运行。为了看到原因，考虑一下如果尝试读取从8字节块的中间开始的i64会发生什么（即，指向它的指针不是8字节对齐）。硬件将不得不进行两次读取-一次从第一个块的后半部分到达i64的开头，一次从第二个块的前半部分读取剩余的i64-然后将结果拼接在一起。这是非常低效的。由于操作分布在对底层内存的多次访问中，如果您从不同的线程同时写入的内存上读取，可能会得到奇怪的结果。您可能在另一个线程的写入发生之前读取前4个字节，然后在写入之后读取后4个字节，导致值损坏。
- 对于未对齐的数据进行操作被称为未对齐访问，可能导致性能下降和并发问题。因此，许多CPU操作要求或强烈建议其参数是自然对齐的。自然对齐的值是其对齐与其大小相匹配的值。因此，例如，对于8字节的加载，提供的地址必须是8字节对齐的。
- 由于对齐访问通常更快并提供更强的一致性语义，编译器会尽可能利用它们。它通过为每个类型分配一个根据其包含的类型计算出的对齐方式来实现这一点。内置值通常对齐到其大小，因此u8是字节对齐的，u16是2字节对齐的，u32是4字节对齐的，u64是8字节对齐的。复杂类型-包含其他类型的类型-通常被分配为其包含的任何类型的最大对齐方式。例如，包含u8、u16和u32的类型将是4字节对齐的，因为有u32的存在。

##### 布局

现在您了解了对齐，我们可以探讨编译器如何确定类型的内存表示，即布局。默认情况下，正如您很快将看到的，Rust编译器对于如何布局类型几乎没有提供任何保证，这对于理解底层原理来说是一个很差的起点。幸运的是，Rust提供了一个repr属性，您可以将其添加到类型定义中，以请求该类型的特定内存表示。您最常见的可能是repr(C)。顾名思义，它以与C或C++编译器布局相兼容的方式布局类型。这在使用外部函数接口与其他语言进行交互的Rust代码中非常有用，我们将在第11章中讨论外部函数接口时详细介绍，因为Rust将生成与其他语言编译器期望的布局相匹配的布局。由于C布局是可预测的且不会更改，repr(C)在不安全的上下文中也非常有用，如果您使用原始指针与该类型一起工作，或者如果您需要在两个已知具有相同字段的不同类型之间进行类型转换。当然，它也非常适合进入布局算法的第一步。

**注意** 另一个有用的表示是repr(transparent)，它只能用于具有单个字段的类型，并保证外部类型的布局与内部类型完全相同。这在与“newtype”模式结合使用时非常方便，其中您可能希望按照内存表示操作某些struct A和struct NewA(A)。

- 那么，让我们看看编译器如何在内存中布局repr(C)中的特定类型：清单2-1中的Foo类型。您认为编译器会如何在内存中布局它？

```rust
#[repr(C)]
struct Foo {
  tiny: bool,
  normal: u32,
  small: u8,
  long: u64,
  short: u16,
}
 ```

清单2-1：对齐影响布局。

- 首先，编译器看到了字段tiny，其逻辑大小为1位（true或false）。但是由于CPU和内存是以字节为单位操作的，tiny在内存表示中被分配了1字节。接下来，normal是一个4字节的类型，所以我们希望它是4字节对齐的。但是，即使Foo是对齐的，我们分配给tiny的1字节也会使normal错过它的对齐。为了纠正这个问题，编译器在tiny和normal之间的内存表示中插入了3字节的填充-这些字节具有不确定的值，在用户代码中被忽略-。填充中没有值，但它占用了空间。
- 对于下一个字段small，对齐很简单：它是一个1字节的值，并且当前结构体中的字节偏移量为1 + 3 + 4 = 8。这已经是字节对齐的，所以small可以紧跟在normal之后。但是，对于long，我们又遇到了问题。现在，我们已经进入了9字节的Foo。如果Foo是对齐的，那么long不是我们希望的8字节对齐，所以我们必须再插入另外7字节的填充来重新对齐long。这也方便地确保了我们需要的2字节对齐，以容纳最后一个字段short，总共为26字节。现在，我们已经遍历了所有字段，还需要确定Foo本身的对齐方式。规则是使用Foo的任何字段的最大对齐方式，这将是8字节，因为有long。因此，为了确保如果将Foo放置在数组中（例如）时Foo保持对齐，编译器添加了最后的6字节填充，使Foo的大小成为其对齐的倍数，即32字节。
- 现在我们准备摆脱C的遗留问题，并考虑一下如果我们在清单2-1中没有使用repr(C)会发生什么。C表示的主要限制之一是它要求我们按照原始结构定义中的顺序放置所有字段。默认的Rust表示repr(Rust)消除了这个限制，以及其他一些较小的限制，例如对于具有相同字段的类型的确定性字段排序。也就是说，即使两个不同的类型共享所有相同的字段，类型相同，顺序相同，也不能保证在使用默认的Rust布局时它们的布局相同！
- 由于我们现在可以重新排序字段，我们可以按照大小递减的顺序放置它们。这意味着我们不再需要Foo字段之间的填充；字段本身用于实现所需的对齐！现在，Foo只是其字段的大小：只有16字节。这是Rust默认情况下不会给出关于类型在内存中布局的许多保证的原因之一：通过给编译器更多的自由重新排列事物，我们可以生成更高效的代码。
- 实际上，还有第三种布局类型的方式，那就是告诉编译器我们不希望在字段之间有任何填充。这样做意味着我们愿意承受使用未对齐访问的性能损失。最常见的用例是当每个额外的字节内存的影响都可以感知到时，例如如果您有大量类型的实例，如果您的内存非常有限，或者如果您正在通过像网络连接这样的低带宽介质发送内存表示。要选择此行为，您可以使用#[repr(packed)]注解您的类型。请记住，这可能导致更慢的代码，并且在极端情况下，如果尝试执行CPU仅对齐参数支持的操作，可能会导致程序崩溃。
- 有时，您希望为特定字段或类型提供比其技术要求更大的对齐方式。您可以使用属性#[repr(align(n))]来实现这一点。这样做的一个常见用例是确保存储在内存中连续的不同值（例如在数组中）最终位于CPU的不同缓存行中。这样，您可以避免伪共享，伪共享可能导致并发程序的性能严重下降。伪共享发生在两个不同的CPU访问共享缓存行的不同值时；虽然它们理论上可以并行操作，但它们最终都会争夺更新缓存中的同一条目。我们将在第10章中更详细地讨论并发性。

##### 复杂类型

- 您可能会好奇编译器如何在内存中表示其他Rust类型。这里是一个快速参考：

  - **元组** 以与元组值相同顺序的相同类型字段的结构体表示。
  - **数组** 作为包含类型的连续序列表示，元素之间没有填充。
  - **联合** 布局独立选择每个变体。对齐方式是所有变体中的最大值。
  - **枚举** 与联合相同，但有一个额外的隐藏共享字段，用于存储枚举变体的鉴别器。鉴别器是代码用来确定给定值包含的枚举变体的值。鉴别器字段的大小取决于变体的数量。
  
##### 动态大小类型和宽指针

您可能在Rust文档的各个奇怪角落和错误消息中遇到过标记特征Sized。通常，它会出现，因为编译器希望您提供一个Sized类型，但您（显然）没有提供。在Rust中，大多数类型都会自动实现Sized，也就是说，它们在编译时具有已知的大小，但有两种常见类型不是：特征对象和切片。如果您有一个dyn Iterator或[u8]，它们没有明确定义的大小。它们的大小取决于程序运行时才能知道的一些信息，而不是在编译时，这就是为什么它们被称为动态大小类型（DST）。没有人事先知道您的函数接收到的dyn Iterator是这个200字节的结构还是那个8字节的结构。这带来了一个问题：通常，编译器必须知道某个东西的大小才能生成有效的代码，例如对于类型为(i32，dyn Iterator，[u8]，i32)的元组分配多少空间，或者如果您的代码尝试访问第四个字段时要使用的偏移量。但是，如果类型不是Sized，那么这些信息是不可用的。

编译器几乎在任何地方都要求类型是Sized的。结构字段、函数参数、返回值、变量类型和数组类型都必须是Sized的。这个限制是如此常见，以至于您编写的每个类型约束都包括T: Sized，除非您使用T: ?Sized明确地选择退出（?表示“可能不是”）。但是，如果您有一个DST并且希望对其执行某些操作，这样做并不是很有帮助，例如，如果您真的希望函数接受特征对象或切片作为参数。
解决无大小和有大小类型之间差距的方法是将无大小类型放在宽指针（也称为胖指针）后面。宽指针与普通指针非常相似，但它包含一个额外的字大小字段，该字段提供了编译器生成与指针一起工作的合理代码所需的附加信息。当您对DST引用时，编译器会自动为您构造一个宽指针。对于切片，额外的信息只是切片的长度。对于特征对象-好吧，我们稍后再说。关键是，宽指针是Sized的。具体而言，它是usize的两倍大小（usize是目标平台上一个字的大小）：一个usize用于保存指针，一个usize用于保存“完成”类型所需的额外信息。
**注意** Box和Arc也支持存储宽指针，这就是为什么它们都支持T: ?Sized的原因。

#### 特质和特质约束

特质是Rust类型系统的关键部分，它们是使类型能够在定义时互操作的粘合剂。《Rust编程语言》对如何定义和使用特质进行了很好的介绍，所以我不会在这里详细介绍。相反，我们将看一下特质的一些更技术性的方面：它们是如何实现的、您必须遵守的限制以及一些更奇特的特质用法。

##### 编译和分派

到目前为止，您可能已经在Rust中编写了相当数量的泛型代码。您在类型和方法上使用了泛型类型参数，甚至可能偶尔使用了一些特质约束。但是，您是否曾经想过在编译泛型代码时实际发生了什么，或者在对dyn Trait调用特质方法时会发生什么？

当您编写一个对T泛型的类型或函数时，实际上是在告诉编译器为每个类型T创建一个副本的类型或函数。当您构造一个Vec或HashMap<String, bool>时，编译器实际上是将泛型类型及其所有实现块复制粘贴，并将每个泛型参数的所有实例替换为您提供的具体类型。它为每个T替换为i32创建了一个完整的Vec类型的副本，并为每个K替换为String和每个V替换为bool创建了一个完整的HashMap类型的副本。
**注意** 实际上，编译器并不真正进行完整的复制粘贴。它只复制您使用的代码的部分，因此如果您从未在Vec上调用find，那么find的代码将不会被复制和编译。

泛型函数也是如此。考虑清单2-2中的代码，它展示了一个泛型方法。

```rust
impl String {
pub fn contains(&self, p: impl Pattern) -> bool {
     p.is_contained_in(self)
  }
}
```

清单2-2：使用静态分派的泛型方法

- 对于每种不同的模式类型，都会创建该方法的副本（回想一下，impl Trait是<T: Trait>的简写）。我们需要为每种impl Pattern类型创建一个不同的函数体副本，因为我们需要知道is_contained_in函数的地址以便调用它。CPU需要被告知跳转到哪里并继续执行。对于任何给定的模式，编译器知道该地址是该模式类型实现该特质方法的地方的地址。但是，我们无法为任何类型使用一个地址，因此我们需要为每种类型创建一个副本，每个副本都有自己的地址跳转。这被称为静态分派，因为对于方法的任何给定副本，我们“分派到”的地址是已知的静态地址。

**注意** 您可能已经注意到，在这个上下文中，“静态”一词有点多义。静态通常用于指代在编译时已知的任何内容，或者可以被视为已知的内容，因为它可以写入静态内存，正如我们在第1章中讨论的那样。

- 从泛型类型到许多非泛型类型的过程称为单态化，这也是泛型Rust代码通常与非泛型代码一样高效的原因之一。当编译器开始优化代码时，它就好像没有泛型存在一样！每个实例都是单独优化的，并且所有类型都是已知的。因此，代码的效率与直接调用传入的模式的is_contained_in方法一样高效，而不需要任何特质。编译器对所涉及的类型有完全的了解，甚至可以选择内联is_contained_in的实现。
- 单态化也有代价：所有这些类型的实例化需要单独编译，如果编译器无法优化它们，这可能会增加编译时间。每个单态化函数也会产生自己的机器代码块，这可能会使程序变得更大。由于不同实例化的泛型类型方法之间不共享指令，CPU的指令缓存也不那么有效，因为现在需要保存多个实际上相同指令的副本。
  
  **非泛型内部函数**

- 通常，泛型方法中的大部分代码与类型无关。例如，考虑HashMap::insert的实现。计算提供的键的哈希值的代码取决于映射的键类型，但遍历映射的桶以找到插入点的代码可能与类型无关。在这种情况下，共享生成的非泛型方法的机器代码将更高效，只有在实际需要时才生成不同的副本。

- 您可以使用以下模式来处理这种情况：在泛型方法内部声明一个非泛型的辅助函数，执行共享操作。这样，编译器只需为您复制粘贴与类型相关的代码，而辅助函数可以共享使用。
- 将函数设置为内部函数的好处是，您不会在模块中污染一个单一目的的函数。相反，您可以在方法之外声明这样的辅助函数；只需注意不要将其设置为泛型impl块下的方法，否则它仍将被单态化。

- 静态分派的替代方案是动态分派，它使代码能够在不知道泛型类型的情况下调用特质方法。我之前说过，在清单2-2中需要多个方法实例的原因是，否则您的程序将不知道调用给定模式上的特质方法is_contained_in的地址。好吧，使用动态分派，调用方只需告诉您。如果您将impl Pattern替换为&dyn Pattern，您告诉调用方他们必须为此参数提供两个信息：模式的地址和is_contained_in方法的地址。在实践中，调用方给我们提供了一个指向称为虚方法表或vtable的内存块的指针，该内存块保存了有关该类型的所有特质方法的实现的地址，其中之一是is_contained_in。当方法内部的代码想要在提供的模式上调用特质方法时，它会在vtable中查找该模式的is_contained_in实现的地址，然后调用该地址处的函数。这使我们能够在不管调用方想要使用什么类型的情况下使用相同的函数体。
**注意** 每个vtable还包含有关具体类型的布局和对齐方式的信息，因为始终需要这些信息来处理类型。如果您想要一个显式vtable的示例，请查看std::task::RawWakerVTable类型。
- 当我们使用dyn关键字选择动态分派时，您会注意到我们必须在其前面加上&符号。原因是我们不再在编译时知道调用方传递的模式类型的大小，因此我们不知道为其分配多少空间。换句话说，dyn Trait是!Sized，其中!表示不。为了使其Sized，以便我们可以将其作为参数接受，我们将其放在指针后面（我们知道其大小）。由于我们还需要传递方法地址表，因此该指针变成了宽指针，其中额外的字保存了指向vtable的指针。您可以使用任何能够保存宽指针的类型进行动态分派，例如&mut、Box和Arc。清单2-3显示了清单2-2的动态分派等效形式。

```rust
impl String {
  pub fn contains(&self, p: &dyn Pattern) -> bool {
    p.is_contained_in(&*self)
  }
}
```

清单2-3：使用动态分派的通用方法

- 实现特质的类型和其vtable的组合被称为特质对象。大多数特质都可以转换为特质对象，但并非所有特质都可以。例如，Clone特质的clone方法返回Self，因此无法转换为特质对象。如果我们接受一个dyn Clone特质对象，然后调用clone方法，编译器将不知道返回的类型是什么。或者，考虑标准库中的Extend特质，它的extend方法对提供的迭代器的类型是泛型的（因此可能有多个实例）。如果您调用一个接受dyn Extend的方法，那么在特质对象的vtable中就没有一个单一的地址可以放置extend；必须为extend可能被调用的每种类型都有一个条目。这些是不可对象安全的特质的示例，因此可能无法转换为特质对象。为了是对象安全的，特质的所有方法都不能是泛型的，也不能使用Self类型。此外，特质不能有任何静态方法（即，第一个参数不解引用为Self的方法），因为无法知道要调用的方法的哪个实例。例如，不清楚FromIterator::from_iter(&[0])应该执行哪段代码。
- 在阅读有关特质对象的文档时，您可能会看到对特质绑定Self: Sized的提及。这样的绑定意味着Self没有通过特质对象使用（因为它将是!Sized）。您可以将该绑定放在特质上，以要求该特质永远不使用动态分派，或者可以将其放在特定方法上，以使该方法在通过特质对象访问特质时不可用。具有where Self: Sized绑定的方法在检查特质是否对象安全时被豁免。
- 动态分派可以减少编译时间，因为不再需要编译类型和方法的多个副本，并且可以提高CPU指令缓存的效率。然而，它也阻止编译器针对特定使用的类型进行优化。使用动态分派，清单2-2中的find方法只能通过vtable插入对函数的调用-编译器无法执行任何额外的优化，因为它不知道该函数调用的另一侧的代码是什么。此外，对特质对象的每个方法调用都需要在vtable中进行查找，这会增加一小部分开销，而不是直接调用方法。

- 当你在静态分派和动态分派之间做选择时，很少有明确的正确答案。总的来说，在库中使用静态分派，在二进制文件中使用动态分派是比较合适的。在库中，你希望允许用户根据他们的需求选择最适合他们的分派方式。如果你使用动态分派，他们也被迫这样做，而如果你使用静态分派，他们可以选择是否使用动态分派。另一方面，在二进制文件中，你编写的是最终代码，所以除了你编写的代码之外，没有其他需求需要考虑。动态分派通常允许你编写更清晰的代码，省略了泛型参数，并且编译速度更快，尽管性能上可能会有一些损失，所以通常对于二进制文件来说是更好的选择。

##### 泛型特质

Rust的特质可以通过两种方式进行泛型化：使用泛型类型参数，例如`trait Foo<T>`，或者使用关联类型，例如trait Foo { type Bar; }。这两者之间的区别并不立即显而易见，但幸运的是，有一个简单的经验法则：如果您期望给定类型的特质只有一个实现，请使用关联类型；否则，请使用泛型类型参数。

- 这样做的原因是，关联类型通常更容易使用，但不允许多个实现。因此，简而言之，建议您尽可能使用关联类型。
- 对于泛型特质，用户必须始终指定所有泛型参数并重复任何参数的约束。这可能很快变得混乱且难以维护。如果您向特质添加了一个泛型参数，那么该特质的所有用户也必须进行更新以反映这些更改。由于对于给定类型可能存在多个特质的实现，编译器可能很难确定您要使用的特质实例，从而导致糟糕的消除歧义的函数调用，例如`FromIterator::<u32>::from_iter`。但好处是，您可以为同一类型多次实现特质，例如，您可以为您的类型实现多个右侧类型的PartialEq，或者您可以同时为`FromIterator<T>`和FromIterator<&T>实现，其中T: Clone，这正是泛型特质提供的灵活性。
- 另一方面，对于关联类型，编译器只需要知道实现特质的类型，然后跟随所有关联类型（因为只有一个实现）。这意味着所有约束都可以存在于特质本身中，不需要在使用时重复。反过来，这允许特质添加进一步的关联类型而不影响其用户。由于类型决定了特质的所有关联类型，您永远不必使用前面段落中显示的统一函数调用语法进行消除歧义。然而，您不能为多个Target类型实现Deref，也不能为多个不同的Item类型实现Iterator。

##### 一致性和孤儿规则

Rust对于可以在哪里实现特质以及可以在哪些类型上实现它们有一些相当严格的规则。这些规则存在的目的是保持一致性属性：对于任何给定的类型和方法，对于该类型使用的方法的实现只有一个正确的选择。为了看到这一点的重要性，考虑一下如果我可以为标准库中的bool类型编写自己的Display特质实现会发生什么。现在，对于任何试图打印bool值并包含我的crate的代码，编译器将不知道是选择我编写的实现还是标准库中的实现。两种选择都不正确，也没有比另一种更好，编译器显然无法随机选择。如果没有涉及标准库，而是我们有两个相互依赖的crate，并且它们都为某个共享类型实现了一个特质，那么同样的问题也会发生。一致性属性确保编译器永远不会陷入这些情况，也永远不必做出这些选择：总是只有一个明显的选择。

- 维护一致性的一种简单方法是确保只有定义特质的crate才能为该特质编写实现；如果其他人无法实现该特质，那么就不会在其他地方出现冲突的实现。然而，在实践中，这太过限制性，会使特质变得无用，因为除非您将自己的类型包含在定义crate中，否则无法为自己的类型实现诸如std::fmt::Debug和serde::Serialize之类的特质。相反的极端观点是，只能为自己的类型实现特质，解决了这个问题，但引入了另一个问题：定义特质的crate现在无法为标准库或其他流行crate中的类型提供该特质的实现！理想情况下，我们希望找到一些规则，以在希望下游crate为其自己的类型实现上游特质之间取得平衡，同时又希望上游crate能够添加自己特质的实现而不会破坏下游代码。

**注意** 上游是指您的代码依赖的内容，下游是指依赖于您的代码的内容。通常，这些术语在直接的crate依赖关系意义上使用，但它们也可以用于指代代码库的官方分支的权威分支 - 如果您对Rust编译器进行分支，官方Rust编译器就是您的“上游”。

- 在Rust中，确立这种平衡的规则是孤儿规则。简单地说，孤儿规则规定，只有当特质或类型是本地crate的时候，才能为类型实现特质。因此，您可以为自己的类型实现Debug，也可以为bool实现MyNeatTrait，但不能为bool实现Debug。如果尝试这样做，您的代码将无法编译，并且编译器将告诉您存在冲突的实现。
- 这可以让您走得很远；它允许您为第三方类型实现自己的特质，并为自己的类型实现第三方特质。然而，孤儿规则并不是故事的终点。还有一些额外的含义、注意事项和例外情况需要注意。

**全局实现**
孤儿规则允许您使用类似impl`<T> MyTrait for T where T:`的代码来为一系列类型实现特质。这是一种全局实现 - 它不仅限于特定的类型，而是适用于广泛的类型范围。只有定义特质的crate才允许编写全局实现，并且向现有特质添加全局实现被认为是一种破坏性的更改。如果不是这样，包含impl MyTrait for Foo的下游crate可能会因为您更新定义MyTrait的crate而突然停止编译，并出现关于冲突实现的错误。
**基本类型**
某些类型非常重要，以至于必须允许任何人在其上实现特质，即使这似乎违反了孤儿规则。这些类型使用#[fundamental]属性进行标记，目前包括&、&mut和Box。对于孤儿规则而言，基本类型可以说不存在 - 在检查孤儿规则之前，它们实际上被擦除了，以便您可以为&MyType实现IntoIterator，例如。只有孤儿规则的话，这个实现是不允许的，因为它为外部类型实现了外部特质 - IntoIterator和&都来自标准库。添加基本类型的全局实现也被认为是一种破坏性的更改。
**覆盖实现**
有一些有限的情况下，我们希望允许为外部类型实现外部特质，而孤儿规则通常不允许这样做。这种情况的最简单示例是当您想要编写类似`impl From<MyType> for Vec<i32>`的代码时。在这里，From特质是外部的，Vec类型也是外部的，但没有违反一致性的危险。这是因为只有通过标准库中的全局实现（标准库无法命名MyType）才能添加冲突的实现，而这本身就是一种破坏性的更改。
为了允许这些类型的实现，孤儿规则包含了一个狭窄的例外，只允许在非常特定的情况下为外部类型实现外部特质。具体而言，只有当至少一个Ti是本地类型，并且在第一个这样的Ti之前的所有T都不是泛型类型P1..=Pn时，才允许给定的impl<P1..=Pn> ForeignTrait<T1..=Tn> for T0。泛型类型参数（Ps）允许出现在T0..Ti中，只要它们被某些中间类型覆盖即可。如果T作为其他类型的类型参数出现（例如`Vec<T>`），则T被视为已覆盖，但如果T独立存在（只是T）或仅出现在基本类型&后面，那么T就不被视为已覆盖。因此，Listing 2-4中的所有实现都是有效的。

```rust
impl<T> From<T> for MyType
impl<T> From<T> for MyType<T>
impl<T> From<MyType> for Vec<T>
impl<T> ForeignTrait<MyType, T> for Vec<T>

```

清单2-4：为外部类型实现外部特质的有效实现

然而，清单2-5中的实现是无效的。

```rust
impl<T> ForeignTrait for T
impl<T> From<T> for T
impl<T> From<Vec<T>> for T
impl<T> From<MyType<T>> for T
impl<T> From<T> for Vec<T>
impl<T> ForeignTrait<T, MyType> for Vec<T>
```

清单2-5：为外部类型实现外部特质的无效实现

- 孤儿规则的这种放宽使得在为现有特质添加新实现时，什么构成破坏性更改变得复杂。特别是，只有当新实现包含至少一个新的本地类型，并且该新的本地类型满足前面描述的例外规则时，才不会产生破坏性更改。添加任何其他新实现都是破坏性更改。

**注意** 注意，`impl<T> ForeignTrait<LocalType, T> for ForeignType`是有效的，但`impl<T> ForeignTrait<T, LocalType> for ForeignType`是无效的！这可能看起来是武断的，但如果没有这个规则，您可以编写impl`<T> ForeignTrait<T, LocalType> for ForeignType`，而另一个crate可以编写`impl<T> ForeignTrait<TheirType, T> for ForeignType`，只有当两个crate合并在一起时才会出现冲突。孤儿规则要求您的本地类型出现在类型参数之前，从而打破了这种关系，并确保如果两个crate在隔离环境中遵守一致性，它们在合并时也会遵守一致性。

##### 特质约束

标准库中充斥着特质约束，无论是HashMap中的键必须实现Hash + Eq，还是传递给thread::spawn的函数必须是FnOnce + Send + 'static。当您自己编写通用代码时，它几乎肯定会包含特质约束，否则您的代码对其泛型类型无法做太多事情。随着您编写更复杂的通用实现，您会发现自己对特质约束需要更多的准确性，因此让我们看一下一些实现这一目标的方法。

- 首先，特质约束不必采用T: Trait的形式，其中T是您的实现或类型泛型的某种类型。约束可以是任意类型限制，甚至不需要包括泛型参数、参数类型或本地类型。您可以编写像where String: Clone这样的特质约束，即使String: Clone始终为真且不包含本地类型。您还可以编写像`where io::Error: From<MyError<T>>`这样的特质约束；您的泛型类型参数不仅需要出现在左侧，这不仅允许您表达更复杂的约束，还可以避免不必要地重复约束。例如，如果您的方法想要构造一个HashMap<K, V, S>，其中键是某个泛型类型T，值是usize，而不是像where T: Hash + Eq, S: BuildHasher + Default这样写出约束，您可以写出where HashMap<T, usize, S>: FromIterator。这样可以避免查找您最终使用的方法的确切约束要求，并更清楚地传达代码的“真实”要求。正如您所看到的，如果底层特质方法的约束较复杂，它还可以显著减少约束的复杂性。

  **派生特质**

  虽然#[derive(Trait)]非常方便，但在特质约束的上下文中，您应该注意一个细微之处，即它通常是如何实现的。许多#[derive(Trait)]展开成`impl Trait for Foo<T> where T: Trait`。这通常是您想要的，但并非总是如此。例如，考虑以这种方式为`Foo<T>派生Clone，而Foo包含Arc<T>`。无论T是否实现Clone，Arc都实现了Clone，但由于派生的约束，只有当T实现Clone时，Foo才会实现Clone！这通常不是太大的问题，但它确实增加了一个不需要的约束。如果我们将类型重命名为Shared，问题可能会变得更清晰一些。想象一下，当编译器告诉用户他们无法克隆`Shared<NotClone>`时，他们会多么困惑！在撰写本文时，标准库提供的#[derive(Clone)]就是这样工作的，尽管这可能会在将来发生变化

- 有时，您希望对您的泛型类型的关联类型进行约束。例如，考虑迭代器方法flatten，它接受一个产生本身实现Iterator的项的迭代器，并生成这些内部迭代器的项的迭代器。它生成的类型Flatten是泛型的，其中I是外部迭代器的类型。如果I实现了Iterator，并且I产生的项本身实现了IntoIterator，则Flatten实现了Iterator。为了使您能够编写这样的约束，Rust允许您使用语法Type::AssocType来引用类型的关联类型。例如，我们可以使用I::Item来引用I的Item类型。如果一个类型具有多个相同名称的关联类型，例如如果提供关联类型的特质本身是泛型的（因此有许多实现），则可以使用语法`<Type as Trait>::AssocType`进行消歧义。使用这种方式，您不仅可以为外部迭代器类型编写约束，还可以为该外部迭代器的项类型编写约束。

- 在广泛使用泛型的代码中，您可能会发现自己需要编写一个关于对类型的引用的约束。通常情况下，这是可以接受的，因为您往往还会有一个可以用作这些引用的生命周期参数。然而，在某些情况下，您希望约束说“对于任何生命周期，此引用都实现此特质。”这种类型的约束被称为高阶特质约束，它在与Fn特质结合使用时特别有用。例如，假设您希望对一个函数进行泛型化，该函数接受对T的引用并返回对T内部的引用。如果您编写F: Fn(&T) -> &U，您需要为这些引用提供一个生命周期，但您真正想要说的是“任何生命周期，只要输出与输入相同。”使用高阶生命周期，您可以编写F: for<'a> Fn(&'a T) -> &'a U，表示对于任何生命周期'a，约束必须成立。Rust编译器足够聪明，当您编写类似于Fn约束的引用时，它会自动添加for，这涵盖了此功能的大多数用例。在撰写本文时，标准库仅在三个地方使用了显式形式，但确实存在，因此值得了解。

- 将所有这些内容结合起来，考虑清单2-6中的代码，它可以用于为任何可以迭代且元素具有Debug特性的类型实现Debug。
  
```rust
impl Debug for AnyIterable
where for<'a> &'a Self: IntoIterator,
for<'a> <&'a Self as IntoIterator>::Item: Debug {
fn fmt(&self, f: &mut Formatter) -> Result<(), Error> {
f.debug_list().entries(self).finish()
}}

```

清单2-6：适用于任何可迭代集合的过度泛化的Debug实现

- 您可以将此实现复制粘贴到几乎任何集合类型中，它将“正常工作”。当然，您可能希望有一个更智能的调试实现，但这很好地说明了特质约束的强大之处。

##### 标记特质

通常，我们使用特质来表示多个类型可以支持的功能；可以通过调用hash对Hash类型进行哈希，可以通过调用clone对Clone类型进行克隆，可以通过调用fmt对Debug类型进行格式化以进行调试。但并非所有特质都以这种方式发挥功能。一些特质，称为标记特质，相反地指示实现类型的属性。标记特质没有方法或关联类型，只是告诉您特定类型可以或不能以某种方式使用。例如，如果一个类型实现了Send标记特质，那么在线程边界上发送它是安全的。如果它没有实现这个标记特质，那么发送它是不安全的。这个行为没有关联的方法；它只是关于类型的一个事实。标准库中有许多这样的特质，包括Send、Sync、Copy、Sized和Unpin，它们中的大多数（除了Copy）也是自动特质；编译器会自动为类型实现它们，除非类型包含了不实现标记特质的内容。

- 标记特质在Rust中起着重要的作用：它们允许您编写捕捉代码中未直接表达的语义要求的约束。在需要类型是Send的代码中没有调用send。相反，代码假设给定的类型可以在单独的线程中使用，没有标记特质，编译器无法检查这个假设。程序员需要记住这个假设并仔细阅读代码，这是我们都知道不希望依赖的事情。这条路上充满了数据竞争、段错误和其他运行时问题。
- 类似于标记特质的是标记类型。它们是不包含数据且没有方法的单元类型（例如struct MyMarker;）。标记类型在标记类型处于特定状态时非常有用。当您希望防止用户误用API时，它们非常方便。例如，考虑一个类型SshConnection，它可能已经进行了身份验证，也可能还没有进行身份验证。您可以为SshConnection添加一个泛型类型参数，然后创建两个标记类型：Unauthenticated和Authenticated。当用户首次连接时，他们会得到`SshConnection<Unauthenticated>`。在其impl块中，您只提供一个方法：connect。connect方法返回一个`SshConnection<Authenticated>`，只有在该impl块中，您才提供运行命令等其他方法。我们将在第3章进一步讨论这种模式。

#### 存在类型

在Rust中，您很少需要为函数体中声明的变量指定类型，也不需要为调用的泛型参数的类型指定类型。这是因为类型推断，编译器根据类型出现的代码所评估的类型来决定使用的类型。编译器通常只会对变量和闭包的参数（和返回类型）进行类型推断；顶层定义，如函数、类型、特质和特质实现块，都需要您明确命名所有类型。这样做的原因有几个，但主要原因是当您至少有一些已知的起点来开始推断时，类型推断会更容易。然而，并不总是容易，甚至不可能完全命名一个类型！例如，如果您从函数返回一个闭包，或者从特质方法返回一个异步块，它的类型没有一个您可以在代码中输入的名称。

- 为了处理这种情况，Rust支持存在类型。很有可能，您已经看到了存在类型的作用。所有标记为async fn或返回类型为impl Trait的函数都具有存在返回类型：签名不给出返回值的真实类型，只是给出函数返回某个实现了一组特质的类型的一些提示，调用者可以依赖于该返回类型实现这些特质，而不是其他任何东西。

**注意** 严格来说，调用者不仅依赖于返回类型，还依赖于其他内容。编译器还会通过impl Trait在返回位置传播自动特质，如Send和Sync。我们将在下一章中更详细地讨论这个问题。

- 这种行为赋予了存在类型其名称：我们断言存在某个与签名匹配的具体类型，并且我们将其寻找的任务交给编译器。编译器通常会通过对函数体应用类型推断来找到这个类型。

- 并非所有的impl Trait实例都使用存在类型。如果您在函数的参数位置使用impl Trait，它实际上只是该函数的未命名泛型参数的简写。例如，fn foo(s: impl ToString)在大多数情况下只是fn foo<S: ToString>(s: S)的语法糖。
- 存在类型在实现具有关联类型的特质时特别有用。例如，想象一下，您正在实现IntoIterator特质。它有一个关联类型IntoIter，它保存了可以将所讨论的类型转换为的迭代器的类型。使用存在类型，您不需要定义一个单独的迭代器类型来用于IntoIter。相反，您可以将关联类型指定为impl Iterator<Item = Self::Item>，并在fn into_iter(self)中编写一个求值为迭代器的表达式，例如通过对某个现有迭代器类型进行映射和过滤。

- 存在类型不仅提供了方便，还提供了一个超越方便的功能：它们允许您执行零成本的类型擦除。您可以使用存在类型隐藏底层具体类型，而不是仅仅因为它们出现在公共签名中而导出辅助类型 - 迭代器和futures是常见的例子。您的接口的用户只会看到相关类型实现的特质，而具体类型则作为实现细节留下。这不仅简化了接口，而且还使您可以随意更改该实现，而不会破坏Future的下游代码。

#### `总结`

本章对Rust类型系统进行了全面的回顾。我们既看了编译器如何在内存中显现类型，又看了它如何推理类型本身。这是后续章节中编写不安全代码、复杂应用程序接口和异步代码的重要背景材料。您还会发现，本章中的大部分类型推理都与您设计Rust代码接口的方式有关，我们将在下一章中介绍这一点。

### 3 设计接口

**每个项目，无论大小，都有一个API。实际上，通常有几个API。其中一些是面向用户的，比如HTTP端点或命令行界面，而另一些是面向开发者的，比如库的公共接口。除此之外，Rust的crate还有许多内部接口：每个类型、特质和模块边界都有自己的微型API，与代码的其余部分进行交互。随着代码库的规模和复杂性的增长，您会发现值得投入一些思考和关注，以设计良好的内部API，以使使用和维护代码的体验尽可能愉快。在本章中，我们将讨论一些在Rust中编写符合惯用法的接口的最重要的考虑因素，无论这些接口的用户是您自己的代码还是使用您的库的其他开发者。这些原则基本上可以归结为四个：接口应该是不令人惊讶的、灵活的、明显的和受限制的。我将依次讨论这些原则，为编写可靠和可用的接口提供一些指导。**

- 我强烈建议在阅读本章后查看Rust API指南[（https://rust-lang.github.io/api-guidelines/）]。其中有一个优秀的清单，您可以按照其中的每个建议进行详细的操作。本章中的许多建议也可以通过cargo clippy工具进行检查，如果您尚未运行该工具，请开始运行。我还鼓励您阅读Rust RFC 1105[（https://rust-lang.github.io/rfcs/1105-api-evolution.html）]和The Cargo Book中关于SemVer兼容性的章节[（https://doc.rust-lang.org/cargo/reference/semver.html）]，它们涵盖了在Rust中什么是破坏性更改和什么不是破坏性更改。

#### 不令人惊讶

最小惊讶原则，也被称为最小惊讶法则，在软件工程中经常出现，对于Rust接口也同样适用。在可能的情况下，您的接口应该足够直观，以至于用户在猜测时通常能够猜对。当然，并不是您的应用程序的所有内容都会立即以这种方式直观，但任何可以不令人惊讶的地方都应该是如此。核心思想是紧密围绕用户可能已经了解的事物，以便他们不必以与他们习惯不同的方式重新学习概念。这样，您可以为他们节省脑力来解决实际上与您的接口有关的问题。

- 有多种方法可以使您的接口可预测。在这里，我们将看看如何使用命名、常见特质和人性化特质技巧来帮助用户。

##### 命名规范

用户通过名称首次接触到您的接口；他们会立即从类型、方法、变量、字段和库的名称中推断出一些信息。如果您的接口重用了其他（可能是常见的）接口中的方法和类型的名称，用户将知道他们可以对您的方法和类型做出某些假设。一个名为iter的方法可能会接受&self，并且可能会返回一个迭代器。一个名为into_inner的方法可能会接受self，并且可能会返回某种包装类型。一个名为SomethingError的类型可能会实现std::error::Error，并出现在各种结果中。通过为相同的目的重用常见名称，您使用户更容易猜测事物的功能，并使他们更容易理解您的接口中与其他接口不同的地方。

- 与此相关的是，具有相同名称的事物实际上应该以相同的方式工作。否则，例如，如果您的iter方法接受self，或者您的SomethingError类型没有实现Error，用户可能会根据他们对接口的期望编写错误的代码。他们会感到惊讶和沮丧，并且不得不花时间研究您的接口与他们的期望有何不同。当我们可以避免给用户带来这种摩擦时，我们应该这样做。

##### 类型的常见特质

在Rust中，用户通常会假设接口中的一切“只是工作的”。他们希望能够使用{:?}打印任何类型，并将任何东西发送到另一个线程，他们期望每个类型都是可克隆的。在可能的情况下，我们应该避免让用户感到惊讶，并且尽早实现大多数标准特质，即使我们目前并不需要它们。

- 由于第2章讨论的一致性规则，编译器不允许用户在需要时实现这些特质。用户不能为您接口中的外部类型实现外部特质（如Clone）。相反，他们需要在自己的类型中包装您的接口类型，即使这样，如果没有访问类型的内部，编写合理的实现可能也很困难。
- 首先，这些标准特质中的第一个是Debug特质。几乎每种类型都可以实现Debug特质，即使只是打印类型的名称也可以。在接口中实现Debug特质的最佳方式通常是使用#[derive(Debug)]，但请记住，所有派生的特质都会自动为任何泛型参数添加相同的约束。您也可以通过利用fmt::Formatter上的各种debug_辅助函数来编写自己的实现。
- 紧随其后的是 Rust 的自动 trait Send 和 Sync（以及在较小程度上是 Unpin）。如果一个类型没有实现这些 trait，那应该有一个非常好的理由。一个没有实现 Send 的类型不能放置在 Mutex 中，也不能在包含线程池的应用程序中进行传递使用。一个没有实现 Sync 的类型不能通过 Arc 进行共享，也不能放置在静态变量中。用户已经习惯了在这些上下文中类型可以正常工作，特别是在几乎所有东西都在线程池上运行的异步世界中，如果您不确保您的类型实现了这些 trait，用户会感到沮丧。如果您的类型无法实现这些 trait，请确保将此事实以及原因在文档中进行充分说明！
- 接下来，您应该实现的几乎通用的特质是Clone和Default。这些特质可以很容易地派生或实现，并且对大多数类型来说都是有意义的。如果您的类型无法实现这些特质，请确保在文档中明确说明，因为用户通常希望能够轻松创建更多（和新的）类型实例。如果他们不能，他们会感到惊讶。
- 在期望特质的层次结构中，比较特质：PartialEq、PartialOrd、Hash、Eq和Ord更进一步。特别值得注意的是PartialEq特质，因为用户最终会有两个希望使用==或assert_eq!来比较的实例。即使对于同一类型的相同实例，您的类型可能会比较相等，实现PartialEq也是值得的，以便让用户使用assert_eq!。
- PartialOrd和Hash更为特殊，可能不适用于所有情况，但在可能的情况下，您也应该实现它们。对于用户可能将其用作映射中的键或使用std::collection集合类型进行去重的类型，这一点尤其重要，因为它们往往需要这些约束。Eq和Ord对于实现类型的比较操作有额外的语义要求，超出了PartialEq和PartialOrd的要求。这些要求在这些特质的文档中有详细说明，只有在您确信这些语义实际适用于您的类型时才应该实现它们。
- 对于大多数类型来说，实现serde crate的Serialize和Deserialize特质是有意义的。这些特质可以很容易地派生，serde_derive crate甚至提供了覆盖仅适用于一个字段或枚举变体的序列化的机制。由于serde是一个第三方crate，您可能不希望添加对它的必需依赖。因此，大多数库选择提供一个serde功能，只有在用户选择时才添加对serde的支持。
- 你可能想知道为什么我没有在这一节中包括可派生的 trait Copy。有两个因素使 Copy 与其他提到的 trait 有所不同。首先，用户通常不希望类型是 Copy；相反，他们倾向于认为如果他们想要两个副本，他们必须调用 clone。Copy 改变了移动给定类型的值的语义，这可能会让用户感到惊讶。这与第二个观察结果相关：一个类型很容易停止是 Copy，因为 Copy 类型受到严格限制。一个最初简单的类型很容易最终需要持有一个 String 或其他非 Copy 类型。如果发生这种情况，并且您必须删除 Copy 实现，那将是一个不兼容的变更。相比之下，您很少需要删除 Clone 实现，因此这是一个较轻的承诺。

##### 人性化的特质实现

Rust 不会自动为实现了特质的类型的引用实现特质。换句话说，您通常不能使用 &Bar 调用 fn foo<T: Trait>(t: T)，即使 Bar: Trait。这是因为 Trait 可能包含需要 &mut self 或 self 的方法，显然无法在 &Bar 上调用。然而，对于看到 Trait 只有 &self 方法的用户来说，这种行为可能非常令人惊讶！

- 因此，当您定义一个新的特质时，通常会根据需要为&T where T: Trait，&mut T where T: Trait和Box<T> where T: Trait提供全局实现。根据Trait的方法接收者，您可能只能实现其中一些。标准库中的许多特质具有类似的实现，这样可以减少用户的惊讶。
- 迭代器是另一种情况，您通常会希望在对类型的引用上专门添加特质实现。对于任何可迭代的类型，考虑在适用的情况下为&MyType和&mut MyType实现IntoIterator。这使得使用借用实例的循环也能够正常工作，就像用户期望的那样。

##### 包装类型

Rust在经典意义上没有对象继承。然而，Deref特质及其类似物AsRef提供了一种类似继承的机制。这些特质允许您拥有一个类型为T的值，并通过直接在T类型的值上调用它们来调用类型为U的一些方法，前提是T: Deref<Target = U>。这对用户来说感觉像是魔法，通常非常好用。

- 如果您提供了一个相对透明的包装类型（比如Arc），很有可能您希望实现Deref，以便用户可以通过使用点运算符在内部类型上直接调用方法。如果访问内部类型不需要任何复杂或潜在缓慢的逻辑，您还应该考虑实现AsRef，这样用户就可以轻松地将&WrapperType用作&InnerType。对于大多数包装类型，您还应该在可能的情况下实现`From<InnerType>`和`Into<InnerType>`，以便用户可以轻松地添加或删除您的包装。
- 您可能也遇到过Borrow特质，它与Deref和AsRef非常相似，但实际上是一个稍微不同的东西。具体而言，Borrow专为一个更狭窄的用例而设计：允许调用者提供同一类型的多个本质上相同的变体中的任何一个。它可能本可以被称为Equivalent。例如，对于一个`HashSet<String>`，Borrow允许调用者提供&str或&String。虽然使用AsRef也可以实现相同的效果，但如果没有Borrow的额外要求，即目标类型与实现类型完全相同地实现了Hash、Eq和Ord，那将是不安全的。Borrow还为T、&T和&mut T提供了`Borrow<T>`的全局实现，这使得在trait约束中方便地接受给定类型的拥有或引用值。一般来说，Borrow仅适用于当您的类型与另一个类型本质上等效时，而Deref和AsRef则适用于更广泛地实现您的类型可以“扮演”的任何内容。

  **解引用和固有方法**

- 当存在在T上接受self的方法时，点运算符和Deref的魔力可能会变得令人困惑和意外。例如，给定一个值t: T，不清楚t.frobnicate()是对T还是底层的U进行frobnicate！
- 因此，允许您在某个事先未知的内部类型上透明调用方法的类型应避免使用固有方法。对于Vec来说，它有一个push方法是可以的，即使它解引用为一个slice，因为您知道slice不会很快获得push方法。但是，如果您的类型解引用为一个用户可控制的类型，您添加的任何固有方法也可能存在于该用户可控制的类型上，从而引发问题。在这些情况下，更倾向于使用形式为fn frobnicate(t: T)的静态方法。这样，t.frobnicate()总是调用U::frobnicate，而T::frobnicate(t)可以用于对T本身进行frobnicate。
  
#### 灵活性

您编写的每段代码都包含一个合同，无论是隐式还是显式。合同由一组要求和一组承诺组成。要求是对代码使用方式的限制，而承诺是关于代码使用方式的保证。在设计新接口时，您需要仔细考虑这个合同。一个好的经验法则是避免施加不必要的限制，并只做出您能够遵守的承诺。添加限制或删除承诺通常需要进行重大的语义版本更改，并可能会破坏其他地方的代码。另一方面，放宽限制或提供额外的承诺通常是向后兼容的。

- 在Rust中，限制通常以特质约束和参数类型的形式出现，而承诺通常以特质实现和返回类型的形式出现。例如，比较列表3-1中的三个函数签名。

```rust
fn frobnicate1(s: String) -> String
fn frobnicate2(s: &str) -> Cow<'_, str>
fn frobnicate3(s: impl AsRef<str>) -> impl AsRef<str>

```

列表3-1：具有不同合同的相似函数签名

- 这三个函数签名都接受一个字符串并返回一个字符串，但它们在合同上有很大的区别。
- 第一个函数要求调用者拥有字符串，以String类型的形式，它承诺将返回一个拥有的String。由于合同要求调用者分配并要求我们返回一个拥有的String，我们无法以向后兼容的方式使这个函数无需分配。
- 第二个函数放宽了合同：调用者可以提供任何字符串的引用，因此用户不再需要分配或放弃对String的所有权。它还承诺返回一个std::borrow::Cow，这意味着它可以返回一个字符串引用或一个拥有的String，具体取决于它是否需要拥有该字符串。这里的承诺是函数将始终返回一个Cow，这意味着我们不能将其更改为使用其他优化的字符串表示。调用者还必须明确提供一个&str，因此如果他们有一个预先存在的自己的String，他们必须将其解引用为&str来调用我们的函数。
- 第三个函数放宽了这些限制。它只要求用户传入一个可以产生字符串引用的类型，并且只承诺返回值可以产生字符串引用。
- 这些函数签名中没有一个比其他函数更好。如果您需要在函数中拥有一个字符串的所有权，您可以使用第一个参数类型来避免额外的字符串复制。如果您希望允许调用者利用分配和返回的拥有字符串的情况，具有返回类型为Cow的第二个函数可能是一个不错的选择。然而，我希望您从中得出的结论是，您应该仔细考虑您的接口绑定给您的合同，因为事后更改可能会带来破坏性的影响。
- 在本节的其余部分，我将给出一些常见的接口设计决策示例，以及它们对您的接口合同的影响。

##### 泛型参数

您的接口对用户的一个明显要求是他们必须为您的代码提供的类型。如果您的函数明确接受一个Foo，用户必须拥有并提供一个Foo。没有其他办法。在大多数情况下，使用泛型而不是具体类型会更有回报，允许调用者传递符合函数实际需求的任何类型，而不仅仅是特定类型。将列表3-1中的&str更改为`impl AsRef<str>`就是这种放松要求的示例。通过这种方式放宽要求的一种方法是从参数完全泛型且没有约束开始，然后只需按照编译器错误提示添加所需的约束。

- 然而，如果过度使用这种方法，将使每个函数的每个参数都成为自己的泛型类型，这既难以阅读又难以理解。没有确切的硬性规则来确定何时应该或不应该使给定的参数成为泛型类型，所以请根据自己的判断。一个好的经验法则是，如果您可以想到其他类型的用户可能合理且经常地想要使用而不是您最初使用的具体类型，则将参数设置为泛型。
- 你可能还记得第2章中提到的泛型代码通过单态化为每个使用的类型组合而复制。考虑到这一点，让许多参数成为泛型可能会让你担心过度增大你的二进制文件。在第2章中，我们还讨论了如何使用动态分发来减轻这个问题，通常只会带来可忽略的性能损失，在这里也适用。对于你已经以引用方式接受的参数（记住dyn Trait不是Sized，并且你需要一个宽指针来使用它们），你可以轻松地用使用动态分发的参数替换你的泛型参数。例如，你可以使用`&dyn AsRef<str>`来取代`impl AsRef<str>`。
- 在你开始这样做之前，有几件事情你应该考虑。首先，你代表你的用户做出了这个选择，他们无法选择不使用动态分发。如果你知道你应用动态分发的代码永远不会对性能敏感，那可能没问题。但是如果有一个用户想在他们的高性能应用程序中使用你的库，那么在一个热循环中调用的函数中使用动态分发可能会成为一个绊脚石。其次，在撰写本文时，只有当你有一个简单的特质约束，比如`T: AsRef<str>` 或 `impl AsRef<str>`时，使用动态分发才能工作。对于更复杂的约束，Rust 不知道如何构建动态分发的虚函数表，所以你不能使用 &dyn Hash + Eq 这样的约束。最后，请记住，对于泛型，调用者总是可以通过传递一个特质对象来选择动态分发。反之则不成立：如果你接受一个特质对象，那就是调用者必须提供的。
- 可能会诱人的是从具体类型开始定义接口，然后逐渐将其转换为泛型。这样做是可行的，但请记住，这样的更改不一定向后兼容。为了理解原因，想象一下将函数从`fn foo(v: &Vec<usize>)`更改为fn foo(v: impl AsRef<[usize]>). 虽然每个`&Vec<usize>`都实现了AsRef<[usize]>，但类型推断仍然可能对用户造成问题。考虑一下如果调用者使用foo(&iter.collect())调用foo会发生什么。在原始版本中，编译器可以确定它应该收集到一个Vec中，但现在它只知道它需要收集到某种实现了AsRef<[usize]>的类型中。而且可能有多个这样的类型，所以随着这个更改，调用者的代码将无法编译！

##### 对象安全性

当您定义一个新的trait时，无论该trait是否是对象安全的（请参见第2章“编译和调度”的末尾），都是该trait合同的一个未写明的部分。如果该trait是对象安全的，用户可以使用dyn Trait将实现该trait的不同类型视为单个公共类型。如果不是，编译器将禁止对该trait使用dyn Trait。即使这会稍微降低使用它们的人性化程度（例如，使用impl AsRef而不是&str），您也应该更喜欢使您的trait成为对象安全的，因为对象安全使您的trait能够以新的方式使用。如果您的trait必须具有泛型方法，请考虑将其泛型参数放在trait本身上，或者如果其泛型参数也可以使用动态分发来保持trait的对象安全性。或者，您可以为该方法添加一个where Self: Sized的trait约束，这样只能使用trait的具体实例来调用该方法（而不是通过dyn Trait）。您可以在Iterator和Read traits中看到这种模式的示例，它们是对象安全的，但在具体实例上提供了一些额外的便利方法。

- 对于如何牺牲多少来保持对象安全性的问题，没有一个单一的答案。我的建议是考虑您的trait将如何使用，以及用户是否希望将其用作trait对象。如果您认为用户可能希望同时使用许多不同的trait实例，那么您应该更加努力提供对象安全性，而如果您认为这种用例并不太有意义，那么就不需要那么努力。例如，对于FromIterator trait来说，动态分发并不有用，因为它的一个方法不接受self，所以您根本无法构造一个trait对象。同样地，std::io::Seek作为一个单独的trait对象几乎没有用处，因为您只能对这样的trait对象进行seek操作，而无法进行读取或写入。
**DROP TRAIT OBJECTS**
您可能认为Drop特质作为特质对象也是无用的，因为您只能对其进行丢弃操作。但事实证明，有一些库只想能够丢弃任意类型。例如，一个提供延迟丢弃值的库，例如用于并发垃圾回收或延迟清理，只关心值是否可以被丢弃，而不关心其他任何内容。有趣的是，Drop的故事并不止于此；由于Rust需要能够丢弃特质对象，每个虚函数表都包含了drop方法。实际上，每个dyn Trait也是一个dyn Drop。请记住，对象安全性是您的公共接口的一部分！
如果以与向后兼容的方式修改特质，例如通过添加具有默认实现的方法，但这使得特质不再是对象安全的，您需要提升主要语义版本号。

##### 借用 vs 拥有

对于您在Rust中定义的几乎每个函数、特质和类型，您都必须决定它是拥有数据还是仅持有对数据的引用。您所做的决定将对接口的人性化和性能产生深远的影响。
幸运的是，这些决策往往是自然而然的。
如果您编写的代码需要拥有数据的所有权，例如调用需要self的方法或将数据移动到另一个线程中，它必须存储拥有的数据。当您的代码必须拥有数据时，通常也应该要求调用者提供拥有的数据，而不是通过引用并进行克隆。这样做可以让调用者控制分配，并明确了使用相关接口的成本。

- 另一方面，如果您的代码不需要拥有数据，应该使用引用进行操作。一个常见的例外是对于像i32、bool或f64这样的小类型，直接存储和复制与通过引用存储一样廉价。但是要小心假设这对所有Copy类型都成立；[u8; 8192]是Copy的，但是在各个地方存储和复制它会很昂贵。
- 当然，在现实世界中，事情往往没有那么清晰明了。
有时候，您事先不知道您的代码是否需要拥有数据。例如，String::from_utf8_lossy只有在传递给它的字节序列包含无效的UTF-8序列时才需要拥有该字节序列的所有权。在这种情况下，Cow类型是您的朋友：它允许您在数据允许的情况下操作引用，并在必要时生成拥有的值。
- 有时候，引用的生命周期会使接口变得非常复杂，以至于使用起来非常麻烦。如果您的用户在使用您的接口时遇到编译问题，那就意味着您可能需要（即使是不必要地）获取某些数据的所有权。如果这样做，首先从便宜的可克隆数据或不涉及性能敏感的数据开始，然后再决定是否需要堆分配可能是一个巨大的字节块。

##### 可失败和阻塞的析构函数

以I/O为中心的类型在被丢弃时通常需要执行清理操作。这可能包括将写入刷新到磁盘、关闭文件或优雅地终止与远程主机的连接。执行这些清理操作的自然位置是类型的Drop实现。不幸的是，一旦一个值被丢弃，我们就没有办法向用户传达错误，除非通过panic。在异步代码中也会出现类似的问题，我们希望在有待处理的工作时完成。当调用drop时，执行器可能正在关闭，我们无法再做更多的工作。我们可以尝试启动另一个执行器，但这会带来一系列问题，比如在异步代码中阻塞，正如我们将在第8章中看到的那样。

- 对于这些问题，没有完美的解决方案，无论我们做什么，一些应用程序都不可避免地会回退到我们的Drop实现。因此，我们需要通过Drop提供尽力而为的清理。如果清理出现错误，至少我们尝试过-我们会忽略错误并继续执行。如果执行器仍然可用，我们可能会生成一个Future任务来进行清理，但如果它从未运行，我们已经尽力而为了。
- 然而，我们应该为希望不留下任何悬空线程的用户提供更好的选择。我们可以通过提供显式的析构函数来实现这一点。通常，这采用一个接受 self 所有权并公开与销毁相关的任何错误（使用 -> Result<_,_>) 或异步性（使用 async fn）的方法的形式。然后，细心的用户可以使用该方法来优雅地关闭任何相关资源。
**注意** 确保在文档中突出显示显式析构函数！
- 像往常一样，存在权衡。一旦添加了显式析构函数，您将遇到两个问题。首先，由于您的类型实现了Drop，您无法在析构函数中移动该类型的任何字段。这是因为在显式析构函数运行之后，仍然会调用Drop::drop，并且它需要&mut self，这要求self的任何部分都没有被移动。其次，drop接受的是&mut self，而不是self，因此您的Drop实现不能简单地调用显式析构函数并忽略其结果（因为它不拥有self）。有几种方法可以解决这些问题，但没有一种是完美的。
- 第一种方法是将顶层类型作为一个新类型包装器，包装一个Option，而Option又持有一些内部类型，该内部类型持有所有字段。然后，在两个析构函数中都可以使用Option::take，并且仅在内部类型尚未被取走时调用内部类型的显式析构函数。由于内部类型没有实现Drop，因此您可以拥有所有字段的所有权。这种方法的缺点是，您希望在顶层类型上提供的所有方法现在都必须包含代码，以通过Option（您知道始终是Some，因为尚未调用drop）访问内部类型的字段。

- 第二种解决方法是使每个字段可取。您可以通过将其替换为None（这就是Option::take的作用）来“取走”一个Option，但您也可以对许多其他类型执行此操作。例如，您可以通过将它们替换为廉价构造的默认值（std::mem::take在这里很有用）来取走一个Vec或HashMap。如果您的类型具有合理的“空”值，这种方法非常有效，但如果您必须将几乎每个字段都包装在Option中，然后修改对这些字段的每次访问以匹配unwrap，这将变得乏味。
- 第三种选择是将数据保存在ManuallyDrop类型中，该类型解引用为内部类型，因此不需要解包。您还可以在析构时使用ManuallyDrop::take来获取所有权。这种方法的主要缺点是ManuallyDrop::take是不安全的。没有安全机制来确保您在调用take之后不会尝试使用ManuallyDrop内部的值，或者不会多次调用take。如果这样做，您的程序将悄无声息地表现出未定义的行为，并发生糟糕的事情。
- 最终，您应该选择最适合您应用程序的方法。我倾向于选择第二个选项，并只在您发现自己陷入Option的困境时切换到其他选项。如果代码足够简单，您可以轻松检查代码的安全性，并且对自己的能力有信心，那么ManuallyDrop解决方案是非常好的选择。

#### 显而易见的

虽然一些用户可能熟悉支撑接口的实现的某些方面，但他们不太可能了解其所有规则和限制。他们不会知道在调用bar之后调用foo是不允许的，或者只有在月亮处于47度角且过去18秒内没有人打喷嚏时才能安全地调用不安全的方法baz。只有当接口明确表明发生了奇怪的事情时，他们才会查阅文档或仔细阅读类型签名。因此，对于用户来说，理解您的接口尽可能容易，尽可能难以错误使用是至关重要的。为此，您可以利用文档和类型系统这两种主要技术。让我们依次看看每种技术。
**注意** 您还可以利用命名来向用户暗示接口背后可能有更多内容。如果用户看到一个名为dangerous的方法，他们很可能会阅读其文档。

##### 文档

使接口透明的第一步是编写良好的文档。
我可以写一本专门讲如何编写文档的书，
但让我们在这里专注于与Rust相关的建议。

- 首先，清楚地记录您的代码可能会做一些意外的事情的情况，
或者它依赖于用户做一些超出类型签名规定的事情。Panic是这两种情况的一个很好的例子：
如果您的代码可能会panic，请记录这一事实，以及它可能在哪些情况下会panic。
同样，如果您的代码可能返回错误，请记录它返回错误的情况。
对于不安全的函数，请记录调用者必须保证的条件，以使调用安全。
- 其次，在crate和模块级别包含端到端的使用示例。这些示例比特定类型或方法的示例更重要，
因为它们让用户了解整个接口的结构。通过对接口的高层次理解，
开发人员可能很快意识到特定方法和类型的作用以及它们应该在哪里使用。
端到端的示例还为用户提供了定制使用的起点，他们可以复制粘贴示例，然后根据自己的需求进行修改。
这种“边做边学”的方式往往比让他们从组件中拼凑出来更有效。
**注意** 非常特定于方法的示例，显示len方法确实返回长度的示例，
不太可能告诉用户有关您的代码的新信息。

- 第三，组织您的文档。将所有类型、特质和函数放在单个顶层模块中，会让用户很难找到开始的地方。利用模块将语义相关的项分组在一起。然后，使用内部文档链接将这些项相互链接起来。如果类型A的文档中提到了特质B，那么应该在那里链接到该特质。如果让用户能够轻松探索您的接口，他们就不太可能错过重要的关联或依赖关系。还要考虑使用#[doc(hidden)]标记那些不打算公开但出于遗留原因仍然需要的接口部分，以避免在文档中混乱。
- 最后，在可能的情况下丰富您的文档。链接到解释概念、数据结构、算法或其他方面的外部资源，这些资源可能在其他地方有很好的解释。如果有相关的RFC、博客文章和白皮书，那就很好。使用#[doc(cfg(..))]来突出显示仅在某些配置下可用的项，这样用户就能快速意识到为什么文档中列出的某个方法不可用。使用#[doc(alias = "...")]使类型和方法可以通过其他名称进行搜索和发现。在顶层文档中，指导用户常用的模块、特性、类型、特质和方法。

##### 类型系统泛型

类型系统是确保接口明显、自说明和抗误用的优秀工具。您有几种技术可以使接口很难被误用，从而更有可能被正确使用。
其中之一是语义类型化，您可以添加类型来表示值的含义，而不仅仅是其原始类型。这里的经典示例是布尔值：如果您的函数接受三个布尔参数，很有可能某个用户会搞错值的顺序，并在出现严重问题后才意识到。然而，如果它接受三个不同的两变量枚举类型的参数，用户在没有编译器警告的情况下无法搞错顺序：如果他们试图将DryRun::Yes传递给overwrite参数，那将不起作用，将Overwrite::No传递给dry_run参数也是如此。您还可以将语义类型化应用于布尔值以外的情况。例如，围绕数值类型的新类型可以为包含的值提供单位，或者可以将原始指针参数限制为仅限于由另一个方法返回的指针。

- 一个密切相关的技术是使用零大小的类型来表示关于类型实例的特定事实。例如，考虑一个名为Rocket的类型，它表示真实火箭的状态。Rocket上的一些操作（方法）应该在任何状态下都可用，但有些操作只在特定情况下有意义。例如，如果火箭已经发射，就不可能再次发射。同样，如果火箭尚未发射，可能不应该能够分离燃料箱。我们可以将它们建模为枚举变体，但这样所有的方法都会在每个阶段都可用，并且我们需要引入可能的panic。
- 相反，如图3-2所示，我们可以在Rocket上引入一个泛型参数Stage，并使用它来限制在何时可用哪些方法。

```rust
1 struct Grounded;
struct Launched;
// and so on
struct Rocket<Stage = Grounded> {
2 stage: std::marker::PhantomData<Stage>,
}
3 impl Default for Rocket<Grounded> {}
impl Rocket<Grounded> {
pub fn launch(self) -> Rocket<Launched> { }
}
4 impl Rocket<Launched> {
pub fn accelerate(&mut self) { }
pub fn decelerate(&mut self) { }
}
5 impl<Stage> Rocket<Stage> {
pub fn color(&self) -> Color { }
pub fn weight(&self) -> Kilograms { }
}
```

清单3-2：使用标记类型限制实现

- 我们引入了单元类型来表示火箭的每个阶段1。实际上，我们不需要存储阶段-只需要存储它提供的元信息-因此我们使用PhantomData 2将其存储在后面，以确保它在编译时被消除。然后，我们只在Rocket持有特定类型参数时编写实现块。您只能在地面上（目前）构建火箭，并且只能从地面上发射它3。只有在火箭发射后，您才能控制其速度4。无论火箭处于什么状态，您总是可以执行某些操作，这些操作我们放在一个通用的实现块中5。您会注意到，以这种方式设计接口，用户根本无法在错误的时间调用方法-我们已经将使用规则编码到类型本身中，并使非法状态无法表示。

- 这个概念也适用于许多其他领域；如果您的函数忽略一个指针参数，除非给定的布尔参数为true，最好将这两个参数合并在一起。使用一个枚举类型，其中一个变体表示false（没有指针），另一个变体表示true并持有一个指针，既不会让调用者也不会让实现者误解两者之间的关系。这是一个强大的想法，我强烈鼓励您使用它。
- 在使接口明显的过程中，另一个小而有用的工具是#[must_use]注解。将其添加到任何类型、特质或函数上，如果用户的代码接收到该类型或特质的元素，或者调用该函数，并且没有明确处理它，编译器将发出警告。您可能已经在Result的上下文中见过这个注解：如果一个函数返回一个Result，而您没有在某个地方分配其返回值，您将得到一个编译器警告。但要小心不要过度使用这个注解-只有在用户在不使用返回值时很可能犯错误时才添加它。

#### 受限制的

随着时间的推移，一些用户将依赖于您接口的每个属性，无论是错误还是功能。这对于公开可用的库尤其如此，因为您无法控制用户。因此，在进行用户可见的更改之前，您应该仔细考虑。无论是添加新类型、字段、方法还是特质实现，还是更改现有的内容，您都希望确保更改不会破坏现有用户的代码，并且您计划保留该更改一段时间。频繁的不向后兼容的更改（在语义版本控制中的主要版本增加）肯定会引起用户的不满。

- 许多不向后兼容的更改是显而易见的，比如重命名公共类型或删除公共方法，但有些更改更加微妙，并且与Rust的工作方式紧密相关。在这里，我们将介绍一些棘手的微妙更改以及如何为其进行规划。您将看到，您需要在某些情况下权衡这些更改，以及您希望接口有多灵活-有时，必须做出一些让步。

##### 类型修改

删除或重命名公共类型几乎肯定会破坏某些用户的代码。为了应对这个问题，您应该尽可能利用Rust的可见性修饰符，如pub(crate)和pub(in path)。您拥有的公共类型越少，您就越有自由在以后更改事物而不破坏现有代码。
用户代码可以以更多方式依赖于您的类型，而不仅仅是名称。考虑清单3-3中的公共类型以及给定的代码使用。

```rust
// in your interface
pub struct Unit;
// in user code
let u = lib::Unit;
```

清单3-3：一个看似无害的公共类型
现在考虑一下如果给Unit添加一个私有字段会发生什么。即使您添加的字段是私有的，这个更改仍然会破坏用户的代码，因为他们依赖的构造函数已经消失了。类似地，考虑清单3-4中的代码和用法。

```rust
// in your interface
pub struct Unit { pub field: bool };
// in user code
fn is_true(u: lib::Unit) -> bool {
matches!(u, Unit { field: true })
}
```

清单3-4：访问单个公共字段的用户代码
同样，如果给Unit添加一个私有字段，这将破坏用户的代码，因为Rust的完整模式匹配检查逻辑能够看到用户无法看到的接口的部分。它识别出还有更多的字段，即使用户代码无法访问它们，并拒绝用户的模式作为不完整的。如果我们将元组结构体转换为具有命名字段的常规结构体，也会出现类似的问题：即使字段本身完全相同，任何旧的模式对于新的类型定义将不再有效。
Rust提供了#[non_exhaustive]属性来帮助缓解这些问题。您可以将其添加到任何类型定义中，编译器将禁止在该类型上使用隐式构造函数（例如lib::Unit { field1: true }）和非穷尽模式匹配（即没有尾随, ..的模式）。如果您怀疑将来可能修改某个特定类型，这是一个很好的属性添加。但是，它会限制用户代码，例如剥夺用户依赖穷尽模式匹配的能力，因此如果您认为某个类型可能保持稳定，请避免添加该属性。

##### 特质实现

正如您在第2章中所记得的，Rust的一致性规则禁止为给定类型实现给定特质的多个实现。由于我们不知道下游代码可能添加了什么实现，因此为现有特质添加一个全局实现通常是一个破坏性的更改。对于为现有类型实现外部特质或为外部类型实现现有特质，情况也是如此-在这两种情况下，外部特质或类型的所有者可能同时添加一个冲突的实现，因此这必须是一个破坏性的更改。
删除特质实现是一个破坏性的更改，但为新类型实现特质从来不会成为问题，因为没有一个crate可以有与该类型冲突的实现。
也许令人意外的是，您还需要小心为现有类型实现任何特质。为了理解原因，请考虑清单3-5中的代码。

```rust
// crate1 1.0
pub struct Unit;
put trait Foo1 { fn foo(&self) }
// note that Foo1 is not implemented for Unit
// crate2; depends on crate1 1.0
use crate1::{Unit, Foo1};
trait Foo2 { fn foo(&self) }
impl Foo2 for Unit { .. }
fn main() {
Unit.foo();
}
```

清单3-5：为现有类型实现特质可能会引起问题。

- 如果您在crate1中添加了对Unit的impl Foo1的实现，而没有将其标记为破坏性更改，那么下游代码将突然停止编译，因为对foo的调用现在变得模糊不清。即使是对新的公共特质的实现，如果下游crate使用通配符导入（use crate1::*），这种情况也可能发生。如果您提供了一个预导模块，并指示用户使用通配符导入，那么您尤其需要牢记这一点。
- 对现有特质的大多数更改也是破坏性的更改，比如改变方法签名或添加新方法。改变方法签名会破坏所有实现，并且可能会破坏特质的许多使用方式，而添加新方法只是“仅仅”破坏所有实现。但是，添加具有默认实现的新方法是可以的，因为现有的实现将继续适用。
- 我在这里使用“通常”和“大多数”这样的词，因为作为接口作者，我们有一个工具可以帮助我们规避一些规则：封闭特质。封闭特质是一种只能被其他 crate 使用而不能被实现的特质。这立即使得一些破坏性更改变得非破坏性。例如，您可以向封闭特质添加一个新方法，因为您知道在当前 crate 之外没有其他实现需要考虑。同样地，您可以为新的外部类型实现封闭特质，因为您知道定义该类型的外部 crate 不可能添加冲突的实现。
- 封闭特质最常用于派生特质-为实现特定其他特质的类型提供全局实现的特质。只有在不合理的情况下，才应该封闭一个特质，使外部 crate 无法实现它；这严重限制了特质的实用性，因为下游 crate 将无法为其自己的类型实现该特质。您还可以使用封闭特质来限制可以用作类型参数的类型，例如将清单3-2中的 Rocket 示例中的 Stage 类型限制为仅限 Grounded 和 Launched 类型。清单3-6展示了如何封闭一个特质，以及如何在定义 crate 中为其添加实现。

```rust
pub trait CanUseCannotImplement: sealed::Sealed 1 { .. }
mod sealed {
pub trait Sealed {}
2 impl<T> Sealed for T where T: TraitBounds {}
}
impl<T> CanUseCannotImplement for T where T: TraitBounds {}
```

清单3-6：如何封闭一个特质并为其添加实现
诀窍是将一个私有的、空的特质作为要封闭的特质的超特质添加进去1。由于超特质在一个私有模块中，其他 crate 无法访问它，因此也无法实现它。封闭特质要求底层类型实现 Sealed，因此只有我们明确允许的类型2才能最终实现该特质。
**注意**：如果您以这种方式封闭一个特质，请确保记录下这个事实，以免用户尝试自己实现该特质而感到沮丧！

##### 隐藏的约定

有时，您对代码的某一部分所做的更改会以微妙的方式影响接口中的其他部分的约定。这种情况主要发生在重新导出和自动特质中。
**重新导出**

如果您的接口的任何部分暴露了外部类型，那么对其中一个外部类型的任何更改也是对您的接口的更改。例如，考虑一下如果您将依赖项的新主要版本作为迭代器类型暴露在您的接口中会发生什么。依赖于您接口的用户可能还直接依赖于该依赖项，并期望您接口提供的类型与该依赖项中同名的类型相同。但是，如果您更改了依赖项的主要版本，即使类型的名称相同，这也不再成立。

清单3-7展示了一个例子。

```rust
// your crate: bestiter
pub fn iter<T>() -> itercrate::Empty<T> { .. }
// their crate
struct EmptyIterator { it: itercrate::Empty<()> }

EmptyIterator { it: bestiter::iter() }
```

清单3-7：重新导出使外部 crate 成为接口契约的一部分。

- 如果您的 crate 从 itercrate 1.0 移动到 itercrate 2.0，但其他方面没有改变，那么此清单中的代码将不再编译。即使没有更改任何类型，编译器也认为（正确地）itercrate1.0::Empty 和 itercrate2.0::Empty 是不同的类型。因此，您无法将后者赋值给前者，这使得这个接口的更改是破坏性的。
- 为了缓解这类问题，通常最好使用新类型模式对外部类型进行封装，然后仅暴露您认为有用的外部类型的部分。在许多情况下，您可以通过使用impl Trait来为调用方提供仅最小的合约，从而完全避免使用新类型包装器。通过承诺更少，您可以减少破坏性的更改。
**语义版本控制技巧**
- - itercrate的例子可能让您感到不舒服。如果Empty类型没有改变，那么为什么编译器不允许使用它的任何代码继续工作，无论代码是使用版本1.0还是2.0？答案是...复杂的。归根结底，这是因为Rust编译器不会假设只因为两个类型具有相同的字段，它们就是相同的类型。举个简单的例子，假设itercrate 2.0为Empty添加了`#[derive(Copy)]`。现在，这个类型在使用1.0或2.0时具有不同的移动语义！而针对其中一个版本编写的代码将无法与另一个版本一起工作。
- - 这个问题往往在大型、广泛使用的库中出现，在这些库中，随着时间的推移，破坏性的更改很可能发生在 crate 的某个地方。不幸的是，语义化版本控制是在 crate 级别上进行的，而不是类型级别上进行的，因此任何地方的破坏性更改都是全局的破坏性更改。
- - 但并非一切都失去了。几年前，David Tolnay（serde的作者，以及其他大量Rust贡献的作者）提出了一个巧妙的技巧来处理这种情况。他称之为“语义版本技巧”。这个想法很简单：如果某个类型T在破坏性更改（从1.0到2.0）之后保持不变，那么在发布2.0之后，您可以发布一个新的1.0次要版本，该版本依赖于2.0，并用来自2.0的T重新导出替换T。

- - 通过这样做，您确保在两个主要版本之间只有一个类型T。这反过来意味着依赖于1.0的任何crate都可以使用来自2.0的T，反之亦然。而且，由于这仅适用于您使用此技巧明确选择的类型，实际上是破坏性的更改将继续存在。

##### 自动特质

Rust拥有一些特质，根据类型的内容自动为每个类型实现。对于本讨论而言，最相关的是Send和Sync，尽管Unpin、Sized和UnwindSafe特质也存在类似的问题。根据它们的本质，这些特质为您的接口中几乎每个类型添加了一个隐藏的承诺。这些特质甚至会传播到像impl Trait这样的类型擦除类型中。

- 这些特质的实现（通常）由编译器自动添加，但这也意味着如果它们不再适用，它们将不会自动添加。因此，如果您有一个包含私有类型B的公共类型A，并且您更改B以使其不再是Send，那么A现在也不再是Send。这是一个破坏性的更改！
- 这些更改很难跟踪，并且通常直到接口的用户抱怨他们的代码不再工作时才会发现。为了在发生之前捕捉到这些情况，最好在测试套件中包含一些简单的测试，检查所有类型是否按照您的预期实现了这些特质。清单3-8给出了一个这样的测试的示例。

```rust
fn is_normal<T: Sized + Send + Sync + Unpin>() {}
#[test]
fn normal_types() {
is_normal::<MyType>();
}
```

清单3-8：测试类型是否实现了一组特质

- **注意**，这个测试不运行任何代码，只是测试代码是否编译通过。如果MyType不再实现Sync，测试代码将无法编译，您将知道刚刚进行的更改破坏了自动特质的实现。
**隐藏文档中的项目**
`#[doc(hidden)] 属性`允许您在文档中隐藏公共项目，而不会使其对知道其存在的代码不可访问。这通常用于公开宏所需的方法和类型，但不用于用户代码。隐藏的项目与接口契约的交互方式存在一些争议。一般来说，标记为#[doc(hidden)]的项目只在其公共影响方面被视为接口契约的一部分；例如，如果用户代码可能包含一个隐藏的类型，那么该类型是否是Send是契约的一部分，而其名称则不是。隐藏的内在方法和封闭特质上的隐藏特质方法通常不是接口契约的一部分，但您应确保在这些方法的文档中明确说明这一点。是的，隐藏的项目仍然应该被记录在文档中！

#### Summary

在本章中，我们探讨了设计Rust接口的许多方面，无论是用于外部使用还是作为您的crate中不同模块之间的抽象边界。我们涵盖了许多具体的陷阱和技巧，但最终，高级原则应该指导您的思考：您的接口应该是不令人惊讶、灵活、明显和受限制的。在下一章中，我们将深入探讨如何在Rust代码中表示和处理错误。

### 4.错误处理

对于除了最简单的程序之外，您将会有可能失败的方法。在本章中，我们将探讨表示、处理和传播这些失败的不同方式，以及每种方式的优点和缺点。我们将首先探讨不同的错误表示方式，包括枚举和擦除，然后研究一些需要不同表示技术的特殊错误情况。接下来，我们将看一些处理错误的方法以及错误处理的Future发展方向。
值得注意的是，Rust中的错误处理最佳实践仍然是一个活跃的讨论话题，在撰写本文时，生态系统尚未就单一统一的方法达成一致。因此，本章将重点介绍基本原则和技术，而不是推荐特定的crate或模式。

#### 表示错误

当你编写可能失败的代码时，最重要的问题是要问自己的是用户将如何与返回的任何错误进行交互。用户是否需要知道确切发生了哪个错误以及出了什么问题的细节，还是他们只需记录错误发生并尽力继续进行？为了理解这一点，我们必须看看错误的性质是否可能影响调用者在接收到错误时的操作。这反过来将决定我们如何表示不同的错误。

- 表示错误有两种主要选项：枚举和擦除。也就是说，您可以让错误类型枚举可能的错误条件，以便调用者可以区分它们，或者您可以只向调用者提供一个不透明的错误。让我们依次讨论这两个选项。

##### 枚举

对于我们的示例，我们将使用一个库函数，该函数将字节从某个输入流复制到某个输出流，类似于std::io::copy。用户提供两个流，一个用于读取，一个用于写入，您将字节从一个流复制到另一个流。在此过程中，任何一个流都有可能失败，此时复制过程必须停止并向用户返回错误。在这种情况下，用户可能想知道是输入流还是输出流发生了错误。例如，在Web服务器中，如果在向客户端流式传输文件时发生输入流错误，可能是因为磁盘被弹出，而如果输出流发生错误，可能是客户端断开连接。后者可能是服务器应该忽略的错误，因为可以继续将数据复制到新的连接，而前者可能需要整个服务器关闭！

这是一个我们希望枚举错误的情况。用户需要能够区分不同的错误情况，以便能够适当地做出响应，因此我们使用了一个名为CopyError的枚举，其中每个变体表示错误的不同根本原因，就像在清单4-1中所示。

```rust
pub enum CopyError {
In(std::io::Error),
Out(std::io::Error),
}
```

清单4-1：一个枚举的错误类型

- 每个变体还包括遇到的错误，以尽可能提供给调用者有关出错的详细信息。
- 当创建自己的错误类型时，您需要采取一些步骤，使错误类型与Rust生态系统的其他部分良好地协同工作。首先，您的错误类型应实现std::error::Error trait，该trait为调用者提供了用于检查错误类型的常用方法。最感兴趣的主要方法是Error::source，它提供了一种查找错误根本原因的机制。这通常用于打印回溯，显示一直追溯到错误的根本原因。对于我们的CopyError类型，source的实现很简单：我们匹配self并提取并返回内部的std::io::Error。
- 第二，您的类型应该实现Display和Debug，以便调用者可以有意义地打印您的错误。如果您实现了Error trait，则需要这样做。一般来说，您的Display实现应该提供一个简短的描述，说明出了什么问题，可以轻松地与其他错误消息合并。显示格式应该是小写的，不带尾部标点符号，以便它可以很好地适应其他更大的错误报告。Debug应该提供更详细的错误信息，包括可能有助于追踪错误原因的辅助信息，例如端口号、请求标识符、文件路径等。通常，使用#[derive(Debug)]就足够了。
**注意** 在旧的 Rust 代码中，您可能会看到对 Error::description 方法的引用，但这已被弃用，推荐使用 Display。
- 第三，如果可能的话，您的类型应该实现Send和Sync，以便用户能够在线程边界上共享错误。如果您的错误类型不是线程安全的，那么在多线程环境中几乎不可能使用您的crate。实现Send和Sync的错误类型也更容易与非常常见的std::io::Error类型一起使用，该类型能够包装实现Error、Send和Sync的错误。当然，并非所有的错误类型都可以合理地实现Send和Sync，比如如果它们与特定的线程本地资源相关联，那就没关系。您可能也不会将这些错误发送到线程边界之外。然而，在将Rc<String>和RefCell<bool>类型放入错误中之前，这是需要注意的事项。
- 最后，如果可能的话，您的错误类型应该是 'static。这样做的最直接好处是，它使调用者更容易将您的错误传播到调用堆栈上，而不会遇到生命周期问题。它还使您的错误类型更容易与类型擦除的错误类型一起使用，我们很快就会看到。

##### 不透明错误

现在让我们考虑一个不同的例子：一个图像解码库。您将一堆字节提供给库进行解码，并且库会为您提供各种图像操作方法。如果解码失败，用户需要能够找出如何解决问题，因此必须了解失败的原因。但是，是否重要的是原因是图像头中的大小字段无效，还是压缩算法无法解压缩块？可能不重要 - 即使应用程序知道确切的原因，也无法有意义地从任何一种情况中恢复。在这种情况下，作为库的作者，您可能希望提供单个不透明的错误类型。这也使得您的库更易于使用，因为在任何地方都只使用一个错误类型。此错误类型应实现Send、Debug、Display和Error（包括适当的source方法），但除此之外，调用者不需要了解更多信息。您可能在内部表示更细粒度的错误状态，但没有必要将其暴露给库的用户。这样做只会增加API的大小和复杂性，没有任何好处。

- 确定不透明错误类型的具体形式主要取决于您。它可以是一个具有所有私有字段的类型，仅公开有限的用于显示和检查错误的方法，或者它可以是一个严重类型擦除的错误类型，如Box<dyn Error + Send + Sync + 'static>，它只透露它是一个错误，通常不允许用户进行内省。决定将错误类型设置为多么不透明主要取决于错误是否除了其描述之外还有其他有趣的内容。使用`Box<dyn Error>`，您只能将错误向上传递给用户。如果它确实没有任何有价值的信息要向用户呈现，那可能没问题，例如，如果它只是一个动态错误消息或来自程序内部更深层次的大量不相关错误之一。但是，如果错误具有一些有趣的方面，例如行号或状态码，您可能希望通过一个具体但不透明的类型来公开它。
**注意** 一般来说，社区共识是错误应该很少发生，因此不应该对“正常路径”增加太多成本。因此，错误通常被放置在指针类型（如Box或Arc）后面。这样，它们不太可能对它们所包含的整体Result类型的大小产生太大影响。
- 使用类型擦除错误的一个好处是，它允许您轻松地组合来自不同来源的错误，而无需引入额外的错误类型。也就是说，类型擦除错误通常可以很好地组合，并允许您表示一组开放的错误。如果您编写的函数的返回类型是`Box<dyn Error + ...>`，那么您可以在该函数内部使用`?`处理不同类型的错误，这些错误可能来自各种不同的错误，并且它们都将转换为相同的错误类型。
- 在擦除的上下文中，Box<dyn Error + Send + Sync + 'static> 上的 'static 约束值得花更多时间来讨论。我在前一节中提到，它对于让调用者传播错误而不必担心失败的方法的生命周期边界非常有用，但它还有一个更重要的目的：访问 downcasting。Downcasting 是将一个类型的项转换为更具体类型的过程。这是 Rust 提供的少数几种可以在运行时访问类型信息的情况之一；它是动态语言通常提供的更一般类型反射的有限情况。在错误的上下文中，downcasting 允许用户将 dyn Error 转换为原始的具体错误类型，前提是该 dyn Error 最初就是该类型。例如，用户可能希望在收到的错误是 std::io::Error 类型的 std::io::ErrorKind::WouldBlock 时采取特定的操作，但在其他情况下不采取相同的操作。如果用户得到了 dyn Error，他们可以使用 Error::downcast_ref 尝试将错误向下转换为 std::io::Error。downcast_ref 方法返回一个 Option，告诉用户 downcast 是否成功。这里的关键观察是：downcast_ref 仅在参数是 'static 的情况下起作用。如果我们返回一个不是 'static 的不透明错误，我们就剥夺了用户进行这种错误内省的能力，即使他们希望这样做。
- 在生态系统中，关于库的类型擦除错误（或更一般地说，类型擦除类型）是否属于其公共和稳定的API存在一些争议。也就是说，如果您的库中的方法foo返回一个`Box<dyn Error>`作为lib::MyError，将foo更改为返回不同的错误类型是否会导致破坏性更改？类型签名没有改变，但用户可能已经编写了假设他们可以使用downcast将该错误转换回lib::MyError的代码。我对此问题的观点是，您选择返回`Box<dyn Error>`（而不是lib::MyError）是有原因的，并且除非明确记录，否则不保证downcasting方面的任何特定内容。

**注意**，虽然`Box<dyn Error + ...>` 是一种吸引人的类型擦除错误类型，但它本身并没有实现 Error。因此，在实现了 Error 的库中，考虑添加自己的 BoxError 类型以进行类型擦除。你可能会想知道 Error::downcast_ref 如何安全地工作。也就是说，它如何知道提供的 dyn Error 参数是否确实是给定的类型 T？标准库甚至有一个叫做 Any 的 trait，它对任何类型都实现了，并且为 dyn Any 实现了 downcast_ref ——这怎么可能没问题呢？答案在于编译器支持的类型 std::any::TypeId，它允许你为任何类型获取一个唯一的标识符。Error trait 有一个隐藏的提供的方法叫做 type_id，默认实现是返回 `TypeId::of::<Self>()`。类似地，Any 有一个针对 T 的通用实现 impl Any for T，在该实现中，它的 type_id 返回相同的值。在这些 impl 块的上下文中，Self 的具体类型是已知的，所以这个 type_id 就是真实类型的类型标识符。这提供了 downcast_ref 需要的所有信息。downcast_ref 调用 self.type_id，通过动态大小类型的虚函数表（参见第2章）转发到底层类型的实现，并将其与提供的 downcast 类型的类型标识符进行比较。如果它们匹配，那么 dyn Error 或 dyn Any 后面的类型确实是 T，从一个引用到另一个引用的转换是安全的。

##### 特殊错误情况

有些函数可能会失败，但如果它们失败了，就无法返回任何有意义的错误。从概念上讲，这些函数的返回类型是 Result<T, ()>。在某些代码库中，您可能会看到它表示为 Option<T>。虽然这两种选择都是合法的函数返回类型，但它们传达了不同的语义含义，通常应避免将 Result<T, ()> “简化”为 Option<T>。Err(()) 表示操作失败，应该重试、报告或以其他方式进行特殊处理。另一方面，None 只表示函数没有返回值；通常不被视为异常情况或需要处理的情况。您可以在 Result 类型上看到 #[must_use] 注解 - 当您获得一个 Result 时，语言期望您重视处理两种情况，而对于 Option，实际上不需要处理任何一种情况。

**注意** 还要记住，`()` 不实现 `Error` 特质。这意味着它不能被类型擦除为 `Box<dyn Error>`，并且在使用 `?` 时可能会有些麻烦。因此，在这些情况下，通常最好定义自己的单元结构类型，为其实现 `Error`，并将其作为错误类型，而不是使用 `()`。

- 有些函数，比如那些启动一个持续运行的服务器循环的函数，只会返回错误；除非发生错误，它们会一直运行。其他一些函数永远不会出错，但仍然需要返回一个Result，例如为了匹配一个trait的签名。对于这样的函数，Rust提供了never类型，使用!语法来表示。never类型表示一个永远不会生成的值。你不能自己构造这种类型的实例——唯一的方法是进入一个无限循环或者panic，或者通过一些其他特殊的操作，编译器知道这些操作永远不会返回。对于Result来说，当你有一个你知道永远不会被使用的Ok或Err时，你可以将其设置为!类型。如果你编写一个返回Result<T, !>的函数，你将无法返回Err，因为唯一的方法是进入永远不会返回的代码。因为编译器知道任何包含!的变体永远不会被生成，所以它也可以根据这一点对你的代码进行优化，比如在Result<T, !>上的unwrap不会生成panic代码。而且当你进行模式匹配时，编译器知道任何包含!的变体甚至不需要列出。非常巧妙！
- 最后一个奇特的错误类型是std::thread::Result。这是它的定义：

```rust
type Result<T> = Result<T, Box<dyn Any + Send + 'static>>;

```

错误类型是类型擦除的，但它并不像我们之前看到的那样被擦除为dyn Error。相反，它是一个dyn Any，它只保证错误是某种类型，没有更多的信息...这并不是一个很好的保证。这个奇怪的错误类型之所以存在，是因为std::thread::Result的错误变体只在发生panic时产生；具体来说，如果您尝试加入一个已经panic的线程。在这种情况下，加入线程除了忽略错误或使用unwrap自己发生panic之外，似乎没有其他什么可以做的。本质上，错误类型是“一个panic”，值是“传递给panic!的任何参数”，它确实可以是任何类型（尽管通常是格式化的字符串）。

##### 传播错误

Rust的?运算符是unwrap或提前返回的简写形式，用于轻松处理错误。但它还有一些其他值得了解的技巧。首先，?通过From trait执行类型转换。在返回Result<T, E>的函数中，您可以在任何Result<T, X>上使用?，其中E: From<X>。这就是使通过Box<dyn Error>进行错误擦除如此吸引人的特性；您可以随处使用?，而不用担心特定的错误类型，它通常会“正常工作”。

**FROM AND INTO**

标准库中有许多转换特质，但其中两个核心特质是 From 和 Into。如果我们有了 From，为什么还需要 Into，反之亦然，这可能让你感到奇怪。有几个原因，但让我们从历史原因开始：由于第2章中讨论的一致性规则，早期的 Rust 不可能只有一个特质。或者更具体地说，一致性规则曾经是什么样子。

- 假设您想在您的crate中实现某个本地类型与标准库中某个类型之间的双向转换。您可以很容易地编写`impl<T> From<Vec<T>> for MyType<T>`和`impl<T> Into<Vec<T>> for MyType<T>`，但如果您只有From或Into，您将不得不编写`impl<T> From<MyType<T>> for Vec<T>`或`impl<T> Into<MyType<T>> for Vec<T>`。然而，编译器过去会拒绝这些实现！只有在Rust 1.41.0之后，当为覆盖类型添加了一项例外规则到一致性规则中时，它们才合法。在那个改变之前，必须同时具备这两个特质。由于大部分Rust代码是在Rust 1.41.0之前编写的，现在无法删除任何一个特质。

- 除了这个历史事实之外，还有一些良好的人机工程学原因，即使我们今天可以从头开始，也要同时拥有这两个特质。在不同的情况下，使用其中一个特质通常要容易得多。例如，如果您正在编写一个接受可以转换为Foo的类型的方法，您是希望编写fn(impl Into<Foo>)还是fn<T>(T) where Foo: From<T>？相反地，要将字符串转换为语法标识符，您是希望编写Ident::from("foo")还是<_ as Into<Ident>>::into("foo")？这两个特质都有各自的用途，我们最好同时拥有它们。
- 鉴于我们两者都有，您可能想知道在您的代码中应该使用哪个。事实证明，答案非常简单：实现From，并在边界中使用Into。原因是Into对于任何实现了From的T都有一个默认实现，所以无论类型是否显式实现了From或Into，它都实现了Into！
- 当然，就像简单的事情经常发生的那样，故事并没有就此结束。由于编译器在使用Into作为约束时通常需要“穿过”泛型实现，判断一个类型是否实现了Into比实现From更复杂。在某些情况下，编译器并不聪明到足以解决这个难题。因此，在撰写本文时，?运算符使用的是From而不是Into。大多数情况下，这并没有什么区别，因为大多数类型都实现了From，但这意味着旧库中实现了Into而不是From的错误类型可能无法与?一起使用。随着编译器变得更加智能，?可能会“升级”为使用Into，这样问题就会消失，但目前我们只能这样。

- ?的第二个要注意的方面是，这个操作符实际上只是一个被暂时称为Try的特质的语法糖。在撰写本文时，Try特质尚未稳定，但在您阅读本文时，很可能已经确定了它或类似的东西。由于细节尚未完全确定，我只会给出Try如何工作的概要，而不是完整的方法签名。在本质上，Try定义了一个包装类型，其状态要么是进一步计算有用的（即happy path），要么是不可用的。其中一些人可能会正确地想到monad，尽管我们不会在这里探讨这种联系。例如，在Result<T, E>的情况下，如果你有一个Ok(t)，你可以通过解包t继续happy path。另一方面，如果你有一个Err(e)，你希望立即停止执行并产生错误值，因为你没有t，所以无法进行进一步的计算。
- 有趣的是，Try适用于更多类型，而不仅仅是Result。例如，Option<T>遵循相同的模式 - 如果你有一个Some(t)，你可以继续在happy path上，而如果你有一个None，你希望返回None而不是继续。这种模式扩展到更复杂的类型，比如Poll<Result<T, E>>，其happy path类型是Poll<T>，这使得?适用于更多情况。当Try稳定下来时，我们可能会看到?开始与各种类型一起工作，使我们的happy path代码更加优雅。

- ?运算符已经可以在可失败函数、doctest和fn main中使用。然而，为了发挥其全部潜力，我们还需要一种方式来限定这种错误处理的范围。例如，考虑列表4-2中的函数。

```rust
fn do_the_thing() -> Result<(), Error> {
    let thing = Thing::setup()?;
    // .. code that uses thing and ? ..
    thing.cleanup();
    Ok(())
}
```

清单4-2：使用?运算符的多步骤可失败函数
这不会按预期工作。在setup和cleanup之间的任何?都会导致整个函数提前返回，从而跳过清理代码！这是try块旨在解决的问题。try块的行为几乎类似于单次迭代循环，其中?使用break而不是return，并且块的最后一个表达式具有隐式的break。我们现在可以修复清单4-2中的代码，以始终执行清理操作，如清单4-3所示。

```rust
fn do_the_thing() -> Result<(), Error> {
    let thing = Thing::setup()?;
    let r = try {
        // .. code that uses thing and ? ..
    };
    thing.cleanup();
    r
}
```

清单4-3：一个多步骤的可失败函数，总是在完成后进行清理

在撰写本文时，try块还不稳定，但是对于它们的有用性已经达成了足够的共识，它们很可能以类似于此处描述的形式出现。

#### 总结

本章介绍了在Rust中构建错误类型的两种主要方法：枚举和擦除。我们讨论了何时使用每种方法以及每种方法的优点和缺点。我们还深入探讨了?运算符的一些幕后细节，并考虑了?在Future可能变得更加有用的情况。在下一章中，我们将从代码中退后一步，看看如何组织一个Rust项目。我们将讨论特性标志、依赖管理和版本控制，以及如何使用工作区和子模块来管理更复杂的crate。我们在下一页见！

### 5.项目结构

本章提供了一些关于组织Rust项目的思路。对于简单的项目，由cargo new设置的结构可能是你很少考虑的事情。你可以添加一些模块来拆分代码，添加一些依赖来增加功能，但仅此而已。然而，随着项目的规模和复杂性的增长，你会发现需要超越这个范围。也许你的crate的编译时间过长，或者你需要条件依赖，或者你需要更好的持续集成策略。在本章中，我们将介绍一些Rust语言和Cargo提供的工具，这些工具可以更轻松地管理这些问题。

#### 特性

特性是Rust中定制项目的主要工具。在其核心，特性只是一个构建标志，crate可以传递给它们的依赖项，以添加可选功能。特性本身没有语义意义-相反，您可以选择为您的crate定义特性的含义。

- 通常，我们使用特性有三种方式：启用可选依赖项，有条件地包含 crate 的其他组件，以及增强代码的行为。请注意，所有这些用法都是累加的；特性可以增加 crate 的功能，但通常不应该删除模块或替换类型或函数签名。这源于一个原则，即如果开发人员对他们的 Cargo.toml 进行简单的更改，比如添加一个新的依赖项或启用一个特性，那么这不应该导致他们的 crate 停止编译。如果一个 crate 有互斥的特性，这个原则很快就会被抛弃——如果 crate A 依赖于 crate C 的一个特性，而 crate B 依赖于 C 的另一个互斥特性，那么添加对 crate B 的依赖将会破坏 crate A！因此，我们通常遵循这样的原则：如果 crate A 在某个特性集上编译通过了 crate C，那么在 crate C 上启用所有特性时，它也应该能够编译通过。
- Cargo非常强调这个原则。例如，如果两个crate（A和B）都依赖于crate C，但它们分别在C上启用了不同的特性，Cargo只会编译一次crate C，并使用A或B所需的所有特性。也就是说，它会对A和B对C请求的特性取并集。因此，向Rust crate添加互斥特性通常很困难；很有可能有两个依赖项会依赖于具有不同特性的crate，如果这些特性是互斥的，那么下游crate将无法构建。

**注意** 我强烈建议您配置持续集成基础设施，以检查您的crate在其特性的任何组合下是否编译通过。一个帮助您完成这个任务的工具是cargo-hack，您可以在<https://github.com/taiki-e/cargo-hack/>找到。

##### 定义和包含特性

特性是在Cargo.toml中定义的。清单5-1展示了一个名为foo的crate的示例，其中包含一个简单的特性，用于启用可选依赖syn。

```toml
[package]
name = "foo"
...
[features]
derive = ["syn"]
[dependencies]
syn = { version = "1", optional = true }
```

清单5-1：启用可选依赖项的特性
当Cargo编译这个crate时，默认情况下不会编译syn crate，这样可以减少编译时间（通常会显著减少）。只有当下游crate需要使用由derive特性启用的API，并明确选择启用它时，syn crate才会被编译。清单5-2展示了这样一个下游crate bar如何启用derive特性，并包含syn依赖项。

```toml
[package]
name = "bar"
...
[dependencies]
foo = { version = "1", features = ["derive"] }
```

清单5-2：启用依赖项的特性

- 有些特性使用得非常频繁，因此更合理的做法是让一个crate选择性地禁用它们，而不是选择性地启用它们。为了支持这一点，Cargo允许您为一个crate定义一组默认特性。同样地，它也允许您选择性地禁用依赖项的默认特性。清单5-3展示了foo如何使其derive特性默认启用，并选择性地禁用syn的一些默认特性，而只启用它所需的用于derive特性的特性。

```toml
[package]
name = "foo"
...
[features]
derive = ["syn"]
default = ["derive"]
[dependencies.syn]
version = "1"
default-features = false
features = ["derive", "parsing", "printing"]
optional = true
```

清单5-3：添加和选择性禁用默认特性，以及可选依赖项

- 在这里，如果一个crate依赖于foo，并且没有明确选择禁用默认特性，它将编译foo的syn依赖项。反过来，syn将只使用列出的三个特性进行构建，而不使用其他特性。通过这种方式选择禁用默认特性，并仅选择您需要的特性，是减少编译时间的好方法！

**将可选依赖项作为特性**

当您定义一个特性时，等号后面的列表本身就是一个特性列表。这可能一开始听起来有点奇怪-在清单5-3中，syn是一个依赖项，而不是一个特性。事实证明，Cargo将每个可选依赖项都作为具有相同名称的特性。如果您尝试添加与可选依赖项同名的特性，您将看到这一点；Cargo不会允许这样做。在Cargo中，特性和依赖项的不同命名空间的支持正在进行中，但在撰写本文时尚未稳定。与此同时，如果您想要一个以依赖项命名的特性，您可以使用package = ""重命名依赖项，以避免名称冲突。特性启用的特性列表还可以包括依赖项的特性。

- 例如，您可以编写 derive = ["syn/derive"] 来使您的 derive 特性启用 syn 依赖项的 derive 特性。

##### 在您的crate中使用特性

在使用特性时，您需要确保您的代码仅在依赖可用时使用。如果您的特性启用了特定的组件，您需要确保如果特性未启用，则不包含该组件。

- 你可以使用条件编译来实现这一点，它允许你使用注解来给出特定代码在何种条件下应该或不应该被编译。条件编译主要通过 #[cfg] 属性来表达。还有一个紧密相关的 cfg! 宏，它允许你根据类似的条件来改变运行时行为。你可以用条件编译做很多有趣的事情，我们将在本章后面看到，但最基本的形式是 #[cfg(feature = "some-feature")]，它使得源代码中的下一个“东西”只在启用了 some-feature 特性时才被编译。类似地，如果 cfg!(feature = "some-feature") 等价于 if true，只有在启用了 derive 特性时（否则为 false）。
- `#[cfg]`属性比cfg!宏更常用，因为宏根据特性修改运行时行为，这可能会导致难以确保特性是可添加的。您可以将#[cfg]放在某些Rust项（如函数和类型定义、impl块、模块和use语句）以及某些其他结构（如结构体字段、函数参数和语句）之前。但是，#[cfg]属性不能随意放置；Rust语言团队精心限制了它的出现位置，以避免条件编译引发过于奇怪和难以调试的情况。
- 请记住，修改API的某些公共部分可能会意外地使特性不可添加，从而使一些用户无法编译您的crate。在这里，您通常可以使用向后兼容更改的规则作为经验法则-例如，如果您将枚举变体或公共结构字段条件化为一个特性，那么该类型也必须用#[non_exhaustive]进行注解。否则，如果由于依赖树中的第二个crate添加了该特性，没有启用该特性的依赖crate可能无法再编译。
**注意** 如果您正在编写一个大型的crate，您预计用户只需要其中的一部分功能，那么您应该考虑通过特性来保护较大的组件（通常是模块）。这样，用户可以选择性地启用他们真正需要的部分，并支付编译的成本。

#### 工作区

在Rust中，crate扮演着多种角色——它们是依赖关系图中的顶点，是特质一致性的边界，也是编译特性的作用域。因此，每个crate都被视为一个单独的编译单元；Rust编译器将一个crate几乎视为一个大的源文件，作为一个整体进行编译，并最终转换为单个二进制输出（可以是可执行文件或库）。

- 虽然这简化了编译器的许多方面，但也意味着处理大型 crate 可能会很困难。如果您对应用程序的某个部分进行了单元测试、注释或类型的更改，编译器必须重新评估整个 crate，以确定是否有任何更改。在内部，编译器实现了许多机制来加速这个过程，比如增量重新编译和并行代码生成，但最终您的 crate 的大小是确定项目编译时间的一个重要因素。
- 因此，随着项目的增长，您可能希望将其拆分为相互依赖的多个crate。Cargo正好有一个方便的功能来实现这一点：工作区。工作区是一组crate（通常称为子crate），它们由顶层的Cargo.toml文件绑定在一起，如清单5-4所示。

```toml
[workspace]
members = [
"foo",
"bar/one",
"bar/two",
]
```

清单5-4：工作区的 Cargo.toml

- members 数组是一个包含工作区中每个 crate 的目录列表。这些 crate 都有自己的 Cargo.toml 文件在自己的子目录中，但它们共享一个单独的 Cargo.lock 文件和一个单独的输出目录。crate 的名称不需要与 members 中的条目匹配。通常情况下，工作区中的 crate 具有相同的名称前缀，通常选择为“主”crate 的名称。例如，在 tokio crate 中，成员被称为 tokio、tokio-test、tokio-macros 等等。
- 工作区最重要的特性之一是您可以在工作区的根目录中通过调用 cargo 与所有工作区成员进行交互。想要检查它们是否都编译通过？cargo check 将检查它们全部。想要运行所有测试？cargo test 将测试它们全部。虽然不像将所有内容放在一个 crate 中那样方便，所以不要将所有内容拆分成微小的 crate，但这是一个相当好的近似。
**注意** 在工作区中，Cargo 命令通常会做“正确的事情”。如果您需要消除歧义，例如如果两个工作区 crate 都有相同名称的二进制文件，请使用 -p 标志（用于 package）。如果您在特定工作区 crate 的子目录中，可以传递 --workspace 来执行整个工作区的命令。
- 一旦您在工作区级别的 Cargo.toml 文件中设置了工作区成员的数组，您可以使用路径依赖关系来使您的 crate 互相依赖，如清单5-5所示。

```toml
# bar/two/Cargo.toml
[dependencies]
one = { path = "../one" }
# bar/one/Cargo.toml
[dependencies]
foo = { path = "../../foo" }
```

清单5-5：工作区中的crate之间的依赖关系

- 现在，如果您对bar/two中的crate进行更改，那么只有该crate会重新编译，因为foo和bar/one没有更改。甚至从头编译项目可能会更快，因为编译器不需要评估整个项目源代码以寻找优化机会。

**指定工作区内部的依赖关系**
在工作区中，最明显的指定一个crate依赖于另一个crate的方法是使用路径指定符，如清单5-5所示。然而，如果您的子crate是为公共使用而设计的，您可能希望使用版本指定符。

- 假设您有一个crate依赖于清单5-5中bar工作区中的一个crate的Git版本，使用one = { git = ". . ." }，以及一个已发布的foo版本（也来自bar），使用foo = "1.0.0"。Cargo将会忠实地获取one的Git仓库，该仓库包含整个bar工作区，并且会看到one依赖于foo，位于工作区内的../../foo。但是Cargo不知道已发布的版本foo = "1.0.0"和Git仓库中的foo是同一个crate！它将它们视为两个独立的依赖项，只是碰巧具有相同的名称。

- 你可能已经看到了这个问题的所在。如果你尝试使用来自 foo（1.0.0）的任何类型与一个接受来自 foo 的类型的 API，编译器将拒绝该代码。尽管这些类型具有相同的名称，但编译器无法知道它们是相同的底层类型。用户会感到非常困惑，因为编译器会显示类似“expected foo::Type，got foo::Type”的错误信息。
- 缓解这个问题的最佳方法是仅在子crate依赖于未发布的更改时使用路径依赖关系。只要一个crate使用foo 1.0.0，它应该在其依赖项中列出foo = "1.0.0"。只有当您对foo进行了更改，并且one需要这些更改时，才应将one更改为使用路径依赖关系。一旦您发布了one可以依赖的foo的新版本，您应该再次删除路径依赖关系。
- 这种方法也有其缺点。现在，如果您更改了 foo，然后运行 one 的测试，您会发现 one 将使用旧的 foo 进行测试，这可能不是您期望的结果。您可能希望配置您的持续集成基础设施，以便对每个子 crate 进行测试，既使用其他子 crate 的最新发布版本，又使用所有子 crate 配置为使用路径依赖项。

#### Project Configuration

运行 cargo new 会为您设置一个最小的 Cargo.toml，其中包含 crate 的名称、版本号、一些作者信息以及一个空的依赖项列表。这可以让您走得很远，但随着项目的发展，您可能希望在 Cargo.toml 中添加一些有用的内容。

##### Crate 元数据

将所有Cargo支持的元数据指令添加到Cargo.toml中是最明显的事情。除了显而易见的字段，如描述和主页，还可以包含其他信息，例如crate的README路径（readme）、与cargo run一起运行的默认二进制文件（default-run）以及额外的关键字和类别，以帮助crates.io对您的crate进行分类。
对于项目布局更复杂的crate，设置include和exclude元数据字段也非常有用。它们决定了应该包含和发布哪些文件。默认情况下，Cargo会包含crate目录中的所有文件，除非在.gitignore文件中列出，但如果您还有大型测试夹具、无关的脚本或其他辅助数据与您想要进行版本控制的相同目录中，这可能不是您想要的。正如它们的名称所示，include和exclude允许您仅包含特定的文件集或排除与给定模式匹配的文件。

**注意** 如果您有一个 crate 不应该被发布，或者只应该发布到某些特定的替代注册表（即不发布到 crates.io），您可以将 publish 指令设置为 false 或允许的注册表列表。
您可以使用的元数据指令列表不断增长，因此请定期查看 Cargo 参考文档的 Manifest Format 页面（<https://doc.rust-lang.org/cargo/reference/manifest.html>）。

##### Build Configuration

Cargo.toml还可以让您控制Cargo如何构建您的crate。
最明显的工具是build参数，它允许您为您的crate编写完全自定义的构建程序（我们将在第11章中重新讨论此问题）。
然而，Cargo还提供了两种较小但非常有用的机制，我们将在这里探讨：patches和profiles。

`**[patch]**`
Cargo.toml的[patch]部分允许您指定一个不同的源来替换依赖项，无论修补的依赖项在依赖关系中的位置如何。当您需要针对某个传递依赖项的修改版本进行编译，以测试错误修复、性能改进或即将发布的新次要版本时，这非常有价值。清单5-6展示了一个临时使用一组依赖项的变体的示例。

```toml

[patch.crates-io]

# use a local (presumably modified) source

regex = { path = "/home/jon/regex" }

# use a modification on a git branch

serde = { git = "<https://github.com/serde-rs/serde.git>", branch = "faster" }

# patch a git dependency

[patch.'https://github.com/jonhoo/project.git']
project = { path = "/home/jon/project" }
```

清单5-6：使用[patch]在Cargo.toml中覆盖依赖项源
即使您修补了一个依赖项，Cargo也会检查crate的版本，以防止意外地修补错误的主要版本crate。如果由于某种原因您在传递依赖项中依赖于多个主要版本的相同crate，您可以通过为每个版本提供不同的标识符来修补它们，如清单5-7所示。

```toml

[patch.crates-io]
nom4 = { path = "/home/jon/nom4", package = "nom" }
nom5 = { path = "/home/jon/nom5", package = "nom" }

```

清单5-7：使用[patch]在Cargo.toml中覆盖同一crate的多个版本

- Cargo将查看每个路径中的Cargo.toml文件，意识到/nom4包含主要版本4，/nom5包含主要版本5，并相应地修补这两个版本。package关键字告诉Cargo在这两种情况下都查找名为nom的crate，而不是像默认情况下那样使用依赖标识符（左侧部分）。您也可以在常规依赖项中使用package来重命名依赖项！
- 请记住，在发布crate时，补丁不会被考虑在上传的包中。依赖于您的crate的crate将仅使用自己的[patch]部分（可能为空），而不是您的crate的[patch]部分！
**CRATES VS. PACKAGES**
您可能想知道包和crate之间的区别是什么。
这两个术语在非正式的上下文中经常可以互换使用，但它们在Rust编译器、Cargo、crates.io或其他情况下具有不同的定义。我个人认为crate是一个Rust模块层次结构，从一个根.rs文件开始（您可以在其中使用crate级别的属性，如#![feature]）-通常是类似lib.rs或main.rs的文件。相比之下，一个package是一组crate和元数据，因此基本上是由Cargo.toml文件描述的所有内容。这可能包括一个库crate、多个二进制crate、一些集成测试crate，甚至可能是多个工作区成员，它们本身就有Cargo.toml文件。

`**[profile]**`
[profile]部分允许您向Rust编译器传递附加选项，以改变它编译crate的方式。这些选项主要分为三类：性能选项、调试选项和以用户定义方式改变代码行为的选项。它们在调试模式和发布模式下有不同的默认值（还有其他模式）。

- 三个主要的性能选项是opt-level、codegen-units和lto。opt-level选项通过告诉编译器在运行时对程序进行多大程度的优化（0表示“没有优化”，3表示“尽可能多的优化”）来调整运行时性能。设置越高，代码优化的程度就越高，这可能使代码运行更快。然而，额外的优化会增加编译时间的成本，这就是为什么通常只在发布构建中启用优化的原因。
**注意** 您还可以将 opt-level 设置为 "s"，以优化二进制文件的大小，这在嵌入式平台上可能很重要。

- codegen-units选项与编译时性能有关。它告诉编译器可以将单个crate的编译拆分成多少个独立的编译任务（代码生成单元）。将大型crate的编译拆分成更多的片段，编译速度将更快，因为可以使用更多的线程并行编译crate。不幸的是，为了实现这种加速，线程需要更多或更少独立地工作，这意味着代码优化会受到影响。例如，想象一下，在一个线程中编译的crate段可以从另一个段中内联一些代码-由于这两个段是独立的，内联无法发生！因此，这个设置是编译时性能和运行时性能之间的权衡。默认情况下，Rust在调试模式下使用无限数量的codegen units（基本上是“尽快编译”），在发布模式下使用较小的数量（在撰写本文时为16个）。

- lto设置用于切换链接时优化（LTO），它使得编译器（或链接器，如果你想更加技术化）能够联合优化程序的各个编译单元，这些单元最初是分别编译的。关于LTO的详细细节超出了本书的范围，但基本思想是每个编译单元的输出都包含了该单元中的代码的信息。在所有单元编译完成后，链接器对所有单元进行另一次遍历，并使用额外的信息来优化组合编译代码。这个额外的遍历增加了编译时间，但可以恢复由于将编译拆分为较小部分而可能丢失的大部分运行时性能。特别是，LTO可以为可能受益于跨crate优化的性能敏感程序提供显著的性能提升。但要注意，跨crate的LTO可能会大大增加编译时间。
- Rust默认情况下在每个crate内部对所有codegen单元执行LTO，以弥补使用多个codegen单元造成的优化损失。由于LTO仅在每个crate内部执行，而不是跨crate执行，因此这个额外的步骤并不太繁重，而且增加的编译时间应该比使用大量codegen单元节省的时间更少。Rust还提供了一种称为thin LTO的技术，它允许LTO过程在很大程度上并行化，但代价是可能会错过一些“完整”LTO过程发现的优化。

**注意** LTO 在许多情况下也可以用于优化跨外部函数接口边界。有关更多详细信息，请参阅 linker-plugin-lto rustc 标志。

- [profile] 部分还支持一些用于调试的标志，例如 debug、debug-assertions 和 overflow-checks。debug 标志告诉编译器在编译的二进制文件中包含调试符号。这会增加二进制文件的大小，但意味着在回溯和性能分析中可以获得函数名等信息，而不仅仅是指令地址。debug-assertions 标志启用 debug_assert! 宏和其他相关的调试代码，这些代码在其他情况下不会被编译（通过 cfg(debug_assertions)）。这些代码可能会使程序运行变慢，但可以更容易地在运行时捕获可疑行为。overflow-checks 标志，顾名思义，启用整数操作的溢出检查。这会减慢它们的速度（注意到一个趋势了吗？），但可以帮助您尽早发现棘手的错误。默认情况下，在调试模式下启用这些标志，在发布模式下禁用。

`[profile.*.panic]`

- [profile] 部分还有一个值得单独讨论的标志：panic。该选项决定当程序中的代码调用 panic! 时（无论是直接调用还是通过 unwrap 等间接调用），会发生什么。您可以将 panic 设置为 unwind（在大多数平台上默认值）或 abort。我们将在第9章中更详细地讨论 panic 和 unwinding，但在这里我会简要总结一下。
- 在 Rust 中，通常情况下，当程序发生 panic 时，引发 panic 的线程会开始进行堆栈展开（unwinding）。您可以将堆栈展开视为从当前函数递归返回到该线程堆栈的底部。也就是说，如果 main 调用了 foo，foo 调用了 bar，bar 调用了 baz，在 baz 中发生 panic 将会强制从 baz、bar、foo，最后从 main 中返回，导致程序退出。进行堆栈展开的线程将正常地丢弃堆栈上的所有值，这使得这些值有机会清理资源、报告错误等。即使发生 panic，这使得运行系统有机会以优雅的方式退出。
- 当一个线程发生 panic 并进行堆栈展开时，其他线程继续运行，不受影响。只有当（如果）运行 main 函数的线程退出时，程序才会终止。也就是说，panic 通常只限于发生 panic 的线程。
- 这意味着堆栈展开是一把双刃剑；程序在一些失败的组件中艰难前行，这可能导致各种奇怪的行为。例如，想象一下，在更新互斥锁中的状态时，一个线程发生了 panic。随后尝试获取该互斥锁的任何线程现在必须准备好处理状态可能处于部分更新、不一致的状态的事实。因此，一些同步原语（如互斥锁）将记住它们上次访问时是否发生了 panic，并将此信息传递给随后尝试访问该原语的任何线程。如果一个线程遇到这样的状态，通常也会发生 panic，从而导致级联，最终终止整个程序。但这可能比继续以损坏的状态运行要好！
- 支持堆栈展开所需的记账工作是不免费的，并且通常需要编译器和目标平台的特殊支持。例如，许多嵌入式平台根本无法高效地展开堆栈。因此，Rust支持一种不同的panic模式：abort，当发生panic时，整个程序立即退出。在这种模式下，没有线程可以进行任何清理工作。这可能看起来很严重，确实如此，但它确保程序永远不会在半工作状态下运行，并且错误会立即显现出来。

**警告** panic 设置是全局的 - 如果将其设置为 abort，则所有依赖项也将使用 abort 进行编译。

- 您可能已经注意到，当一个线程发生 panic 时，它倾向于打印一个回溯：导致 panic 发生的函数调用的轨迹。这也是一种展开，尽管它与此处讨论的 panic 展开行为是分开的。即使在 panic=abort 的情况下，您也可以通过向 rustc 传递 -Cforce-unwind-tables 来获得回溯，这使得 rustc 包含了在 panic 时回溯堆栈的必要信息，同时终止程序的执行。
**配置文件覆盖**
您可以使用配置文件覆盖来为特定的依赖项或特定的配置文件设置配置选项。例如，清单5-8展示了如何在调试模式下为serde crate启用激进的优化，并为所有其他crate启用适度的优化，使用[profile.<profile-name>.package.<crate-name>]语法。

```toml

[profile.dev.package.serde]
opt-level = 3
[profile.dev.package."*"]
opt-level = 2
```

清单5-8：为特定依赖项或特定模式覆盖配置文件选项

- 如果某个依赖项在调试模式下非常慢（例如解压缩或视频编码），而您需要对其进行优化，以便测试套件不需要花费数天的时间才能完成，那么这种优化覆盖可能非常有用。您还可以在Cargo配置文件的~/.cargo/config中使用[profile.dev]（或类似的）部分指定全局配置文件默认值。
- 当您为特定依赖项设置优化参数时，请记住这些参数仅适用于作为该crate的一部分编译的代码；如果在此示例中的serde中有您在crate中使用的通用方法或类型，那么该方法或类型的代码将在您的crate中进行单态化和优化，并且将应用您crate的配置文件设置，而不是serde的配置文件覆盖中的设置。

#### 条件编译

大多数您编写的 Rust 代码都是通用的，无论在哪个 CPU 或操作系统上运行，它都能正常工作。但有时，您可能需要在 Windows 上、在 ARM 芯片上或在针对特定平台应用程序二进制接口（ABI）编译时执行一些特殊操作。或者，当某个 CPU 指令可用时，您可能希望编写一个优化版本的特定函数，或者在连续集成（CI）环境中运行时禁用一些慢但无趣的设置代码。为了满足这些情况，Rust 提供了条件编译的机制，即只有在编译环境满足某些条件时，才会编译特定的代码段。

- 我们使用cfg关键字来表示条件编译，你在本章的“在你的crate中使用特性”中已经见过它。它通常以#[cfg(condition)]属性的形式出现，表示只有在条件为真时才编译下一个项。Rust还有#[cfg_attr(condition, attribute)]，如果条件成立，则编译为#[attribute]，否则不做任何操作。您还可以使用cfg!(condition)宏将cfg条件评估为布尔表达式。
- 每个cfg结构都接受一个由选项组成的条件，例如feature = "some-feature"，以及组合器all、any和not，它们的功能符合您的预期。选项可以是简单的名称，例如unix，也可以是用于特性条件的键/值对。
- 有许多有趣的选项可以使编译依赖于它们。让我们从最常见的到最不常见的逐个介绍：

##### 功能选项

- 您已经看到了这些的示例。功能选项采用feature = "name-of-feature"的形式，如果启用了指定的功能，则被视为true。您可以使用组合器在单个条件中检查多个功能。例如，any(feature = "f1", feature = "f2")在启用了功能f1或功能f2时为true。

##### 操作系统选项

- 这些使用键/值语法，键为target_os，值为windows、macos和linux。您还可以使用target_family指定操作系统的系列，它接受值windows或unix。它们非常常见，已经有了自己的命名简写形式，因此您可以直接使用cfg(windows)和cfg(unix)。例如，如果您希望特定的代码段仅在macOS和Windows上编译，您可以编写：#[cfg(any(windows, target_os = "macos"))]。

##### 上下文选项

- 这些选项允许您根据特定的编译上下文来定制代码。其中最常见的是test选项，只有在crate在测试配置文件下编译时才为true。请记住，test仅针对正在测试的crate设置，而不针对其任何依赖项设置。这也意味着在运行集成测试时，您的crate中不会设置test；实际上，是集成测试在测试配置文件下编译，而您的crate会正常编译（即没有设置test）。相同的规则也适用于doc和doctest选项，它们仅在构建文档或编译doctest时设置。还有一个debug_assertions选项，默认情况下在调试模式下设置。

工具选项

- 一些工具，如clippy和Miri，设置自定义选项（稍后详细介绍），可以在运行这些工具时自定义编译。通常，这些选项以工具的名称命名。例如，如果您不希望某个特定的计算密集型测试在Miri下运行，您可以给它添加属性#[cfg_attr(miri, ignore)]。

##### Architecture options

- 这些选项允许您根据编译器所针对的CPU指令集进行编译。您可以使用target_arch指定特定的架构，它接受值如x86、mips和aarch64，或者您可以使用target_feature指定特定的平台特性，它接受值如avx或sse2。对于非常底层的代码，您可能还会发现target_endian和target_pointer_width选项很有用。

##### Compiler options

- 这些选项允许您根据编译的平台ABI来调整代码，可以通过target_env来获取，它接受值如gnu、msvc和musl。出于历史原因，这个值通常为空，特别是在GNU平台上。通常只有在需要直接与环境ABI进行接口的情况下，才需要此选项，例如在使用#[link]链接到特定ABI的符号名称时。虽然cfg条件通常用于自定义代码，但有些条件也可以用于自定义依赖项。例如，依赖项winrt通常只在Windows上有意义，而nix crate可能只在基于Unix的平台上有用。清单5-9展示了如何使用cfg条件来实现这一点：

```toml

[target.'cfg(windows)'.dependencies]
winrt = "0.7"
[target.'cfg(unix)'.dependencies]
nix = "0.17"
```

清单5-9：条件依赖项

- 在这里，我们指定 winrt 版本 0.7 应该只在 cfg(windows)（即在 Windows 上）下作为依赖项，而 nix 版本 0.17 则只在 cfg(unix)（即在 Linux、macOS 和其他基于 Unix 的平台上）下作为依赖项。需要记住的一件事是，在构建过程的早期阶段，只有某些 cfg 选项可用，因此无法使用此语法基于特性和上下文来引入依赖项。但是，您可以使用仅依赖于目标规范或架构的任何 cfg，以及由调用 rustc 的工具明确设置的任何选项（如 cfg(miri)）。
**注意** 在我们讨论依赖规范的同时，我强烈建议您设置CI基础设施，使用cargo-deny和cargo-audit等工具对您的依赖项进行基本审核。这些工具可以检测到以下情况：您在传递依赖关系中依赖于多个主要版本的给定依赖项，您依赖于未维护或已知存在安全漏洞的crate，或者您使用了您可能希望避免的许可证。使用这样的工具是提高代码库质量的一种自动化方式！

- 添加自定义的条件编译选项也非常简单。您只需要确保在 rustc 编译您的 crate 时传递 --cfg=myoption。最简单的方法是将 --cfg 添加到 RUSTFLAGS 环境变量中。这在 CI 中非常有用，您可以根据测试套件是在 CI 上运行还是在开发机器上运行来自定义测试套件：在 CI 设置中添加 --cfg=ci 到 RUSTFLAGS，然后在代码中使用 cfg(ci) 和 cfg(not(ci))。以这种方式设置的选项也可以在 Cargo.toml 的依赖项中使用。

#### 版本控制

所有的 Rust crate 都有版本号，并且预期遵循 Cargo 对语义化版本控制的实现。语义化版本控制规定了哪些变化需要增加哪些版本号，以及哪些版本被认为是兼容的，以及以何种方式兼容。RFC 1105 标准本身值得一读（它并不是非常技术性），但总结起来，它区分了三种类型的变化：破坏性变化需要进行主版本号的更改；新增功能需要进行次版本号的更改；修复错误只需要进行补丁版本号的更改。RFC 1105 在概述了在 Rust 中什么是破坏性变化方面做得相当不错，我们在本书的其他地方也提到了一些相关内容。

- 我不会在这里详细介绍不同类型变化的确切语义。相反，我想强调一些在决定如何为自己的 crate 进行版本控制时需要注意的 Rust 生态系统中不太直观的版本号使用方式。

#### 最低支持的 Rust 版本

第一个 Rust 特性是最低支持的 Rust 版本（MSRV）。在 Rust 社区中，关于项目在 MSRV 和版本控制方面应该遵循什么策略存在很多争议，而且没有一个真正好的答案。问题的核心是，一些 Rust 用户受限于使用较旧的 Rust 版本，通常是在企业环境中，他们几乎没有选择。如果我们不断利用新稳定的 API，这些用户将无法编译我们 crate 的最新版本，将被落下。

- 有两种技术可以让创建者为处于这种情况下的用户提供一些便利。第一种是建立一个最低支持的 Rust 版本（MSRV）策略，承诺新版本的 crate 将始终与过去 X 个月内的任何稳定版本编译通过。确切的数字有所不同，但通常为 6 或 12 个月。根据 Rust 的六周发布周期，这对应于最新的四个或八个稳定版本。项目中引入的任何新代码都必须与 MSRV 编译器（通常由 CI 检查）一起编译通过，或者在 MSRV 策略允许的情况下暂时保留，直到可以合并。这有时可能会有些麻烦，因为这意味着这些 crate 无法充分利用语言的最新功能，但它将为您的用户带来便利。
- 第二种技术是确保每当 MSRV 更改时，增加您的 crate 的次要版本号。因此，如果您发布了版本为 2.7.0 的 crate，并将其 MSRV 从 Rust 1.44 增加到 Rust 1.45，那么依赖于您的 crate 并停留在 1.44 上的项目可以使用依赖版本说明符 version = "2, <2.7" 来保持项目正常运行，直到可以迁移到 Rust 1.45。重要的是，您要增加次要版本号，而不仅仅是修订版本号，这样您仍然可以通过进行另一个修订版本的关键安全修复来为先前的 MSRV 发布提供支持，如果有必要的话。
- 一些项目非常重视对最低支持的 Rust 版本（MSRV）的支持，将 MSRV 的更改视为破坏性更改并增加主版本号。这意味着下游项目必须明确选择接受 MSRV 的更改，而不是选择不接受，但这也意味着没有严格的 MSRV 要求的用户将无法看到Future的错误修复，除非更新其依赖项，这可能需要他们进行破坏性更改。正如我所说，这些解决方案都有缺点。
- 在当前的 Rust 生态系统中，强制最低支持的 Rust 版本（MSRV）是具有挑战性的。只有少数一部分的 crate 提供了任何 MSRV 的保证，即使你的依赖项提供了，你也需要不断监控它们以了解何时增加了 MSRV。当它们增加了 MSRV 时，你需要使用之前提到的限制版本范围进行新的 crate 发布，以确保你的 MSRV 不会改变。这可能会迫使你放弃依赖项的安全性和性能更新，因为你必须继续使用旧版本，直到你的 MSRV 策略允许更新。而这个决定也会影响到你的依赖者。有一些提案将 MSRV 检查集成到 Cargo 中，但截至目前为止，还没有可行的稳定版本。

#### 最小依赖版本

当您首次添加依赖项时，往往不清楚应该给出什么版本说明符。程序员通常选择最新版本或当前主要版本，但很可能这两种选择都是错误的。我所说的“错误”并不意味着您的 crate 无法编译，而是选择这样做可能会给您 crate 的用户带来麻烦。让我们看看为什么每种情况都存在问题。

- 首先，考虑一种情况，您添加了对 hugs = "1.7.3" 的依赖，这是最新发布的版本。现在想象一下，某个开发人员依赖于您的 crate，但他们还依赖于另一个 crate，名为 foo，它本身依赖于 hugs。进一步想象一下，foo 的作者非常注意他们的 MSRV 策略，所以他们依赖于 hugs = "1, <1.6"。在这种情况下，您将遇到麻烦。当 Cargo 看到 hugs = "1.7.3" 时，它只考虑 >=1.7 的版本。但是然后它看到 foo 对 hugs 的依赖要求 <1.6，所以它放弃了，并报告说没有满足所有要求的 hugs 版本。
**注意** 在实践中，有许多原因可能导致一个 crate 明确不希望使用较新的依赖项版本。最常见的原因是为了保持最低支持的 Rust 版本（MSRV），满足企业审计要求（较新的版本可能包含未经审计的代码），以及确保可重现构建，只使用精确列出的版本。
- 这是不幸的，因为很可能您的 crate 可以与 hugs 1.5.6 编译通过。甚至可能它可以与任何 1.X 版本编译通过！但是通过使用最新的版本号，您告诉 Cargo 仅考虑在该次要版本及以上的版本。那么解决方案是使用 hugs = "1" 吗？不，也不完全正确。可能您的代码确实依赖于仅在 hugs 1.6 中添加的某些内容，因此 1.6.2 是可以的，但 1.5.6 不行。如果您只在使用较新版本的情况下编译 crate，您可能不会注意到这一点，但是如果依赖图中的某个 crate 指定了 hugs = "1, <1.5"，则您的 crate 将无法编译！
- 正确的策略是列出具有您的 crate 所依赖的所有内容的最早版本，并确保即使在向 crate 添加新代码时也保持这种情况。但是，除了浏览更改日志或通过试错之外，如何确定这一点呢？您最好的选择是使用 Cargo 的不稳定 -Zminimal-versions 标志，它使您的 crate 使用所有依赖项的最低可接受版本，而不是最高版本。然后，将所有依赖项设置为最新的主版本号，尝试编译，并为任何不兼容的依赖项添加一个次要版本号。反复尝试，直到一切都能正常编译，这样您就得到了最低版本要求！
- 值得注意的是，与最低支持的 Rust 版本（MSRV）一样，最小版本检查也面临着生态系统采用的问题。尽管您可能已经正确设置了所有版本规范，但您所依赖的项目可能没有。这使得在实践中很难使用 Cargo 的最小版本标志（这也是为什么它仍然是不稳定的）。如果您依赖于 foo，并且 foo 依赖于 bar，而 bar 的规范为 bar = "1"，而实际上它需要 bar = "1.4"，无论您如何列出 foo，Cargo 都会报告无法编译 foo，因为 -Z 标志告诉它始终优先选择最小版本。您可以通过在依赖项中直接列出 bar 并指定适当的版本要求来解决此问题，但这些解决方法可能很麻烦并且难以维护。您可能会列出大量仅通过传递依赖项引入的依赖项，并且随着时间的推移，您将不得不保持该列表的更新。
**注意** 目前的一个提案是提供一个标志，该标志在当前 crate 中偏向最小版本，但在依赖项中偏向最大版本，这似乎非常有前景。

##### 更新日志

- 对于除了最简单的 crate 之外，我强烈建议保持一个更新日志。没有什么比看到一个依赖项进行了主版本升级，然后不得不深入 Git 日志中找出变更内容以及如何更新代码更令人沮丧的了。我建议您不要只是将 Git 日志转储到一个名为 changelog 的文件中，而是保持一个手动的更新日志。这样更有可能有用。
- 一个简单但不错的更新日志格式是 Keep a Changelog 的格式，文档在 <https://keepachangelog.com/> 中有记录。

##### Unreleased Versions

即使依赖项的源是目录或Git存储库，Rust在考虑版本号时也会起作用。这意味着即使您尚未发布到crates.io，语义化版本控制也很重要；在发布之间，Cargo.toml中列出的版本号很重要。语义化版本控制标准没有规定如何处理这种情况，但我将提供一个工作流程，既能很好地工作，又不会太繁琐。

- 在发布了一个版本之后，立即在 Cargo.toml 中更新版本号为下一个带有类似 -alpha.1 后缀的补丁版本。如果刚发布了 2.0.3，那么新版本将是 2.0.4-alpha.1。如果刚发布了一个 alpha 版本，则增加 alpha 编号即可。
- 在发布之间对代码进行更改时，请注意增量或破坏性的更改。如果发生了破坏性更改，并且与上次发布时的版本号没有变化，那么请增加版本号。例如，如果上次发布的版本是2.0.3，当前版本是2.0.4-alpha.2，并且您进行了增量更改，请将具有更改的版本号设置为2.1.0-alpha.1。如果进行了破坏性更改，则将其设置为3.0.0-alpha.1。如果相应的版本增加已经完成，请只增加alpha编号。
- 当您发布一个版本时，删除后缀（除非您想进行预发布），然后发布，并从头开始。
- 这个过程是有效的，因为它可以更好地支持两种常见的工作流程。首先，假设开发人员依赖于您 crate 的主版本2，但他们需要一个目前只在Git中可用的功能。然后，您提交了一个破坏性的更改。如果您不同时增加主版本号，他们的代码将以意想不到的方式突然失败，可能是无法编译，或者是由于奇怪的运行时问题。如果您按照这里提出的步骤进行操作，他们将收到Cargo的通知，说明发生了破坏性的更改，他们将不得不解决这个问题或者固定一个特定的提交。
- 接下来，想象一下，一个开发人员需要一个他们刚刚贡献给您 crate 的功能，但这个功能尚未包含在您 crate 的任何发布版本中。他们在很长一段时间内都在使用您 crate 的 Git 依赖项，因此他们项目中的其他开发人员已经有了您 crate 仓库的旧版本。如果您在 Git 中不增加主版本号，这个开发人员就没有办法告知他们的项目现在依赖于刚刚合并的功能。如果他们推送了他们的更改，他们的同事开发人员将发现项目无法编译，因为 Cargo 将重用旧的检出。然而，如果开发人员可以增加 Git 依赖项的次要版本号，那么 Cargo 将意识到旧的检出已经过时。
- 这个工作流程并不完美。它没有提供一个很好的方式来传达在发布之间的多个次要或主要更改，并且您仍然需要做一些工作来跟踪版本。然而，它确实解决了 Rust 开发人员在使用 Git 依赖项时遇到的两个最常见问题，即使在发布之间进行多个此类更改，这个工作流程仍然可以捕捉到许多问题。
- 如果您对版本号的小幅或连续变化不太担心，您可以通过始终增加版本号的适当部分来改进此建议的工作流程。但是，请注意，根据您进行此类更改的频率，这可能会使您的版本号变得非常大！

#### 摘要

在本章中，我们已经介绍了一些配置、组织和发布 crate 的机制，既有利于自己，也有利于他人。我们还讨论了在使用 Cargo 中处理依赖项和特性时的一些常见问题，希望这些问题不会再困扰到你。在下一章中，我们将转向测试，并深入探讨如何超越我们所熟悉和喜爱的 Rust 的简单 #[test] 函数。

### 6.测试

在本章中，我们将介绍各种扩展Rust测试能力的方法，以及您可能希望添加到测试组合中的其他类型的测试。Rust提供了许多内置的测试工具，这些工具在《Rust编程语言》中得到了很好的介绍，主要由#[test]属性和tests/目录表示。当您开始一个项目时，这些工具可以很好地满足您的需求，并且适用于各种应用和规模。然而，随着代码库的发展和测试需求的增加，您可能需要超越仅仅在个别函数上添加#[test]标记的方式。

- 本章分为两个主要部分。第一部分介绍了Rust的测试机制，如标准测试框架和条件测试代码。第二部分介绍了评估Rust代码正确性的其他方法，如基准测试、代码检查和模糊测试。

#### Rust Testing Mechanisms

要理解Rust提供的各种测试机制，首先必须了解Rust如何构建和运行测试。当您运行cargo test --lib时，Cargo所做的唯一特殊之处是向rustc传递--test标志。该标志告诉rustc生成一个测试二进制文件，该文件运行所有单元测试，而不仅仅是编译crate的库或二进制文件。在幕后，--test有两个主要效果。首先，它启用了cfg(test)，以便您可以有条件地包含测试代码（稍后会详细介绍）。其次，它使编译器生成一个测试harness：一个精心生成的main函数，在运行时调用程序中的每个`#[test]函数`。

##### 测试工具

编译器通过一种混合使用过程宏（procedural macros）和一些神奇的方式生成测试harness的main函数。我们将在第7章中更详细地讨论过程宏。测试harness将每个使用#[test]注解的函数转换为一个测试描述符，这是过程宏的一部分。然后，它将每个描述符的路径暴露给生成的main函数，这是神奇的部分。描述符包括测试的名称、任何额外设置的选项（如#[should_panic]），等等。在核心部分，测试harness迭代遍历crate中的测试，运行它们，捕获结果，并打印结果。因此，它还包括解析命令行参数的逻辑（例如--test-threads=1），捕获测试输出，以并行方式运行列出的测试，并收集测试结果。

- 截至目前，Rust开发人员正在努力使测试harness生成的魔法部分成为公开可用的API，以便开发人员可以构建自己的测试harness。这项工作仍处于实验阶段，但该提案与现有模型相当接近。需要解决的一部分魔法是如何确保生成的main函数可以访问#[test]函数，即使它们位于私有子模块中。
- 集成测试（位于tests/目录中的测试）遵循与单元测试相同的流程，唯一的区别是它们被编译为独立的 crate，意味着它们只能访问主 crate 的公共接口，并且在没有 #[cfg(test)] 的情况下对主 crate 进行编译。对于 tests/ 目录中的每个文件，都会生成一个测试 harness。为了允许您在测试中共享子模块，不会为 tests/ 子目录中的文件生成测试 harness。
**注意** 如果您明确希望在子目录中的文件中使用测试harness，可以通过将文件命名为main.rs来选择启用它。
- Rust不要求您使用默认的测试harness。您可以选择退出并实现自己的main方法来代表测试运行器，通过在Cargo.toml中设置harness = false来为给定的集成测试，如示例6-1所示。您定义的main方法将被调用来运行测试。

```rust

[[test]]
name = "custom"
path = "tests/custom.rs"
harness = false

```

代码清单 6-1：选择退出标准测试harness

- 没有测试harness，#[test]周围的所有魔法都不会发生。
相反，您需要编写自己的main函数来运行要执行的测试代码。实质上，您正在编写一个普通的Rust二进制文件，只是碰巧由cargo test运行。该二进制文件负责处理默认harness通常执行的所有事情（如果您想支持它们），例如命令行标志。harness属性是针对每个集成测试单独设置的，因此您可以有一个使用标准harness的测试文件和一个不使用harness的测试文件。

**默认测试harness的参数**
默认的测试harness支持一些命令行参数，用于配置测试的运行方式。这些参数不直接传递给cargo test，而是传递给Cargo为您编译和运行的测试二进制文件。要访问这组参数，您可以在cargo test后面加上--，然后是测试二进制文件的参数。例如，要查看测试二进制文件的帮助文本，您可以运行cargo test -- --help。

- 通过这些命令行参数，可以使用一些方便的配置选项。--nocapture标志禁用了通常在运行Rust测试时发生的输出捕获。如果您想实时观察测试的输出而不是在测试失败后一次性查看，这非常有用。您可以使用--test-threads选项来限制并发运行的测试数量，这对于有 hang 或 segfault 的测试很有帮助，您可以通过按顺序运行测试来找出是哪个测试出了问题。还有一个--skip选项，用于跳过与特定模式匹配的测试，--ignored用于运行通常被忽略的测试（例如那些需要外部程序运行的测试），--list用于列出所有可用的测试。

- 请记住，这些参数都是由默认的测试harness实现的，因此如果您禁用它（使用harness = false），您将需要在您的main函数中自己实现所需的参数！
- 没有测试harness的集成测试主要用于基准测试，我们稍后会看到，但它们也在您想要运行不适合标准“一个函数，一个测试”模型的测试时非常有用。例如，您经常会看到无harness的测试与模糊测试器、模型检查器以及需要自定义全局设置的测试一起使用（例如在WebAssembly下或在使用自定义目标时）。

#### `#[cfg(test)]`

当 Rust 构建测试代码时，它会设置编译器配置标志 test，您可以使用条件编译来编写代码，除非特别进行测试，否则该代码将被编译掉。表面上看，这似乎有些奇怪：难道您不想测试与生产环境中完全相同的代码吗？确实如此，但是在测试时仅有的代码可以让您编写更好、更全面的测试，有几种方式。

**MOCKING**
在编写测试时，您通常希望对正在测试的代码以及代码可能交互的任何其他类型具有严格的控制。例如，如果您正在测试一个网络客户端，您可能不希望在真实网络上运行单元测试，而是希望直接控制“网络”发出的字节和时间。或者，如果您正在测试一个数据结构，您希望您的测试使用的类型允许您控制每次调用时每个方法返回的内容。您还可能希望收集指标，例如给定方法被调用的频率或是否发出了给定的字节序列。

- 这些“假”类型和实现被称为模拟对象（mocks），它们是任何大型单元测试套件的关键特性。虽然您通常可以手动完成获取此类控制所需的工作，但最好有一个库来为您处理大部分琐碎的细节。这就是自动模拟的作用。模拟库将提供生成具有特定属性或签名的类型（包括函数）的功能，以及在测试执行期间控制和检查这些生成的项的机制。
- 在Rust中，模拟通常通过泛型来实现 - 只要您的程序、数据结构、框架或工具对您可能想要模拟的任何内容都是泛型的（或者接受一个特质对象），您就可以使用模拟库生成符合要求的类型来实例化这些泛型参数。然后，通过使用生成的模拟类型实例化您的泛型构造，编写单元测试，然后开始测试！
- 在泛型不方便或不合适的情况下，例如如果您想避免将类型的特定方面泛型化给用户，您可以将您想要模拟的状态和行为封装在一个专用的结构体中。然后，您可以生成该结构体及其方法的模拟版本，并使用条件编译根据cfg(test)或类似cfg(feature = "test_mock_foo")的测试专用功能来使用真实或模拟实现。
- 目前，在Rust社区中还没有出现一个单一的模拟库，甚至也没有出现一个单一的模拟方法，被认为是唯一正确的答案。我所知道的最全面和详尽的模拟库是mockall crate，但它仍在积极开发中，还有许多其他竞争者。

##### Test-Only APIs

首先，拥有仅供测试使用的代码可以让您向（单元）测试公开额外的方法、字段和类型，以便测试不仅可以检查公共API的行为是否正确，还可以检查内部状态是否正确。例如，考虑 hashbrown 中实现标准库 HashMap 的 HashMap 类型。HashMap 类型实际上只是围绕 RawTable 类型的包装器，而 RawTable 类型实现了大部分哈希表逻辑。假设在对空映射进行 HashMap::insert 操作后，您想要检查映射中的一个桶是否非空，如代码清单 6-2 所示。

```rust
#[test]
fn insert_just_one() {
  let mut m = HashMap::new();
  m.insert(42, ());
  let full = m.table.buckets.iter().filter(Bucket::is_full).count();
  assert_eq!(full, 1);
}
```

代码清单 6-2：访问不可访问的内部状态的测试，因此无法编译

- 这段代码无法编译，因为尽管测试代码可以访问HashMap的私有table字段，但它无法访问RawTable的私有buckets字段，因为RawTable位于不同的模块中。我们可以通过将buckets字段的可见性设置为pub(crate)来修复这个问题，但我们实际上不希望HashMap能够直接访问buckets，因为它可能会意外地破坏RawTable的内部状态。即使将buckets作为只读字段可用也可能会有问题，因为HashMap中的新代码可能会开始依赖于RawTable的内部状态，从而使Future的修改变得更加困难。
- 解决方案是使用#[cfg(test)]。我们可以向RawTable添加一个方法，只允许在测试时访问buckets，如代码清单6-3所示，从而避免为其余代码添加不必要的风险。然后，可以更新代码清单6-2中的代码，调用buckets()而不是访问私有的buckets字段。

```rust
impl RawTable {
    #[cfg(test)]
    pub(crate) fn buckets(&self) -> &[Bucket] {
      &self.buckets
    }
}
```

代码清单 6-3：使用 #[cfg(test)] 使内部状态在测试环境中可访问

##### 测试断言的记账

拥有仅在测试期间存在的代码的第二个好处是，您可以增加程序以执行额外的运行时记账，然后可以由测试进行检查。例如，想象一下，您正在编写自己版本的标准库中的BufWriter类型。在测试时，您希望确保BufWriter不会不必要地发出系统调用。最明显的方法是让BufWriter跟踪它在底层Write上调用write的次数。然而，在生产环境中，这些信息并不重要，并且跟踪它会引入（微小的）性能和内存开销。使用 # [cfg(test)]，您可以只在测试时进行记账，如代码清单6-4所示。

```rust

struct BufWriter<T> {
  # [cfg(test)]
  write_through: usize,
// other fields...
}

impl<T: Write> Write for BufWriter<T> {
  fn write(&mut self, buf: &[u8]) -> Result<usize> {
  // ...
  if self.full() {

    # [cfg(test)]
    self.write_through += 1;
    let n = self.inner.write(&self.buffer[..])?;
  // ...
  }
}
```

代码清单 6-4：使用 #[cfg(test)] 限制记账到测试上下文中
请记住，test 只对正在编译为测试的 crate 设置。对于单元测试，这是您要测试的 crate，正如您所期望的那样。然而，对于集成测试，它是作为测试编译的集成测试二进制文件 - 您要测试的 crate 只是作为库进行编译，因此不会设置 test。

#### Doctests

Rust代码片段在文档注释中会自动作为测试用例运行。这些通常被称为doctests。因为doctests出现在您的crate的公共文档中，并且用户很可能模仿其中的内容，所以它们被作为集成测试运行。这意味着doctests无法访问私有字段和方法，并且测试不会设置在主crate的代码上。每个doctest都被编译为独立的crate，并在隔离环境中运行，就像用户将doctest复制粘贴到自己的程序中一样。

- 在幕后，编译器对doctest进行了一些预处理，使其更简洁。最重要的是，它自动在您的代码周围添加了一个fn main。这使得doctest只关注用户可能关心的重要部分，比如实际使用您库中的类型和方法的部分，而不包含不必要的样板代码。
- 您可以通过在doctest中定义自己的fn main来选择退出此自动包装。例如，如果您想使用#[tokio::main] async fn main编写异步主函数，或者如果您想向doctest添加其他模块，您可能希望这样做。
- 在您的doctest中使用?运算符时，通常不需要使用自定义的main函数，因为rustdoc会根据一些启发式规则将返回类型设置为Result<(), impl Debug>，如果您的代码看起来使用了?（例如，如果以Ok(())结尾）。如果类型推断对函数的错误类型感到困惑，您可以通过将doctest的最后一行更改为显式类型来消除歧义，例如：Ok::<(), T>(())。
- Doctests具有一些额外的功能，对于编写更复杂接口的文档非常有用。首先是隐藏单行的能力。如果您在doctest的一行前面加上#，那么该行在编译和运行doctest时会被包含，但不会在生成的文档中的代码片段中显示。这使您可以轻松隐藏对当前示例不重要的细节，例如为虚拟类型实现特性或生成值。如果您希望呈现一系列示例而不每次都显示相同的前导代码，这也很有用。清单6-5展示了一个带有隐藏行的doctest示例。

```rust

/// Completely frobnifies a number through I/O.
///
/// In this first example we hide the value generation.
/// ```
/// # let unfrobnified_number = 0;
/// # let already_frobnified = 1;
/// assert!(frobnify(unfrobnified_number).is_ok());
/// assert!(frobnify(already_frobnified).is_err());
/// ```
///
/// Here's an example that uses ? on multiple types
/// and thus needs to declare the concrete error type,
/// but we don't want to distract the user with that.
/// We also hide the use that brings the function into scope.
/// ```
/// # use mylib::frobnify;
/// frobnify("0".parse()?)?;
/// # Ok::<(), anyhow::Error>(())
/// ```
///
/// You could even replace an entire block of code completely,
/// though use this _very_ sparingly:
/// ```
/// # /*
/// let i = ...;
/// # */
/// # let i = 42;
/// frobnify(i)?;
/// ```
fn frobnify(i: usize) -> std::io::Result<()> {

```

Listing 6-5: Hiding lines in a doctest with #

**注意** 使用此功能时要小心；如果用户复制粘贴示例代码，然后由于您隐藏的必要步骤而无法正常工作，可能会令用户感到沮丧。

- 与 #[test] 函数类似，doctest 也支持修改运行方式的属性。这些属性紧跟在用于表示代码块的三个反引号之后，多个属性可以用逗号分隔。
- 与测试函数类似，您可以使用 should_panic 属性来指示特定的 doctest 在运行时应该发生 panic，或者使用 ignore 来仅在使用 --ignored 标志运行 cargo test 时检查代码段。您还可以使用 no_run 属性来指示给定的 doctest 应该编译但不应运行。
- 属性 compile_fail 告诉 rustdoc 文档示例中的代码不应该编译通过。这向用户表明某个特定的用法是不可能的，并作为一个有用的测试，提醒您在库的相关方面发生变化时更新文档。您还可以使用此属性来检查某些类型的静态属性是否成立。清单 6-6 展示了如何使用 compile_fail 来检查给定类型是否不实现 Send，这在不安全代码中可能需要维护安全性保证。

```rust


compile_fail
# struct MyNonSendType(std::rc::Rc<()>);
fn is_send<T: Send>() {}
is_send::<MyNonSendType>();

```

清单 6-6：使用 compile_fail 测试代码无法编译

`compile_fail` 是一个相对简单的工具，它不会提供代码无法编译的原因。例如，如果代码由于缺少分号而无法编译，那么 `compile_fail` 测试将会被认为是成功的。因此，通常情况下，您需要在确保测试确实无法编译并出现预期错误后才添加该属性。
如果您需要更细粒度的编译错误测试，例如在开发宏时，可以查看 trybuild crate。

#### Additional Testing Tools

测试远不止于运行测试函数并验证其产生预期结果。对测试技术、方法论和工具的全面调查超出了本书的范围，但在扩展您的测试技能时，有一些关键的 Rust 特定知识需要了解。

##### Linting

您可能不认为代码检查工具的检查是测试，但在Rust中，它们通常可以被视为测试。Rust代码检查工具Clippy将其许多lints分类为正确性lints。这些lints可以捕获编译通过但几乎肯定是错误的代码模式。一些示例包括a = b; b = a，未能交换a和b；std::mem::forget(t)，其中t是一个引用；以及for x in y.next()，它只会迭代y的第一个元素。如果您还没有将Clippy作为CI流程的一部分运行，那么您可能应该考虑这样做。

- Clippy提供了许多其他的lint，虽然通常很有帮助，但可能比您期望的更具主观性。例如，默认情况下启用的type_complexity lint会在您的程序中使用特别复杂的类型（例如Rc<Vec<Vec<Box<(u32, u32, u32, u32)>>>>）时发出警告。虽然这个警告鼓励您编写更易读的代码，但您可能会觉得它过于苛刻，不太实用。如果您的代码的某个部分错误地触发了特定的lint，或者您只想允许特定的实例，您可以使用#[allow(clippy::name_of_lint)]在该代码片段中禁用该lint。
- Rust编译器还提供了一套自己的lints，以警告的形式存在，尽管这些lints通常更多地用于指导编写符合惯用写法的代码，而不是检查正确性。相反，编译器中的正确性lints被视为错误（可以查看rustc -W help获取列表）。

**注意** 并非所有的编译器警告都是默认启用的。那些默认禁用的警告通常仍在不断完善，或者更多关注的是代码风格而非内容。一个很好的例子是“Rust 2018 edition”的惯用写法警告，您可以使用 #![warn(rust_2018_idioms)] 启用它。当启用此警告时，编译器会告诉您是否未能利用 Rust 2018 edition 带来的变化。当您开始一个新项目时，您可能还想养成启用一些其他警告的习惯，比如 missing_docs 和 missing_debug_implementations，它们会在您的 crate 中有任何公共项未被文档化或任何公共类型未添加 Debug 实现时发出警告。

#### Test Generation

编写一个良好的测试套件是一项很大的工作。即使在你完成了这项工作之后，你编写的测试只能测试你在编写它们时考虑到的特定行为集。幸运的是，你可以利用许多测试生成技术来开发更好、更全面的测试。这些技术为你生成输入，用于检查你的应用程序的正确性。有许多这样的工具存在，每个工具都有其自身的优点和缺点，所以在这里我只会介绍这些工具使用的主要策略：模糊测试和属性测试。

##### Fuzzing

整本书都可以写关于模糊测试的内容，但从高层次来看，它的思想很简单：生成随机输入到你的程序中，然后观察是否崩溃。如果程序崩溃了，那就是一个 bug。例如，如果你正在编写一个 URL 解析库，你可以通过系统地生成随机字符串并将它们传递给解析函数来进行模糊测试，直到它发生 panic。如果简单地按顺序生成输入，比如从 a 开始，然后是 b，然后是 c，等等，那么要生成一个像 http://[:]. 这样棘手的 URL 将需要很长时间。实际上，现代的模糊测试工具使用代码覆盖度指标来探索代码中的不同路径，这使得它们能够更快地达到更高的覆盖度，而不是完全随机选择输入。

- Fuzzers非常擅长发现您的代码无法正确处理的奇怪边界情况。它们需要很少的设置：您只需将模糊器指向一个接受“可模糊化”输入的函数，然后它就会开始工作。例如，清单6-7展示了如何对URL解析器进行模糊测试的示例。

```rust

libfuzzer_sys::fuzz_target!(|data: &[u8]| {
  if let Ok(s) = std::str::from_utf8(data) {
  let_ = url::Url::parse(s);
  }
});
```

清单 6-7：使用 libfuzzer 对 URL 解析器进行模糊测试

- 模糊器将为闭包生成半随机输入，并将任何形成有效的 UTF-8 字符串的输入传递给解析器。请注意，此处的代码不检查解析是否成功或失败，而是寻找解析器由于违反内部不变量而引发 panic 或其他崩溃的情况。
- 模糊测试工具会持续运行，直到您终止它，因此大多数模糊测试工具都配备了在探索一定数量的测试用例后停止的内置机制。如果您的输入不是一个简单的可模糊化类型，比如哈希表，您通常可以使用类似 arbitrary 的 crate 将模糊测试生成的字节字符串转换为更复杂的 Rust 类型。这感觉像是魔法，但在底层实际上是以非常直接的方式实现的。该 crate 定义了一个 Arbitrary trait，其中包含一个方法 arbitrary，该方法从随机字节源构造实现类型。原始类型如 u32 或 bool 从输入中读取所需数量的字节以构造自身的有效实例，而像 HashMap 或 BTreeSet 这样的更复杂类型则从输入中产生一个数字来指示它们的长度，然后在其内部类型上调用 Arbitrary 该数字次数。甚至还有一个属性 #[derive(Arbitrary)]，它通过在每个包含的类型上调用 arbitrary 来实现 Arbitrary！要进一步探索模糊测试，我建议从 cargo-fuzz 开始。

##### Property-Based Testing

有时候你不仅想检查程序是否崩溃，还想确保它按照预期工作。你的 add 函数没有发生 panic 是很好，但如果它告诉你 add(1, 4) 的结果是 68，那可能还是错的。这就是属性测试的作用；你描述了代码应该遵守的一些属性，然后属性测试框架生成输入并检查这些属性是否确实成立。

- 使用属性测试的常见方法是首先编写一个简单但不太高效的代码版本，你对其正确性有信心。
然后，对于给定的输入，将该输入分别提供给你要测试的代码和简化但不太高效的版本。
如果两个实现的结果或输出相同，那么你的代码是正确的，这就是你要验证的正确性属性。
但如果结果不同，那么很可能发现了一个 bug。
你还可以使用属性测试来检查与正确性直接相关的属性以外的属性，比如某个实现的操作是否比另一个实现的操作时间更短。
共同的原则是，你希望真实版本和测试版本之间的任何结果差异都能提供有用的信息和可操作性，以便每次失败都能让你进行改进。
简化但不太高效的实现可以是标准库中的一个（比如std::collections::VecDeque），你想要替换或增强它，也可以是一个你试图优化的算法的简化版本（比如朴素与优化的矩阵乘法）。

- 如果这种生成输入直到满足某个条件的方法听起来很像模糊测试，那是因为它确实是——比我聪明的人们认为模糊测试就是“只要不崩溃就行”的属性测试。
- 属性测试的一个缺点是它更加依赖于提供的输入描述。而模糊测试会尝试所有可能的输入，属性测试往往会根据开发者的注释进行引导，比如“0到64之间的数字”或“包含三个逗号的字符串”。这使得属性测试能够更快地找到模糊测试可能需要很长时间才能随机遇到的情况，但它需要手动工作，并可能忽略重要但特定的错误输入。然而，随着模糊测试和属性测试越来越接近，模糊测试工具也开始获得这种基于约束的搜索能力。
- 如果你对属性测试生成感兴趣，我推荐从 proptest crate 开始。
  
**测试操作序列**
由于模糊测试工具和属性测试工具允许您生成任意的 Rust 类型，因此您不仅限于测试 crate 中的单个函数调用。例如，假设您想要测试某个类型 Foo 在执行特定操作序列时是否正确行为。您可以定义一个列出操作的枚举 Operation，并使您的测试函数接受一个 Vec<Operation>。然后，您可以实例化一个 Foo，并依次对该 Foo 执行每个操作。大多数测试工具都支持最小化输入，因此，如果找到违反属性的输入，它们甚至会搜索最小的操作序列！

#### Test Augmentation

假设您已经设置了一个完美的测试套件，并且您的代码通过了所有的测试。这是非常美妙的。但是，有一天，其中一个通常可靠的测试莫名其妙地失败或者由于段错误而崩溃了。这种非确定性的测试失败有两个常见原因：竞态条件，即如果两个操作以特定顺序在不同的线程上发生，您的测试可能会失败；以及不安全代码中的未定义行为，例如如果某些不安全代码从未初始化的内存中读取特定值。[]: # END: ed8c6549bwf9

- 使用普通测试捕获这些类型的错误可能很困难 - 通常情况下，您无法对线程调度、内存布局和内容或其他类似随机的系统因素具有足够的低级控制，以编写可靠的测试。您可以在循环中多次运行每个测试，但即使如此，如果错误情况非常罕见或不太可能发生，也可能无法捕获错误。幸运的是，有一些工具可以帮助增强您的测试，使捕获这些类型的错误变得更容易。
- 其中一个工具是令人惊叹的 Miri，它是 Rust 的中级中间表示（MIR）的解释器。MIR 是 Rust 的内部简化表示，它帮助编译器找到优化并检查属性，而无需考虑 Rust 本身的所有语法糖。通过 Miri 运行测试非常简单，只需运行 cargo miri test。Miri 解释执行您的代码，而不是像普通二进制文件那样编译和运行它，这使得测试运行速度较慢。但作为回报，Miri 可以在代码的每一行执行时跟踪整个程序状态。这使得 Miri 能够检测并报告程序是否出现某些类型的未定义行为，例如未初始化的内存读取、在值被丢弃后继续使用或越界指针访问。Miri 不会让这些操作产生奇怪的程序行为，可能只有在某些情况下才会导致可观察的测试失败（如崩溃），而是在发生时立即检测并告知您。
- 例如，考虑清单 6-8 中非常不安全的代码，它创建了两个对值的独占引用。

```rust

let mut x = 42;
let x: *mut i32 = &mut x;
let (x1, x2) = unsafe { (&mut*x, &mut *x) };
println!("{} {}", x1, x2);
```

清单 6-8：Miri 检测到不正确的极不安全代码

- 在撰写本文时，如果您通过Miri运行此代码，您将收到一个指出问题所在的错误：

```rust
error: Undefined Behavior: trying to reborrow for Unique at alloc1383, but
parent tag <2772> does not have an appropriate item in the borrow stack
--> src/main.rs:4:6
|
4 | let (x1, x2) = unsafe { (&mut*x, &mut *x) };
| ^^ trying to reborrow for Unique at alloc1383, but parent tag <2772>
does not have an appropriate item in the borrow stack

```

**注意** Miri仍在开发中，其错误消息并不总是最容易理解的。这是一个正在积极解决的问题，所以当您阅读本文时，错误输出可能已经得到了很大的改进！

- 另一个值得一看的工具是 Loom，这是一个聪明的库，它尝试确保您的测试在每个相关的并发操作交错中运行。在高层次上，Loom跟踪所有跨线程同步点，并一遍又一遍地运行您的测试，每次调整线程从这些同步点继续的顺序。因此，如果线程A和线程B都获取相同的Mutex，Loom将确保测试先以A先获取，然后以B先获取的方式运行。Loom还跟踪原子访问、内存顺序和对UnsafeCell的访问（我们将在第9章中讨论），并检查线程是否不适当地访问它们。如果测试失败，Loom可以给出确切的运行情况，包括哪些线程以什么顺序执行，以便您确定崩溃发生的原因。

##### Performance Testing

编写性能测试很困难，因为往往很难准确地模拟反映您的 crate 在实际使用中的工作负载。但是拥有这样的测试非常重要；如果您的代码突然运行速度变慢了100倍，那真的应该被视为一个 bug，但如果没有性能测试，您可能无法发现这个回归。如果您的代码运行速度提高了100倍，这也可能表明有些地方出了问题。这两种情况都是将自动化性能测试作为 CI 的一部分的好理由——如果性能发生了显著的变化，无论是向好的方向还是向坏的方向，您都应该知道。

- 与功能测试不同，性能测试没有一个共同的、明确定义的输出。功能测试要么成功，要么失败，而性能测试可能会给出吞吐量、延迟配置文件、处理的样本数量或其他与所涉及应用程序相关的指标。此外，性能测试可能需要在循环中运行一个函数数十万次，或者可能需要在分布式多核盒子的网络上运行数小时。因此，很难以一般意义上讨论如何编写性能测试。相反，在本节中，我们将看一下在使用Rust编写性能测试时可能遇到的一些问题以及如何减轻这些问题。经常被忽视的三个常见陷阱是性能差异、编译器优化和I/O开销。让我们依次探讨每个问题。

##### Performance Variance

性能可能因各种原因而有所变化，许多因素会影响特定机器指令序列的运行速度。有些是显而易见的，比如CPU和内存时钟速度，或者机器的负载情况，但许多因素则更加微妙。例如，您的内核版本可能会影响分页性能，您的用户名长度可能会改变内存布局，房间的温度可能会导致CPU降频。最终，如果您运行两次基准测试，很不可能得到相同的结果。实际上，即使使用相同的硬件，您可能观察到显著的差异。或者，从另一个角度来看，您的代码可能变得更慢或更快，但由于基准测试环境的差异，这种影响可能是不可见的。

- 消除性能结果中的所有差异是不可能的，除非您能够在一个高度多样化的机器群上重复运行基准测试。即使如此，我们仍然需要尽力处理测量差异，以从嘈杂的测量结果中提取出信号。在实践中，我们在对抗差异方面的最佳助手是多次运行每个基准测试，然后查看测量结果的分布，而不仅仅是单个结果。Rust 提供了一些工具来帮助我们。例如，与其问“这个函数平均运行多长时间？”，像 hdrhistogram 这样的 crate 可以让我们查看诸如“我们观察到的样本中有多少运行时间落在了 95% 的范围内？”这样的统计数据。为了更加严谨，我们可以使用统计学中的零假设检验等技术，以建立一些置信度，确保测量到的差异确实对应于真正的变化，而不仅仅是噪音。
  
##### 编译器优化

现在的编译器非常聪明。它们消除死代码，编译时计算复杂表达式，展开循环，并进行其他黑魔法，以从我们的代码中挤取出每一点性能。通常情况下，这很好，但当我们试图测量特定代码段的速度时，编译器的聪明才智可能会给我们带来无效的结果。例如，看一下清单 6-9 中用于对 Vec::push 进行基准测试的代码。

```rust

let mut vs = Vec::with_capacity(4);
let start = std::time::Instant::now();
for i in 0..4 {
vs.push(i);
}
println!("took {:?}", start.elapsed());
```

清单 6-9：一个可疑地快速的性能基准测试

- 如果你查看使用像 godbolt.org 或 cargo-asm 这样的工具编译的 release 模式下的汇编输出，你会立即注意到有些不对劲：对 Vec::with_capacity 和 Vec::push 的调用，以及整个 for 循环，都不见了。它们被完全优化掉了。编译器意识到代码中实际上没有需要执行的向量操作，并将其消除为死代码。当然，编译器完全有权这样做，但对于基准测试来说，这并不特别有帮助。
- 为了避免这些优化对基准测试的影响，标准库提供了 std::hint::black_box。这个函数在撰写本文时仍在讨论和混淆中，并且仍在等待稳定，但它非常有用，值得在这里讨论。在其核心，它只是一个恒等函数（接受 x 并返回 x），告诉编译器假设函数的参数以任意（合法）的方式使用。它不会阻止编译器对输入参数应用优化，也不会阻止编译器优化返回值的使用方式。相反，它鼓励编译器实际计算函数的参数（在假设参数将被使用的情况下），并将结果存储在对 CPU 可访问的某个地方，以便可以使用 black_box 调用计算出的值。编译器可以自由地在编译时计算输入参数，但它仍应将结果注入到程序中。

- 对于我们许多基准测试需求来说，这个函数就足够了，尽管不得不承认并非全部。例如，我们可以对清单 6-9 进行注释，以使向量访问不再被优化掉，如清单 6-10 所示。

```rust

let mut vs = Vec::with_capacity(4);
let start = std::time::Instant::now();
for i in 0..4 {
    black_box(vs.as_ptr());
    vs.push(i);
    black_box(vs.as_ptr());
}
println!("took {:?}", start.elapsed());
```

清单 6-10：清单 6-9 的修正版本

- 我们告诉编译器在每次循环迭代之前和之后，假设 vs 在任意方式上被使用，包括 push 调用。这迫使编译器按顺序执行每个 push，而不会合并或优化连续的调用，因为它必须假设在每个调用之间可能发生“无法优化掉的任意操作”（这就是 black_box 的作用）。
- 注意我们使用了 vs.as_ptr() 而不是 &vs。这是因为编译器应该假设 black_box 可以对其参数执行任何合法操作的一个警告。通过共享引用对 Vec 进行变异是不合法的，所以如果我们使用 black_box(&vs)，编译器可能会注意到 vs 在循环迭代之间不会改变，并基于这个观察实施优化！

###### I/O Overhead Measurement

在编写基准测试时，很容易意外地测量错误的内容。例如，我们经常希望实时获取有关基准测试进度的信息。为了做到这一点，我们可能会编写类似于清单 6-11 中的代码，旨在测量 my_function 的运行速度：

```rust

let start = std::time::Instant::now();
for i in 0..1_000_000 {
  println!("iteration {}", i);
  my_function();
}
println!("took {:?}", start.elapsed());
```

清单 6-11：我们真正在这里进行基准测试的是什么？

- 这看起来似乎达到了目标，但实际上它并没有真正测量 my_function 的速度。相反，这个循环很可能告诉我们打印一百万个数字需要多长时间。循环体中的 println! 在幕后做了很多工作：它将二进制整数转换为十进制数字进行打印，锁定标准输出，使用至少一个系统调用写出一系列 UTF-8 代码点，然后释放标准输出锁。不仅如此，如果您的终端打印输入的速度较慢，系统调用可能会阻塞。这是很多周期！而调用 my_function 的时间可能相形见绌。
- 当基准测试使用随机数时，类似的情况也会发生。如果你在循环中运行my_function(rand::random())，你可能主要测量的是生成一百万个随机数所花费的时间。对于获取当前时间、读取配置文件或启动新线程等操作也是如此，相对而言，这些操作都需要很长时间，可能会掩盖你实际想要测量的时间。
- 幸运的是，一旦你意识到这个问题，解决起来通常很容易。确保你的基准测试循环的主体几乎只包含你想要测量的特定代码。所有其他代码应该在基准测试开始之前或在基准测试的测量部分之外运行。如果你使用 criterion，可以看一下它提供的不同计时循环，它们都是为了满足需要不同测量策略的基准测试情况！

#### 摘要

在本章中，我们详细探讨了Rust提供的内置测试功能。我们还介绍了一些在测试Rust代码时有用的测试设施和技术。这是本书中关于中级Rust使用的高级方面的最后一章。从下一章关于声明式和过程式宏开始，我们将更加专注于Rust代码。下一页见！

### 7.MACROS

宏本质上是一种让编译器为您编写代码的工具。您给编译器一个根据一些输入参数生成代码的公式，编译器会将每次调用宏的地方替换为运行公式的结果。您可以将宏视为自动代码替换，其中您可以定义替换的规则。

- Rust的宏有很多不同的形式和大小，可以轻松实现许多不同形式的代码生成。主要有两种类型的宏：声明式宏和过程宏，我们将在本章中探讨这两种宏。我们还将介绍一些宏在日常编码中的便利之处，以及在更高级使用中可能出现的一些陷阱。
- 来自基于C的语言的程序员可能习惯于C和C++的邪恶之地，您可以使用#define将每个true更改为false，或者删除所有else关键字的出现。如果您是这种情况，您需要将宏与做一些“不好”的感觉分离开来。在Rust中，宏远非C宏的荒野西部。它们遵循（大多数）明确定义的规则，并且相当难以滥用。

#### Declarative Macros

声明式宏是使用`macro_rules!`语法定义的宏，它允许您方便地定义类似函数的宏，而无需编写专用的 crate（与过程宏不同）。一旦您定义了声明式宏，就可以使用宏的名称后跟感叹号来调用它。我喜欢将这种宏看作是一种编译器辅助的搜索和替换：它可以完成许多常规的、结构良好的转换任务，以及消除重复的样板代码。在您到目前为止对 Rust 的经验中，您认识的大多数宏可能都是声明式宏。但请注意，并非所有的函数式宏都是声明式宏；`macro_rules!` 本身就是一个例子，`format_args!` 是另一个例子。感叹号后缀只是告诉编译器，在编译时，宏调用将被替换为不同的源代码。

**注意** 由于Rust的解析器专门识别和解析带有!的宏调用，因此您只能在解析器允许的位置使用它们。它们可以在大多数您期望的位置使用，比如在表达式位置或impl块中，但并非所有地方都可以。例如，在需要标识符或匹配分支的位置，您（在撰写本文时）无法调用类似函数的宏。

- 或许并不立即明显为什么称呼声明式宏为声明式。毕竟，在你的程序中，你不是“声明”了一切吗？在这个上下文中，声明式指的是你不说出宏的输入应该如何转换为输出，只是说当输入为B时，你希望输出看起来像A。你声明它应该是这样的，编译器会找出所有必须发生的解析重连，使你的声明成为现实。这使得声明式宏简洁而富有表现力，尽管它们也往往变得相当晦涩，因为你只有有限的语言来表达你的声明。

##### 何时使用它们

声明式宏在你发现自己一遍又一遍地编写相同代码时非常有用，而你希望不再这样做。它们最适合于相对机械的替换——如果你想进行复杂的代码转换或大量的代码生成，那么过程宏可能更适合。

- 我最常使用声明式宏的情况是在我发现自己编写重复且结构相似的代码时，比如在测试和特性实现中。对于测试，我经常希望以稍微不同的配置运行相同的测试多次。我可能会像清单 7-1 中所示那样编写代码。

```rust

fn test_inner<T>(init: T, frobnify: bool) { ... }

# [test]

fn test_1u8_frobnified() {
test_inner(1u8, true);
}
// ...

# [test]

fn test_1i128_not_frobnified() {
test_inner(1i128, false);
}
```

清单 7-1：重复的测试代码
虽然这样可以工作，但它太冗长、太重复，而且容易出错。通过使用宏，我们可以做得更好，如清单 7-2 所示。

```rust
macro_rules! test_battery {
($($t:ty as $name:ident),*)) => {
$(
mod $name {

# [test]

fn frobnified() { test_inner::<$t>(1, true) }

# [test]

fn unfrobnified() { test_inner::<$t>(1, false) }
}
)*
}
}
test_battery! {
u8 as u8_tests,
// ...
i128 as i128_tests
);

```

清单 7-2：让宏为您重复

- 这个宏将每个逗号分隔的指令扩展为自己的模块，每个模块包含两个测试，一个调用带有true参数的test_inner，另一个调用带有false参数的test_inner。虽然宏的定义并不简单，但它使添加更多的测试变得更容易。在test_battery!调用中，每个类型占据一行，宏将负责生成针对true和false参数的测试。我们还可以让它为init的不同值生成测试。现在，我们大大降低了忘记测试特定配置的可能性！
- 对于trait实现，情况类似。如果你定义了自己的trait，通常你会希望为标准库中的一些类型实现该trait，即使这些实现是微不足道的。假设你发明了Clone trait，并希望为标准库中的所有Copy类型实现它。而不是手动为每个类型编写实现，你可以使用像清单7-3中的宏一样的工具。

```rust
macro_rules! clone_from_copy {
  ($($t:ty),_) => {
    $(impl Clone for $t {
      fn clone(&self) -> Self { *self }
    })*
  }
}
clone_from_copy![bool, f32, f64, u8, i8, /* ... */];
```

清单 7-3：使用宏一次性为许多相似类型实现 trait

- 在这里，我们为每个提供的类型生成了一个 Clone 的实现，其主体只是使用 * 从 &self 复制出来。你可能会想为什么我们不为 T: Copy 的类型添加一个 Clone 的通用实现。我们可以这样做，但一个很大的原因是它会强制其他 crate 中的类型也使用相同的 Clone 实现来处理它们自己的类型，而这些类型恰好是 Copy 的。一个名为 specialization 的实验性编译器特性可能提供了一种解决方法，但在撰写本文时，该特性的稳定化还有一段时间。因此，目前我们最好是具体列举这些类型。这种模式也不仅限于简单的转发实现：例如，你可以很容易地修改清单 7-3 中的代码，为所有整数类型实现一个 AddOne trait！
**注意** 如果你曾经想知道是否应该使用泛型还是声明式宏，那么你应该使用泛型。泛型通常比宏更符合人体工程学，并且与语言中的其他结构更好地集成。考虑以下经验法则：如果你的代码基于类型而变化，使用泛型；否则，使用宏。

##### How They Work

每种编程语言都有一种语法，它规定了如何将构成源代码的个别字符转换为标记（tokens）。
标记是语言的最低级构建块，例如数字、标点符号、字符串和字符字面量以及标识符；在这个级别上，语言关键字和变量名之间没有区别。例如，在类似Rust的语法中，文本(value + 4)将由五个标记序列(, value, +, 4, )表示。将文本转换为标记的过程还为编译器的其余部分和解析文本的低级细节提供了一层抽象。例如，在标记表示中，没有空白字符的概念，"/_foo_*/"和"/_foo_/"具有不同的表示（前者不是标记，后者是一个具有内容"/_foo_/"的字符串字面量标记）。

- 一旦源代码被转换为一系列的标记，编译器会遍历这个序列并为标记赋予语法意义。例如，以()为界定的标记组成一个组，!标记表示宏调用，等等。这就是解析的过程，最终产生了描述源代码结构的抽象语法树（AST）。举个例子，考虑表达式let x = || 4，它由一系列的标记组成：let（关键字）、x（标识符）、=（标点符号）、两个|（标点符号）和4（字面量）。当编译器将其转换为语法树时，它将其表示为一个语句，其模式是标识符x，右侧的表达式是一个没有参数的闭包，其主体是一个整数字面量4。请注意，语法树表示比标记序列更丰富，因为它根据语言的语法为标记组合赋予了语法意义。
- Rust宏决定了给定一系列标记被转换成的语法树。当编译器在解析过程中遇到宏调用时，它必须评估宏以确定替换的标记，这些标记最终将成为宏调用的语法树。然而，在这一点上，编译器仍然在解析标记，可能还没有准备好评估宏，因为它只是解析了宏定义的标记。因此，编译器推迟解析宏调用括号内的任何内容，并记住输入的标记序列。当编译器准备好评估指定的宏时，它在标记序列上评估宏，解析生成的标记，并将结果的语法树替换到宏调用的位置。
- 从技术上讲，编译器确实对宏的输入进行了一些解析。具体来说，它解析出基本的内容，如字符串字面量和分隔的组，并生成一系列的标记树，而不仅仅是标记。例如，代码x - (a.b + 4)解析为三个标记树的序列。第一个标记树是一个单独的标记，即标识符x，第二个标记树是一个单独的标记，即标点符号-，第三个标记树是一个组（使用括号作为分隔符），它本身由五个标记树组成：a（一个标识符）、.（标点符号）、b（另一个标识符）、+（另一个标点符号）和4（一个字面量）。这意味着宏的输入不一定是有效的Rust代码，但它必须由Rust编译器可以解析的代码组成。例如，你不能在Rust中写for <- x，但在宏调用内部可以，只要宏生成有效的语法。另一方面，你不能将for {传递给宏，因为它没有闭合的大括号。
- 声明宏始终生成有效的 Rust 代码作为输出。你不能让宏生成函数调用的前半部分或者没有后续代码块的 if 语句。声明宏必须生成一个表达式（基本上任何可以赋值给变量的东西）、一个语句（比如 let x = 1;）、一个项（如 trait 定义或 impl 块）、一个类型或者一个匹配模式。这使得 Rust 宏不容易被滥用：你简单地不能编写一个生成无效 Rust 代码的声明宏，因为宏定义本身就无法编译通过！
- 从高层次来看，这就是声明式宏的全部内容 - 当编译器遇到宏调用时，它将传递给宏的标记解析为标记流，并用生成的抽象语法树替换宏调用。

##### How to Write Declarative Macros

详细解释声明式宏支持的所有语法超出了本书的范围。然而，我们将介绍一些基础知识，因为有一些值得注意的奇怪之处。

- 声明式宏由两个主要部分组成：匹配器和转录器。
一个给定的宏可以有多个匹配器，每个匹配器都有一个关联的转录器。
当编译器找到一个宏调用时，它会从第一个到最后一个遍历宏的匹配器，
当它找到一个与调用中的标记匹配的匹配器时，它会通过遍历相应转录器的标记来替换调用。
清单 7-4 展示了声明式宏规则的不同部分如何组合在一起。

```rust
macro_rules! /_macro name _/ {
(/_ 1st matcher _/) => { /_ 1st transcriber _/ };
(/_ 2nd matcher _/) => { /_ 2nd transcriber_/ };
}
```

清单 7-4：声明式宏定义组件

##### 匹配器

- 您可以将宏匹配器视为编译器尝试以预定义的方式扭曲和弯曲以匹配在调用点给定的输入标记树的标记树。例如，考虑具有匹配器$a:ident + $b:expr的宏。该匹配器将匹配任何标识符（:ident）后跟加号，后跟任何Rust表达式（:expr）。如果使用x + 3 _5调用宏，编译器会注意到匹配器在设置$a = x和$b = 3_5时匹配。即使在匹配器中没有出现_，编译器也意识到3_5是一个有效的表达式，因此可以与接受任何表达式的$b:expr匹配（:expr部分）。

- 匹配器可以变得非常复杂，但它们具有巨大的表达能力，就像正则表达式一样。以一个不太复杂的例子为例，这个匹配器接受一个以 key => value 格式给出的逗号分隔的键值对序列 ($())，其中至少有一个 (+) 键值对：

```rust
$($key:expr => $value:expr),+

```

而且，至关重要的是，使用这个匹配器调用宏的代码可以为键或值提供任意复杂的表达式 - 匹配器的魔力会确保键和值表达式被适当地分割。

- 宏规则支持各种片段类型；你已经看到了标识符的 :ident 和表达式的 :expr，还有类型的 :ty，甚至还有任何单个标记树的 :tt！你可以在 Rust 语言参考手册的第三章中找到片段类型的完整列表[（https://doc.rust-lang.org/reference/macros-by-example.html）]。这些片段类型，再加上重复匹配模式的机制（$()），使你能够匹配大多数简单的代码模式。然而，如果你发现使用匹配器难以表达你想要的模式，你可以尝试使用过程宏，其中你不需要遵循 macro_rules! 所要求的严格语法。我们将在本章后面更详细地介绍这些内容。

##### Transcribers

- 一旦编译器匹配了声明式宏的匹配器，它就会使用匹配器关联的转录器生成代码。宏匹配器定义的变量被称为元变量，编译器会将转录器中的每个元变量的出现替换为与匹配器中相应部分匹配的输入。如果匹配器中有重复（如前面示例中的$()，+），您可以在转录器中使用相同的语法，它将根据输入中的每个匹配重复一次，并且每个扩展都包含适当的替换值。例如，对于$key和$value匹配器，我们可以编写以下转录器，为每个匹配的$key/$value对生成一个插入调用到某个映射中：

```rust
$(map.insert($key, $value);)+
```

- 注意，在这里我们希望每次重复都有一个分号，而不仅仅是用于分隔重复，因此我们将分号放在重复的括号内。

**注意** 在转录器中的每个重复中，您必须使用一个元变量，以便编译器知道在匹配器中使用哪个重复（如果有多个）。

##### Hygiene

你可能听说过 Rust 的宏是清洁的，也许认为它们的清洁性使它们更安全、更易于使用，但可能并不完全理解这是什么意思。当我们说 Rust 的宏是清洁的时，我们的意思是声明式宏（通常）不能影响未显式传递给它的变量。一个简单的例子是，如果你声明了一个名为 foo 的变量，然后调用一个也定义了名为 foo 的变量的宏，那么默认情况下，宏的 foo 在调用点（宏被调用的地方）是不可见的。同样地，宏不能访问在调用点定义的变量（甚至是 self），除非它们被显式传递进来。
大多数情况下，你可以将宏标识符视为存在于与它们展开的代码不同的命名空间中。举个例子，看一下清单 7-5 中的代码，其中有一个宏试图（但失败了）在调用点遮蔽一个变量。

```rust

macro_rules! let_foo {
  ($x:expr) => {
    let foo = $x;
  }
}
let foo = 1;
// expands to let foo = 2;
let_foo!(2);
assert_eq!(foo, 1);

```

清单 7-5：宏存在于它们自己的小宇宙中。大多数情况下。

- 在编译器展开 let_foo!(2) 后，assert 看起来应该会失败。然而，原始代码中的 foo 和宏生成的 foo 存在于不同的宇宙中，除了它们恰好共享一个可读的名称之外，它们之间没有任何关系。实际上，编译器会抱怨宏中的 let foo 是一个未使用的变量。这种隔离对于使宏更容易调试非常有帮助 - 你不必担心因为选择了相同的变量名而意外遮蔽或覆盖宏调用者中的变量！
- 然而，这种清洁的分离并不适用于除变量标识符之外的内容。声明式宏与调用点共享类型、模块和函数的命名空间。这意味着你的宏可以定义新的函数，在调用点处调用它们，为在其他地方定义的类型添加新的实现（而不是传递进来的类型），引入一个新的模块，然后可以在宏被调用的地方访问它，等等。这是有意设计的 - 如果宏不能影响更广泛的代码，那么使用宏生成类型、特性实现和函数将变得更加繁琐，而这正是它们最有用的地方。
- 当编写一个希望从你的 crate 中导出的宏时，宏中类型的缺乏清洁性尤为重要。为了使宏真正可重用，你不能假设调用方的作用域中会有什么类型。也许调用你的宏的代码定义了一个 mod std {}，或者导入了自己的 Result 类型。为了保险起见，确保使用完全指定的类型，如 ::core::option::Option 或 ::alloc::boxed::Box。如果你特别需要引用定义宏的 crate 中的内容，可以使用特殊的元变量 $crate。
  
**注意** 如果可能的话，避免使用 ::std 路径，以便宏在 no_std crate 中继续工作。

- 如果你希望宏影响调用者作用域中的特定变量，你可以选择在宏和调用者之间共享标识符。关键是记住标识符的来源，因为它将与该命名空间绑定。如果在宏中放置 let foo = 1;，那么标识符 foo 的来源是宏，将永远不会在调用者的标识符命名空间中可用。另一方面，如果宏以 $foo:ident 作为参数，然后写入 let $foo = 1;，当调用者使用 !(foo) 调用宏时，标识符将源自调用者，并且将引用调用者作用域中的 foo。

- 标识符不必如此明确地传递；在宏外部源自代码中出现的任何标识符都将引用调用者作用域中的标识符。在清单 7-6 的示例中，变量标识符出现在 :expr 中，但仍然可以访问调用者作用域中的变量。

```rust
macro_rules! please_set {
($i:ident, $x:expr) => {
  $i = $x;
  }

}
let mut x = 1;
please_set!(x, x + 1);
assert_eq!(x, 2);
```

清单 7-6：让宏在调用点处访问标识符

- 我们可以在宏中使用 = $i + 1，但是我们不能使用 = x + 1，因为宏的定义范围中没有名为 x 的变量。
- 关于声明式宏和作用域的最后一点说明：与 Rust 中的几乎所有其他内容不同，声明式宏只有在声明后才存在于源代码中。如果您尝试在文件中后面定义的位置使用宏，这是行不通的！这适用于整个项目；如果您在一个模块中声明了一个宏，并希望在另一个模块中使用它，那么声明宏的模块必须出现在 crate 中的较早位置，而不是较晚位置。如果 foo 和 bar 是 crate 根目录下的模块，并且 foo 声明了一个 bar 想要使用的宏，那么 mod foo 必须在 lib.rs 中出现在 mod bar 之前！
**注意** 这种奇怪的宏作用域规则有一个例外（正式称为文本作用域），即如果你使用#[macro_export]标记宏。这个注解将宏提升到crate的根部，并将其标记为pub，以便它可以在你的crate中的任何地方或者被你的crate的依赖项使用。

#### Procedural Macros

- 你可以将过程宏看作是解析器和代码生成的组合，其中你在中间编写粘合代码。在高层次上，使用过程宏，编译器收集到宏的输入令牌序列，并运行你的程序来确定要用什么令牌替换它们。
- 过程宏之所以被称为过程宏，是因为你定义了如何根据一些输入令牌生成代码，而不仅仅是编写生成的代码。编译器在这方面几乎没有太多智能的参与 - 就它所知，过程宏更像是一个源代码预处理器，可以任意替换代码。你的输入仍然需要能够被解析为一系列 Rust 令牌的流，但仅此而已！

##### Types of Procedural Macros

过程宏有三种不同的类型，每种类型都专门用于特定的常见用例：
• 函数宏，例如由 macro_rules! 生成的宏
• 属性宏，例如 #[test]
• 派生宏，例如 #[derive(Serialize)]
这三种类型使用相同的底层机制：编译器会向宏提供一系列的标记，并期望你返回一系列与输入树（可能）相关的标记。然而，它们在宏的调用方式和输出处理方式上有所不同。我们将简要介绍每一种类型。

###### Function-Like Macros

函数宏是过程宏中最简单的形式。与声明式宏类似，它只是将调用点处的宏代码替换为过程宏返回的代码。然而，与声明式宏不同，函数宏没有任何限制：这些宏（像所有的过程宏一样）不需要是清洁的，并且不会保护您免受与调用点周围代码中的标识符交互的影响。相反，您的宏应该明确指出哪些标识符应与周围代码重叠（使用Span::call_site），哪些应该被视为宏的私有标识符（使用Span::mixed_site，我们稍后会讨论）。

###### Attribute Macros

属性宏还会整体替换属性所赋予的项，但它接受两个输入：出现在属性中的标记树（不包括属性的名称）和整个项的标记树，包括该项可能具有的其他属性。属性宏允许您轻松编写一个过程宏，用于转换项，例如通过向函数定义添加前言或尾声（类似于 #[test] 的作用）或通过修改结构体的字段。

###### Derive Macros

派生宏与其他两种宏略有不同，它是在目标宏的基础上添加内容，而不是替换它。尽管这种限制可能看起来严格，但派生宏是创建过程宏的最初动机之一。具体来说，serde crate 需要派生宏来实现其现在广为人知的 # [derive(Serialize, Deserialize)] 魔法。

- 派生宏可以说是过程宏中最简单的形式，因为它们具有非常严格的形式：只能在注解项之后追加项；不能替换注解项，也不能让派生接受参数。派生宏允许您定义辅助属性 - 可以放置在注解类型内部以向派生宏提供提示（例如 #[serde(skip)]） - 但这些属性主要起到标记的作用，不是独立的宏。

###### The Cost of Procedural Macros

在讨论不同的过程宏类型何时适用之前，值得讨论一下为什么在使用过程宏之前你可能要三思而后行，即增加的编译时间。

- 过程宏会显著增加编译时间，主要有两个原因。首先，它们往往会带来一些相当重的依赖项。例如，syn crate 提供了一个用于解析 Rust 令牌流的解析器，使编写过程宏的体验更加容易，但启用所有功能时，它可能需要几十秒的编译时间。您可以通过禁用不需要的功能并在调试模式下编译过程宏来缓解这个问题。在调试模式下，代码的编译速度通常会快几倍，对于大多数过程宏来说，您甚至不会注意到执行时间的差异。
- 第二个增加编译时间的原因是，过程宏使您能够生成大量代码而不自知。虽然宏可以帮助您省去实际输入生成的代码的步骤，但编译器仍然需要解析、编译和优化它。随着您使用更多的过程宏，生成的样板代码会累积起来，并且可能会导致编译时间膨胀。
- 话虽如此，实际执行过程宏的时间很少成为整体编译时间的因素。虽然编译器必须等待过程宏完成其任务才能继续，但实际上，大多数过程宏不会进行任何重型计算。然而，如果你的过程宏特别复杂，你的编译可能会在过程宏代码上花费大量的执行时间，这值得注意！

###### So You Think You Want a Macro

现在让我们来看看每种类型的过程宏的一些好的用途。我们先从简单的开始：派生宏。

###### When to Use Derive Macros

- 派生宏只用于一件事，那就是在可能的情况下自动实现一个trait。并非所有的trait都有明显的自动实现，但很多都有。实际上，只有在以下两个条件满足时，才应考虑为一个trait添加派生宏：该trait经常被实现，并且对于任何给定的类型，其实现是相当明显的。第一个条件可能是常识；如果您的trait只会被实现一两次，那么编写和维护一个复杂的派生宏可能不值得。
- 第二个条件可能看起来更奇怪：什么是“明显”的实现？考虑一个像 Debug 这样的 trait。如果你被告知 Debug 做什么，并展示一个类型，你可能期望 Debug 的实现会在调试表示的值旁边输出每个字段的名称。而 derive(Debug) 就是这样做的。那 Clone 呢？你可能期望它只是克隆每个字段 - 而 derive(Clone) 正是这样做的。对于 derive(serde::Serialize)，我们期望它序列化每个字段及其值，它也确实如此。总的来说，你希望一个 trait 的派生与开发者对其可能的实现的直觉相匹配。如果一个 trait 没有明显的派生方式，或者更糟糕的是，如果你的派生与明显的实现不匹配，那么最好不要给它一个派生宏。

###### When to Use Function-Like Macros

对于函数宏，很难给出一个普遍适用的经验法则。你可以说当你想要一个函数宏但无法用macro_rules!表达时，你应该使用函数宏，但这是一个相当主观的指导方针。毕竟，如果你真的下了决心，你可以用声明式宏做很多事情！

- 有两个特别好的理由可以使用函数宏：
• 如果你已经有一个声明式宏，并且它的定义变得非常复杂，以至于很难维护。
• 如果你有一个纯函数，需要在编译时执行，但无法用 const fn 表达。一个例子是 phf crate，它在给定一组在编译时提供的键时，使用完美哈希函数生成哈希映射或集合。另一个例子是 hex-literal，它接受一个十六进制字符的字符串，并将其替换为相应的字节。总的来说，任何不仅仅在编译时转换输入，而是实际上对其进行计算的内容都有可能成为一个很好的候选。
- 我不建议仅仅为了打破宏的卫生性而使用函数宏。函数宏的卫生性是一个避免许多调试头疼的特性，你应该在有意打破它之前仔细考虑。

###### When to Use Attribute Macros

这样我们就只剩下属性宏了。虽然可以说属性宏是过程宏中最通用的一种，但也是最难确定何时使用的。多年来，我一次又一次地看到属性宏在以下四个方面增加了巨大的价值。

**Test generation**
很常见的情况是希望在多个不同的配置下运行相同的测试，或者在相同的引导代码下运行许多类似的测试。虽然声明式宏可以让您表达这一点，但如果您有一个类似 #[foo_test] 的属性，它在每个注解测试中引入了一个设置前导和尾声，或者一个可重复的属性像 #[test_case(1)] #[test_case(2)] 来标记一个给定的测试应该重复多次，每次都有不同的输入，那么您的代码通常更易于阅读和维护。

###### Framework annotations

像 rocket 这样的库使用属性宏来增强函数和类型，为框架提供额外的信息，而无需用户进行大量手动配置。使用 #[get("/<name>")] fn hello(name: String) 比设置一个包含函数指针等内容的配置结构要方便得多。实质上，这些属性构成了一个迷你领域特定语言（DSL），隐藏了许多必要的样板代码。
类似地，异步 I/O 框架 tokio 允许您使用 #[tokio::main] async fn main() 来自动设置运行时并运行您的异步代码，从而避免在每个异步应用程序的主函数中编写相同的运行时设置。

###### Transparent middleware

有些库希望以不显眼的方式注入到您的应用程序中，以提供不改变应用程序功能的附加价值。例如，tracing和logging库（如tracing）以及度量收集库（如metered）允许您通过向函数添加属性来透明地对其进行仪器化，然后每次调用该函数时，都会运行由库指定的一些额外代码。

###### Type transformers

有时候，你想要超越仅仅为类型派生trait，而是在某种根本的方式上改变类型的定义。在这种情况下，属性宏是一个很好的选择。pin_project crate就是一个很好的例子：它的主要目的不是实现特定的trait，而是确保对给定类型的字段进行固定访问时，按照Rust的Pin类型和Unpin trait所规定的严格规则进行操作（我们将在第8章中详细讨论这些类型）。它通过生成额外的辅助类型，为注解类型添加方法，并引入静态安全检查来确保用户不会意外地自找麻烦。虽然pin_project可以使用过程宏来实现，但派生的trait实现可能不够明显，这违反了我们在何时使用过程宏的规则之一。

#### How Do They Work?

在所有过程宏的核心是 TokenStream 类型，可以迭代它以获取组成该令牌流的单个 TokenTree 项。TokenTree 可以是单个令牌，如标识符、标点符号或字面量，也可以是另一个由括号（()）或大括号（{}）括起来的 TokenStream。通过遍历 TokenStream，您可以解析出任何您希望的语法，只要单个令牌是有效的 Rust 令牌。如果您希望将输入解析为 Rust 代码，您可能需要使用 syn crate，它实现了一个完整的 Rust 解析器，并可以将 TokenStream 转换为易于遍历的 Rust AST。

- 对于大多数过程宏，你不仅需要解析 TokenStream，还需要生成要注入到调用过程宏的程序中的 Rust 代码。有两种主要的方法可以实现这一点。第一种方法是手动构建一个 TokenStream，并逐个 TokenTree 扩展它。第二种方法是使用 TokenStream 的 FromStr 实现，它允许你将包含 Rust 代码的字符串解析为 TokenStream，例如 "".parse::<TokenStream>()。你也可以混合使用这两种方法；如果你想在宏的输入之前添加一些代码，只需构建一个用于前言的 TokenStream，然后使用 Extend trait 将原始输入追加到其中。
**注意**，TokenStream还实现了Display，可以将流中的令牌漂亮地打印出来。
这对于调试非常有用！
令牌比我之前描述的稍微神奇一些，因为每个令牌，实际上每个TokenTree，都有一个范围。范围是编译器将生成的代码与生成它的源代码关联起来的方式。
每个令牌的范围标记了该令牌的起源位置。例如，考虑列表7-7中的（声明式）宏，它为提供的类型生成了一个简单的Debug实现。

```rust

macro_rules! name_as_debug {
  ($t:ty) => {
    impl ::core::fmt::Debug for $t {
      fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result{ 
        ::core::write!(f, ::core::stringify!($t)) 
      }
    } 
  };
}
```

清单7-7：一个非常简单的用于实现Debug的宏

- 现在让我们假设有人使用 name_as_debug!(u31) 调用这个宏。从技术上讲，编译器错误发生在宏内部，具体来说是在我们为 $t 编写的地方（$t 的另一个用法可以处理无效的类型）。但是我们希望编译器将用户指向他们代码中的 u31，并且确实，这就是范围让我们能够做到的。
- 在生成的代码中，$t 的范围是映射到宏调用中的 $t 的代码。这些信息会通过编译器传递，并与最终的编译器错误关联起来。当编译器最终打印出该错误时，它会从宏内部打印错误，指出类型 u31 不存在，但会在宏调用中突出显示 u31 参数，因为这是错误的关联范围！

- 范围非常灵活，它使您能够编写可以生成复杂错误消息的过程宏，如果您使用 compile_error! 宏。正如其名称所示，compile_error! 会导致编译器在其所放置的位置发出错误，提供的字符串作为消息。这可能看起来并不是很有用，直到您将其与范围配对。通过将生成的 TokenTree 的范围设置为与输入的某个子集的范围相等，您实际上是告诉编译器发出此编译器错误，并将用户指向源代码的这部分。通过这两种机制，宏可以产生看起来源自代码相关部分的错误，即使实际的编译器错误在用户甚至从未看到的生成代码中！

**注意** 如果您曾经对syn的错误处理方式感到好奇，它的Error类型实现了Error::to_compile_error方法，将其转换为仅包含compile_error!指令的TokenStream。特别有趣的是，syn的Error类型内部保存了一组错误，每个错误都产生一个具有自己范围的独立compile_error!指令，因此您可以轻松地从您的过程宏中产生多个独立的错误。

- 跨度的威力不止于此；跨度也是 Rust 宏卫生的实现方式。当你构造一个 Ident 令牌时，你还要给出该标识符的跨度，而该跨度决定了该标识符的作用域。如果你将标识符的跨度设置为 Span::call_site()，则该标识符将在调用宏的地方解析，并且不会与周围的作用域隔离。另一方面，如果你将其设置为 Span::mixed_site()，那么（变量）标识符将在宏定义的地方解析，因此在调用点处与同名变量完全卫生。Span::mixed_site 之所以被称为这样，是因为它符合 macro_rules! 的标识符卫生规则，正如我们之前讨论的那样，它在变量上“混合”了标识符解析，使用宏定义的地方解析变量，使用调用点解析类型、模块和其他所有内容。

#### Summary

在本章中，我们介绍了声明式宏和过程宏，并讨论了在编写自己的宏时需要注意的一些机制、特性和注意事项。在下一章中，我们将开始探索异步编程和Future trait。我保证，它就在下一页上。

### 8.异步编程

在深入了解异步编程模型的细节之前，我们首先需要了解一下替代方案是什么。也就是说，我们需要先了解同步编程模型。这对于澄清概念并展示使用异步编程的权衡是很重要的：异步解决方案并不总是正确的选择！我们将从快速了解异步编程的动机开始，然后深入探讨Rust中异步的实际工作原理。

#### What’s the Deal with Asynchrony?

在深入了解同步和异步编程模型的细节之前，我们首先需要快速了解一下当计算机运行程序时实际发生的情况。

- 计算机速度非常快。真的非常快。事实上，它们大部分时间都在等待事情发生。除非你在解压文件、编码音频或进行数值计算，否则你的CPU大部分时间都处于空闲状态，等待操作完成。它在等待网络数据包到达，等待鼠标移动，等待磁盘完成写入一些字节，甚至只是等待从主内存读取完成。从CPU的角度来看，这些事件之间经过了漫长的时间。当一个事件发生时，CPU会运行几条指令，然后再次进入等待状态。看一下你的CPU利用率，可能只有个位数的低水平，这很可能是大部分时间的情况。

##### 同步接口

同步接口允许你的程序（或者说，程序中的一个线程）一次只执行一个操作；每个操作都必须等待前一个同步操作完成后才能运行。大多数你在实际开发中见到的接口都是同步的：你调用它们，它们会执行一些操作，最终在操作完成后返回，你的程序可以从那里继续执行。之所以如此，我们将在本章后面看到，是因为使操作异步化需要额外的机制。除非你需要异步的好处，否则坚持同步模型需要更少的繁文缛节。

- 同步接口隐藏了所有这些等待过程；应用程序调用一个函数，该函数说“将这些字节写入这个文件”，然后一段时间后，该函数完成，下一行代码执行。在幕后，真正发生的是操作系统将写操作排队到磁盘，然后将应用程序置于休眠状态，直到磁盘报告写操作已完成。应用程序将此视为函数执行时间很长，但实际上它根本没有执行，只是在等待。
- 以这种方式按顺序执行操作的接口通常也被称为阻塞接口，因为在接口中，等待某个外部事件发生以使操作继续进行的操作会阻塞进一步的执行，直到该事件发生。无论您将接口称为同步还是阻塞，基本思想都是一样的：应用程序在当前操作完成之前不会继续执行。当操作等待时，应用程序也会等待。
同步接口通常被认为易于使用和简单推理，因为您的代码一次只执行一行。但它们也只允许应用程序一次只能做一件事。这意味着如果您希望程序等待用户输入或网络数据包，除非您的操作系统提供了专门用于此目的的操作，否则您将无法实现。同样地，即使您的应用程序在磁盘写入文件时可以执行其他有用的工作，但由于文件写入操作会阻塞执行，它也无法选择这个选项！

##### Multithreading

到目前为止，允许并发执行的最常见解决方案是使用多线程。在多线程程序中，每个线程负责执行特定的独立的阻塞操作序列，操作系统通过多路复用来在线程之间切换，以便如果任何一个线程可以取得进展，就会有进展。如果一个线程被阻塞，可能仍然有其他线程可运行，因此应用程序可以继续进行有用的工作。

- 通常，这些线程使用锁或通道等同步原语进行通信，以便应用程序仍然可以协调它们的工作。例如，您可能有一个线程等待用户输入，一个线程等待网络数据包，另一个线程等待这两个线程之一在所有三个线程之间共享的通道上发送消息。
- 多线程提供了并发性，即能够同时执行多个独立的操作。由运行应用程序的系统（在本例中为操作系统）选择未被阻塞的线程，并决定下一个要执行的线程。如果一个线程被阻塞，它可以选择运行另一个可以取得进展的线程。
- 多线程结合阻塞接口可以让你走得很远，很多生产级软件都是这样构建的。但是这种方法也有其缺点。首先，跟踪所有这些线程很快变得繁琐；如果你必须为每个并发任务启动一个线程，包括等待键盘输入这样简单的任务，线程数量会迅速增加，需要额外的复杂性来跟踪所有这些线程的交互、通信和协调。
- 其次，随着线程数量的增加，线程之间的切换成本也会增加。每当一个线程停止运行，另一个线程开始运行时，您需要进行一次往返到操作系统调度程序，这是不免费的。在某些平台上，创建新线程也是一个相当重量级的过程。具有高性能需求的应用程序通常通过重用线程并使用允许您在许多相关操作上阻塞的操作系统调用来减轻这个成本，但最终您仍然面临同样的问题：阻塞接口要求您拥有与要进行阻塞调用数量相同的线程。
- 最后，线程将并行性引入到您的程序中。并发和并行的区别微妙但重要：并发意味着任务的执行是交错的，而并行意味着多个任务同时执行。如果您有两个任务，它们的执行在ASCII中可能看起来像 _-_-_（并发）与=====（并行）。多线程不一定意味着并行性——即使您有多个线程，您可能只有一个核心，因此在给定时间只有一个线程在执行——但这两者通常是相辅相成的。您可以通过使用Mutex或其他同步原语使两个线程在执行上互斥，但这会引入额外的复杂性——线程希望并行运行。虽然并行通常是一件好事——谁不希望他们的程序在更多的核心上运行得更快——但这也意味着您的程序必须处理对共享数据结构的真正同时访问。这意味着从Rc、Cell和RefCell转移到更强大但也更慢的Arc和Mutex。虽然您可能希望在并发程序中使用后者类型以实现并行性，但线程强制您使用它们。我们将在第10章中更详细地讨论多线程。

##### Asynchronous Interfaces

现在我们已经探索了同步接口，我们可以看看另一种选择：异步或非阻塞接口。异步接口是一种可能不会立即产生结果的接口，而是可能指示结果将在稍后的某个时间可用。这使调用者有机会在此期间做其他事情，而不必一直等待直到特定操作完成。在Rust中，异步接口是一个返回Poll的方法，如清单8-1所定义。

```rust

enum Poll<T> {
  Ready(T),
  Pending
}
```

清单8-1：异步的核心：“现在给你或稍后回来”的类型

- Poll通常出现在以poll开头的函数的返回类型中，这些函数是指它们可以尝试执行操作而不阻塞的方法。我们将在本章后面详细介绍它们是如何做到这一点的，但总的来说，它们会尝试在通常会阻塞之前尽可能多地执行操作，然后返回。关键是，它们会记住它们离开的位置，以便在以后可以再次进行额外的进展时恢复执行。
- 这些非阻塞函数使我们能够轻松地同时执行多个任务。例如，如果您想从网络或用户的键盘读取数据，只需在循环中轮询两者，直到其中一个返回 Poll::Ready。无需额外的线程或同步！
- 这里的循环一词可能会让你有些紧张。当可能需要几分钟才能发生下一次输入时，你不希望程序每秒循环三十亿次。在阻塞接口的世界中，这不是一个问题，因为操作系统会将线程置于休眠状态，并在发生相关事件时唤醒它，但在这个新的非阻塞世界中，我们如何避免在等待时消耗计算资源？这就是本章剩余部分将要讨论的内容。

#### 标准化的轮询

为了实现每个库都可以以非阻塞的方式使用，我们可以让每个库的作者自己编写自己的轮询方法，这些方法的名称、签名和返回类型都略有不同，但这很快就会变得难以管理。相反，在Rust中，通过Future trait来标准化轮询。清单8-2展示了Future的简化版本（我们稍后会回到真正的版本）。

```rust

trait Future {
  type Output;
  fn poll(&mut self) -> Poll<Self::Output>;
}
```

清单8-2：Future trait的简化视图

- 实现Future trait的类型被称为futures，表示可能尚不可用的值。一个future可以表示下一个网络数据包到达的时间、鼠标光标移动的时间，或者只是某个时间段已经过去的时间点。您可以将Future<Output = Foo>理解为“将在Future产生一个Foo类型的值的类型”。在其他语言中，这样的类型通常被称为promises，它们承诺最终会产生指定的类型。当一个future最终返回Poll::Ready(T)时，我们说该future解析为T类型。

- 有了这个trait，我们可以将提供poll方法的模式泛化。不再需要像poll_recv和poll_keypress这样的方法，而是可以使用像recv和keypress这样的方法，它们都返回具有适当Output类型的impl Future。这并不改变您必须对它们进行轮询的事实——我们稍后会处理这个问题——但至少意味着这些待处理值有了一个标准化的接口，我们不需要在每个地方都使用poll_前缀。

**注意** 通常情况下，在一个future返回了Poll::Ready之后，不应该再次对其进行轮询。如果这样做，future有权抛出panic。一个在返回Ready后仍然安全进行轮询的future有时被称为融合的future。

#### Ergonomic Futures

按照我之前描述的方式编写实现Future的类型非常麻烦。为了理解原因，首先看一下清单8-3中的相当直观的异步代码块，它只是尝试将输入通道rx中的消息转发到输出通道tx。

```rust
async fn forward<T>(rx: Receiver<T>, tx: Sender<T>) {
  while let Some(t) = rx.next().await {
    tx.send(t).await;
  }
}
```

清单8-3：使用async和await实现通道转发future

- 这段使用async和await语法编写的代码与其等效的同步代码非常相似，易于阅读。我们只是在一个循环中发送接收到的每个消息，直到没有更多的消息，每个await点对应于同步变体可能阻塞的地方。现在想象一下，如果您必须通过手动实现Future trait来表达这段代码。由于每次调用poll都从函数的顶部开始，您需要打包必要的状态以从代码中上次暂停的位置继续执行。结果相当丑陋，如清单8-4所示。

- This code, written using async and await syntax, looks very similar to its
equivalent synchronous code and is easy to read. We simply send each message
we receive in a loop until there are no more messages, and each await
point corresponds to a place where a synchronous variant might block. Now
think about if you instead had to express this code by manually implementing
the Future trait. Since each call to poll starts at the top of the function,
you’d need to package the necessary state to continue from the last place
the code yielded. The result is fairly grotesque, as Listing 8-4 demonstrates.

```rust

enum Forward<T> { 1
  WaitingForReceive(ReceiveFuture<T>, Option<Sender<T>>),
  WaitingForSend(SendFuture<T>, Option<Receiver<T>>),
}
impl<T> Future for Forward<T> {
  type Output = (); 2
  fn poll(&mut self) -> Poll<Self::Output> {
    match self { 3
      Forward::WaitingForReceive(recv, tx) => {
      if let Poll::Ready((rx, v)) = recv.poll() {
        if let Some(v) = v {
          let tx = tx.take().unwrap(); 4
          *self = Forward::WaitingForSend(tx.send(v), Some(rx)); 5
// Try to make progress on sending.
          return self.poll(); 6
        } else {
// No more items.
        Poll::Ready(())
      }
    } else {
      Poll::Pending
    }
  }
  Forward::WaitingForSend(send, rx) => {
    if let Poll::Ready(tx) = send.poll() {
      let rx = rx.take().unwrap();
      *self = Forward::WaitingForReceive(rx.receive(), Some(tx));
  // Try to make progress on receiving.
      return self.poll();
    } else {
      Poll::Pending
    }
  }
  }
}
}
```

清单8-4：手动实现通道转发future

在 Rust 中，您很少需要编写这样的代码，但它能够深入了解底层工作原理，因此让我们一起来看看。首先，我们将Future类型定义为一个枚举 1，我们将使用它来跟踪当前正在等待的操作。这是因为当我们返回 Poll::Pending 时，下一次调用 poll 将再次从函数顶部开始。我们需要一种方式来知道我们中途停下来的位置，以便知道要继续哪个操作。此外，根据我们的操作不同，我们需要跟踪不同的信息：如果我们正在等待接收完成，我们需要保留 ReceiveFuture（此示例中未显示其定义），以便在下次自己被轮询时对其进行轮询；对于 SendFuture 也是如此。这里的 Option 可能让您感到奇怪；我们稍后会详细解释。

- 当我们为Forward实现Future时，将其输出类型声明为() 2，因为这个future实际上不返回任何东西。相反，当它完成从输入通道到输出通道的所有转发时，该future解析（没有结果）。在一个更完整的示例中，我们的转发类型的Output可能是一个Result，以便它可以将receive()和send()的错误传递回堆栈，以便轮询转发完成的函数。但是这段代码已经足够复杂了，所以我们将把它留到以后再说。
- 当对Forward进行轮询时，它需要从上次离开的地方继续执行，我们可以通过匹配当前存储在self中的枚举变体来找到 3。对于我们进入的任何分支，第一步是对阻止当前操作进展的Future进行轮询；如果我们尝试接收，我们轮询ReceiveFuture，如果我们尝试发送，我们轮询SendFuture。如果轮询调用返回Poll::Pending，则我们无法取得任何进展，我们自己返回Poll::Pending。但是如果当前的Future解析了，我们就有工作要做！
- 当内部的某个future解析时，我们需要通过切换存储在self中的枚举变体来更新当前操作。为了做到这一点，我们必须移出self以调用Receiver::receive或Sender::send，但我们不能这样做，因为我们只有&mut self。因此，我们将需要移动的状态存储在Option中，并使用Option::take来移出 4。这有点愚蠢，因为我们马上就要覆盖self 5，因此Options总是Some，但有时需要一些技巧来让借用检查器满意。
- 最后，如果我们取得了进展，我们再次对self进行轮询 6，以便如果我们可以立即在挂起的发送或接收上取得进展，我们就这样做。实际上，这在实现真正的Future trait时是必要的，我们稍后会回到这个问题，但现在将其视为一种优化。
- 我们刚刚手写了一个状态机：一个具有多个可能状态并根据特定事件在这些状态之间转换的类型。这个状态机相当简单。想象一下，如果您需要为具有额外中间步骤的更复杂用例编写这样的代码，那将是多么困难！
- 除了编写笨重的状态机之外，我们还必须知道Sender::send和Receiver::receive返回的Future类型，以便将它们存储在我们的类型中。如果这些方法返回的是impl Future，我们将无法为我们的变体编写类型。send和receive方法还必须获取发送器和接收器的所有权；如果它们没有这样做，返回的Future的生命周期将与self的借用相关联，而当我们从poll返回时，这个借用将结束。但这样做是行不通的，因为我们试图将这些Future存储在self中。

**注意** 您可能已经注意到，Receiver 很像是 Iterator 的异步版本。其他人也注意到了这一点，标准库正在逐步添加一个专门用于可以有意义地实现 poll_next 的类型的 trait。在Future，这些异步迭代器（通常称为流）可能会获得一流的语言支持，例如直接在它们上面进行循环！

- 最终，这段代码很难编写、难以阅读和难以修改。例如，如果我们想要添加错误处理，代码的复杂性将显著增加。幸运的是，有一种更好的方法！

##### async/await

Rust 1.39 引入了 async 关键字和紧密相关的 await 后缀运算符，我们在清单 8-3 的原始示例中使用了它们。它们一起为我们提供了一种更方便的机制来编写像清单 8-5 中的异步状态机。具体来说，它们让您以一种看起来甚至不像状态机的方式编写代码！

```rust

async fn forward<T>(rx: Receiver<T>, tx: Sender<T>) {
  while let Some(t) = rx.next().await {
    tx.send(t).await;
  }
}
```

清单8-5：使用async和await实现通道转发future，与清单8-3中的代码重复

- 如果您对async和await没有太多经验，那么清单8-4和清单8-5之间的区别可能会让您对为什么Rust社区对它们的到来如此兴奋有所了解。但由于这是一本中级书籍，让我们深入了解一下这段代码是如何替代更长的手动实现的。为了做到这一点，我们首先需要讨论生成器——实现async和await的机制。

##### Generators

简单来说，生成器是一段代码，带有一些额外的由编译器生成的部分，使其能够在执行过程中停止或暂停，并在稍后从上次暂停的位置继续执行。以清单8-3中的forward函数为例。想象一下，它到达了send的调用，但通道当前已满。函数无法再取得进展，但也不能阻塞（毕竟这是非阻塞代码），因此需要返回。现在假设通道最终清空，我们想要继续进行发送。如果我们从头再次调用forward，它将再次调用next，我们之前尝试发送的项目将丢失，这样不好。相反，我们将forward转换为生成器。

- 每当forward生成器无法再取得进展时，它需要将当前状态存储在某个地方，以便在最终恢复执行时，能够在正确的位置和正确的状态下继续执行。它通过编译器生成的关联数据结构来保存状态，该数据结构包含生成器在给定时间点的所有状态。该数据结构上的一个方法（也是由编译器生成的）允许生成器从存储在&mut self中的当前状态恢复，并在生成器再次无法取得进展时再次更新状态。
- 这种“返回但允许我稍后恢复”的操作被称为yielding，它实际上意味着在返回的同时保留一些额外的状态。当我们稍后想要恢复对forward的调用时，我们调用生成器的已知入口点（resume方法，对于async生成器来说是poll），生成器会检查之前存储在self中的状态来决定下一步该做什么。这与我们在清单8-4中手动完成的工作完全相同！换句话说，清单8-5中的代码大致转换为清单8-6中显示的假设代码。

```rust

generator fn forward<T>(rx: Receiver<T>, tx: Sender<T>) {
  loop {
    let mut f = rx.next();
    let r = if let Poll::Ready(r) = f.poll() { r } else { yield };
    if let Some(t) = r {
    let mut f = tx.send(t);

    let _ = if let Poll::Ready(r) = f.poll() { r } else { yield };
    } else {
       break Poll::Ready(()); 
      }
  }
}


```

清单8-6：将async/await转换为生成器

- 在撰写本文时，生成器实际上在Rust中无法使用——它们只是编译器内部用于实现async/await的工具——但这可能会在将来发生变化。生成器在许多情况下非常有用，例如在不必携带结构体的情况下实现迭代器，或者实现一个impl Iterator，该迭代器可以逐个生成项目。

- 如果您仔细观察清单8-5和清单8-6，一旦您知道每个await或yield实际上都是函数的返回，它们可能看起来有点神奇。毕竟，函数中有几个局部变量，不清楚在稍后恢复时如何恢复它们。这就是生成器的编译器生成部分发挥作用的地方。编译器会透明地注入代码，将这些变量持久化到生成器的关联数据结构中，并在执行时从中读取，而不是从堆栈中读取。因此，如果您声明、写入或读取某个局部变量a，实际上是在操作类似于self.a的东西。问题解决了！这真是太神奇了。

- 手动转发实现和async/await版本之间一个微妙但重要的区别是后者可以在yield点之间保持引用。这使得像清单8-5中的Receiver::next和Sender::send这样的函数可以接受&mut self，而不是清单8-4中的self。如果我们尝试在手动状态机实现中使用&mut self接收器来实现这些方法，借用检查器将无法强制执行在调用Receiver::next时和返回的future解析之间，不能引用Forward内部存储的Receiver的规则，因此它会拒绝该代码。只有通过将Receiver移动到future中，我们才能说服编译器Receiver在其他地方不可访问。与此同时，使用async/await，借用检查器可以在编译器将代码转换为状态机之前检查代码，并验证在future被丢弃（即await返回）之后，rx确实不会再次被访问。

**生成器的大小**
用于支持生成器状态的数据结构必须能够在任何一个yield点上保存组合状态。如果您的async fn包含一个[u8; 8192]，那么这8KiB必须存储在生成器本身中。即使您的async fn只包含较小的局部变量，它也必须包含它等待的任何Future，因为它需要在调用poll时能够轮询这样的Future。

- 这种嵌套意味着生成器以及基于异步函数和块的Future可能会变得非常庞大，而在您的代码中没有任何可见的指示。这反过来会影响您程序的运行时性能，因为这些巨大的生成器可能需要在函数调用之间和数据结构中进行复制，这相当于相当多的内存复制。实际上，您通常可以通过查看应用程序性能概要中的memcpy函数的使用时间来确定生成器基于Future的大小是否影响性能！

- 然而，找到这些大型Future并不总是容易的，通常需要手动识别长或复杂的异步函数链。Clippy可能在Future能够提供帮助，但在撰写本文时，您需要自己解决。当您找到一个特别大的Future时，有两种选择：您可以尝试减少异步函数所需的局部状态量，或者将Future移动到堆上（使用Box::pin），以便移动Future只需要移动指向它的指针。后者是最简单的方法，但它也引入了额外的分配和指针间接引用。通常，您最好将有问题的Future放在堆上，测量性能，然后使用性能基准来指导您的进一步操作。

##### Pin and Unpin

我们还没有完成。虽然生成器很棒，但从我目前描述的技术中出现了一个挑战。特别是，如果生成器中的代码（或等效的异步块）对局部变量取引用，那么情况就不太清楚了。在清单8-5中的代码中，rx.next()返回的Future必须在下一个消息不可用时持有对rx的引用，以便在生成器下次恢复时知道从哪里再次尝试。当生成器暂停时，Future和Future包含的引用都被存储在生成器内部。但是，如果移动生成器会发生什么呢？具体来说，看一下清单8-7中调用forward的代码。

```rust

async fn try_forward<T>(rx: Receiver<T>, tx: Sender<T>) -> Option<impl Future>
{
  let mut f = forward(rx, tx);
  if f.poll().is_pending() { Some(f) } else { None }
}
```

清单8-7：在对其进行轮询后移动Future

try_forward函数只对forward进行一次轮询，尽可能多地转发消息而不阻塞。如果接收器可能仍然产生更多的消息（即，它返回的是Poll::Pending而不是Poll::Ready(None)），那么这些消息将被延迟到稍后的某个时间通过将转发的Future返回给调用者来转发。调用者可以选择在适当的时候再次进行轮询。

- 让我们根据我们目前对async和await的了解来分析这里发生的情况。当我们轮询forward生成器时，它会通过while循环进行一些未知次数的迭代，最终返回Poll::Ready(())（如果接收器结束）或Poll::Pending（否则）。如果返回Poll::Pending，生成器中包含从rx.next()或tx.send(t)返回的future。这些future都包含对forward最初提供的参数（分别是rx和tx）的引用，这些参数也必须存储在生成器中。但是当try_forward返回整个生成器时，生成器的字段也会移动。因此，rx和tx不再位于内存中的相同位置，而存储在生成器中的引用也不再指向正确的数据！

- 我们在这里遇到的是一个自引用的数据结构的情况：它既包含数据，又包含对该数据的引用。对于生成器来说，构建这种自引用结构非常容易，而无法支持它们将对人体工程学产生重大影响，因为这意味着您将无法在任何yield点上保持引用。在Rust中，支持自引用数据结构的（巧妙的）解决方案是Pin类型和Unpin trait。简单来说，Pin是一个包装类型，阻止被包装类型被（安全地）移动，而Unpin是一个标记trait，表示实现该trait的类型可以安全地从Pin中移除。

- What we’ve run into here is a case of a self-referential data structure: one
that holds both data and references to that data. With generators, these selfreferential
structures are very easy to construct, and being unable to support
them would be a significant blow to ergonomics because it would mean you
wouldn’t be able to hold references across any yield point. The (ingenious)
solution for supporting self-referential data structures in Rust comes in the
form of the Pin type and the Unpin trait. Very briefly, Pin is a wrapper type that
prevents the wrapped type from being (safely) moved, and Unpin is a marker
trait that says the implementing type can be removed safely from a Pin.

##### Pin

这里有很多细节需要讲解，所以让我们从一个具体的Pin包装器的使用开始。清单8-2给出了Future trait的简化版本，但现在我们准备揭开其中的一部分简化。清单8-8展示了Future trait更接近最终形式的样子。

```rust

trait Future {
type Output;
fn poll(self: Pin<&mut Self>) -> Poll<Self::Output>;
}
```

清单8-8：带有Pin的Future trait的更详细视图

- 特别是，这个定义要求您在Pin<&mut Self>上调用poll。
一旦您有了一个Pin后面的值，这就构成了一个合同，即该值将不再移动。
这意味着您可以在内部构建自引用，就像生成器一样。

**注意** 虽然Future使用了Pin，但Pin并不局限于Future trait - 您可以将Pin用于任何自引用的数据结构。

- 但是如何获取一个Pin来调用poll呢？Pin又如何确保包含的值不会移动呢？为了了解这个魔法是如何工作的，让我们看一下std::pin::Pin的定义以及其中一些关键方法，如清单8-9所示。

```rust

struct Pin<P> { pointer: P }

impl<P> Pin<P> where P: Deref {
  pub unsafe fn new_unchecked(pointer: P) -> Self;
}
impl<'a, T> Pin<&'a mut T> {
  pub unsafe fn get_unchecked_mut(self) -> &'a mut T;
}
impl<P> Deref for Pin<P> where P: Deref {
  type Target = P::Target;
  fn deref(&self) -> &Self::Target;
}
```

清单8-9：std::pin::Pin及其关键方法

- 这里有很多细节需要讲解，我们需要多次查看清单8-9中的定义，直到所有部分都变得清晰明了，请耐心等待。

- 首先，您会注意到Pin持有一个指针类型。也就是说，它不直接持有某个T类型的值，而是持有一个通过Deref解引用到T的类型P。这意味着，您将拥有的是`Pin<Box<MyType>>、Pin<Rc<MyType>>`或`Pin<&mut MyType>`，而不是简单的`Pin<MyType>`。这种设计的原因很简单 - Pin的主要目标是确保一旦将T放在Pin后面，T就不会移动，因为这样做可能会使存储在T中的自引用失效。如果Pin直接持有T，那么仅仅移动Pin就足以使这个不变量失效！在本节的其余部分，我将将P称为指针类型，将T称为目标类型。

- 接下来，请注意Pin的构造函数new_unchecked是不安全的。这是因为编译器无法实际检查指针类型是否确实承诺指向的目标类型不会再次移动。例如，考虑一个位于堆栈上的变量foo。如果Pin的构造函数是安全的，我们可以使用Pin::new(&mut foo)，调用一个需要Pin<&mut Self>的方法（因此假设Self不会再次移动），然后丢弃Pin。此时，我们可以随意修改foo，因为它不再被借用 - 包括移动它！然后，我们可以再次固定它并调用相同的方法，而该方法不会意识到第一次构造时可能构建的任何自引用指针现在都是无效的。

**PIN CONSTRUCTOR SAFETY**
构造Pin的另一个不安全的原因是它的安全性取决于一些本身是安全的trait的实现。例如，`Pin<P>`实现get_unchecked_mut的方式是使用P的DerefMut::deref_mut的实现。虽然对get_unchecked_mut的调用是不安全的，但对于P的impl DerefMut来说是安全的。然而，它接收一个&mut self，并且可以自由地（无需使用不安全的代码）移动T。Drop也是同样的情况。因此，Pin::new_unchecked的安全要求不仅是指针类型不会再次移动目标类型（就像Pin<&mut T>的例子中那样），还要求它的Deref、DerefMut和Drop实现不会移动接收到的&mut self后面的指向的值。

- 然后我们来到了get_unchecked_mut方法，它给出了对Pin指针类型后面的T的可变引用。这个方法也是不安全的，因为一旦我们给出了一个&mut T，调用者必须承诺不会使用该&mut T来移动T或以其他方式使其内存无效，以免任何自引用失效。如果这个方法不是不安全的，调用者可以在两个Pin<&mut _>上调用一个接受Pin<&mut Self>的方法，然后调用get_unchecked_mut的安全变体，然后使用mem::swap交换Pin后面的值。如果我们再次在任何一个Pin上调用一个接受Pin<&mut Self>的方法，它对Self没有移动的假设将被违反，并且它存储的任何内部引用都将无效！
- 令人惊讶的是，`Pin<P>`总是实现了`Deref<Target = T>`，而且这是完全安全的。原因是，通过&T，您无法移动T，除非编写其他不安全的代码（例如，UnsafeCell，我们将在第9章中讨论）。这是为什么不安全块的范围超出了它包含的代码的一个很好的例子。如果您在应用程序的某个部分中编写了一些代码（不安全地）使用UnsafeCell替换&T后面的T，那么可能是该&T最初来自Pin<&mut T>，而您现在已经违反了Pin后面的T永远不会移动的不变量，即使您不安全地替换&T的地方甚至没有提到Pin！
**注意** 如果您在阅读本章时浏览了Pin文档，可能会注意到Pin::set方法，它接受一个`&mut self和<P as Deref>::Target`，并安全地更改Pin后面的值。这是可能的，因为set方法不返回先前固定的值 - 它只是在原地丢弃它，并将新值存储在那里。因此，它不违反固定不变量：旧值在放置在Pin后面后从未在Pin之外访问过。

##### Unpin: The Key to Safe Pinning

此时，您可能会问：既然获取可变引用本身就是不安全的，为什么不直接让Pin持有T呢？也就是说，不需要通过指针类型进行间接引用，而是可以使get_unchecked_mut的约定是只有在未移动Pin的情况下才能安全调用。对于这个问题的答案在于指针设计所实现的一种巧妙的安全使用方式。回想一下，我们之所以需要Pin，是因为我们希望有可能包含对自身的引用的目标类型（比如生成器），并给它们的方法提供一个保证，即目标类型没有移动，因此内部的自引用仍然有效。Pin让我们可以使用类型系统来强制执行这个保证，这非常好。但不幸的是，到目前为止，使用Pin非常不方便。这是因为它总是需要使用不安全的代码，即使您正在处理一个不包含任何自引用的目标类型，因此无论它是否被移动都无关紧要。

- 这就是标记trait Unpin发挥作用的地方。对于一个类型的Unpin实现，它只是断言该类型在用作目标类型时可以安全地从Pin中移动出来。也就是说，该类型承诺在用作目标类型时不会使用Pin关于引用对象不再移动的任何保证，因此这些保证可能会被打破。Unpin是一个自动trait，类似于Send和Sync，因此编译器会自动为仅包含Unpin成员的任何类型实现Unpin。只有显式选择不使用Unpin的类型（比如生成器）和包含这些类型的类型才是!Unpin。
- 对于Unpin的目标类型，我们可以提供一个更简单的安全接口给Pin，如清单8-10所示。

```rust

impl<P> Pin<P> where P: Deref, P::Target: Unpin {
  pub fn new(pointer: P) -> Self;
}
impl<P> DerefMut for Pin<P> where P: DerefMut, P::Target: Unpin {
  fn deref_mut(&mut self) -> &mut Self::Target;
}
```

清单8-10：针对Unpin目标类型的Pin的安全API

- 要理解清单8-10中的安全API，我们需要考虑清单8-9中的不安全方法的安全要求：Pin::new_unchecked函数是不安全的，因为调用者必须承诺引用对象不能在Pin之外移动，并且指针类型的Deref、DerefMut和Drop的实现不会通过接收到的引用移动引用对象。这些要求的目的是确保一旦我们给出一个Pin到T，我们就不会再移动该T。但是，如果T是Unpin的，它声明了即使之前被固定，它也不在乎是否被移动，所以如果调用者不满足这些要求，那也没关系！
- 类似地，get_unchecked_mut是不安全的，因为调用者必须保证不会将T从&mut T中移出，但是对于T: Unpin，T声明了即使被固定后也可以移动，因此这个安全要求不再重要。这意味着对于Pin<P>，其中P::Target: Unpin，我们可以简单地提供这两个方法的安全变体（DerefMut是get_unchecked_mut的安全版本）。实际上，如果目标类型是Unpin，我们甚至可以提供一个简单的Pin::into_inner，它只是返回拥有的P，因为Pin本身基本上是无关紧要的！

##### Ways of Obtaining a Pin

有了对Pin和Unpin的新理解，我们现在可以朝着使用清单8-8中要求Pin<&mut Self>的新Future定义取得进展。第一步是构造所需的类型。如果future类型是Unpin的，那么这一步很容易 - 我们只需使用Pin::new(&mut future)。如果它不是Unpin的，我们可以通过两种主要方式之一将future固定在堆上或堆栈上。

- 让我们从固定到堆上开始。Pin的主要约定是一旦某个对象被固定，它就不能移动。固定API负责在Pin上的所有方法和特性中遵守这个约定，因此构造Pin的任何函数的主要作用是确保如果Pin本身移动了，被引用的值也不会移动。最简单的方法是将被引用的值放在堆上，然后在Pin中只放置一个指向被引用值的指针。然后，您可以随意移动Pin，但目标值将保持在原地。这就是（安全的）Box::pin方法的原理，它接受一个T并返回一个`Pin<Box<T>>`。这没有什么神奇的，它只是断言Box遵循Pin构造函数、Deref和Drop的约定。

**UNPIN BOX**
在我们讨论Box的同时，让我们看一下Box对于Unpin的实现。Box类型无条件地为任何T实现Unpin，即使T本身不是Unpin。这可能让您感到奇怪，因为前面断言Unpin是一个自动trait，通常只有当类型的所有成员也都是Unpin时才会为该类型实现Unpin。Box是一个例外，原因与它可以提供安全的Pin构造函数相同：如果移动了一个`Box<T>`，并不会移动T。换句话说，无条件的实现断言您可以从Pin中移动出一个`Box<T>`，即使T不能从Pin中移动出来。然而，请注意，这并不意味着您可以从`Pin<Box<T>>`中移动一个!Unpin的T。

- 另一种选择是将值固定到堆栈上，这需要一些不安全的代码。我们必须确保在使用&mut引用它的Pin被丢弃后，无法再访问固定的值。我们通过在宏中显示阴影值来实现这一点，如清单8-11所示，或者使用提供此宏的某个crate。也许有一天它甚至会进入标准库！

```rust

macro_rules! pin_mut {
  ($var:ident) => {
    let mut $var = $var;
    let mut $var = unsafe { Pin::new_unchecked(&mut $var) };
  }
}
```

清单8-11：将值固定到堆栈的宏

- 通过接收要固定到堆栈的变量的名称，该宏确保调用者已经在堆栈上有了要固定的值。对$var的阴影处理确保调用者无法丢弃Pin并继续使用未固定的值（这将违反任何!Unpin目标类型的Pin约定）。通过移动$var中存储的值，该宏还确保调用者无法在不丢弃原始变量的情况下丢弃宏声明的$var绑定。具体来说，如果没有这一行，调用者可以编写以下代码（注意额外的作用域）：

- By taking the name of the variable to pin to the stack, the macro
ensures that the caller has the value it wants to pin somewhere on the
stack already. The shadowing of $var ensures that the caller cannot drop
the Pin and continue to use the unpinned value (which would breach the
Pin contract for any target type that’s !Unpin). By moving the value stored
in $var, the macro also ensures that the caller cannot drop the $var binding
the macro declarations without also dropping the original variable.
Specifically, without that line, the caller could write (note the extra scope):

```rust

let foo = /**/; { pin_mut!(foo); foo.poll() }; foo.mut_self_method();
```

- 在这里，我们将一个固定的foo实例传递给poll，但后来我们又在没有Pin的情况下使用了一个对foo的&mut引用，这违反了Pin的约定。另一方面，如果有额外的重新赋值，那么该代码也会将foo移动到新的作用域中，在作用域结束后无法再使用它。
- 在堆栈上固定值因此需要使用不安全的代码，与Box::pin不同，但避免了Box引入的额外分配，并且在no_std环境中也适用。

##### Back to the Future

现在我们有了固定的future，并且我们知道这意味着什么。但是您可能已经注意到，在使用async和await编写的大多数异步代码中，没有出现任何重要的固定相关内容。这是因为编译器将其隐藏起来。

- 回想一下我们讨论清单8-5时，我告诉您<expr>.await会被展开成类似以下的代码：

```rust

loop { if let Poll::Ready(r) = expr.poll() { break r } else { yield } }
```

- 这是一个微小的简化，因为正如我们所见，只有当您拥有一个Pin<&mut Self>用于future时，才能调用Future::poll。实际上，展开的代码更加复杂，如清单8-12所示。

```rust

1 match expr {
  mut pinned => loop {
    2 match unsafe { Pin::new_unchecked(&mut pinned) }.poll() {
      Poll::Ready(r) => break r,
      Poll::Pending => yield,
    }
  }
}

```

清单8-12：更准确的<expr>.await展开

- match 1是一种简洁的写法，不仅可以确保展开后仍然是有效的表达式，还可以将表达式结果移动到一个变量中，然后我们可以将其固定在堆栈上。除此之外，主要的新添加是对Pin::new_unchecked的调用2。这个调用是安全的，因为为了对包含的异步块进行轮询，它必须已经被固定，这是由于Future::poll的签名。而且，我们已经对异步块进行了轮询，以达到对Pin::new_unchecked的调用，所以生成器状态是固定的。由于固定存储在对应于异步块的生成器中（必须如此才能正确恢复yield），我们知道固定将不会再次移动。此外，在循环中，除了通过Pin访问固定之外，无法访问固定，因此没有代码能够从固定的值中移动出来。因此，我们满足了Pin::new_unchecked的所有安全要求，代码是安全的。

#### Going to Sleep


We went pretty deep into the weeds with Pin, but now that we’re out the
other side, there is another issue around futures that may have been making
your brain itch. If a call to Future::poll returns Poll::Pending, you need
something to call poll again at a later time to check whether you can make
progress yet. That something is usually called the executor. Your executor
could be a simple loop that polls all the futures you are waiting on until
they’ve all returned Poll::Ready, but that would burn a lot of CPU cycles you
could probably have used for other, more useful things, like running your
web browser. Instead, we want the executor to do whatever useful work it
can do, and then go to sleep. It should stay asleep until one of the futures
can make progress, and only then wake up to do another pass, before going
to sleep again.

我们对Pin进行了深入的探讨，但是现在我们已经解决了另一个与future相关的问题，这可能让你感到困惑。如果对Future::poll的调用返回Poll::Pending，你需要在稍后的时间再次调用poll来检查是否可以取得进展。通常，这个任务被称为执行器（executor）。你的执行器可以是一个简单的循环，它轮询所有你正在等待的future，直到它们都返回Poll::Ready。但是这样做会消耗大量的CPU周期，你可能本可以用于其他更有用的事情，比如运行你的网页浏览器。相反，我们希望执行器尽可能地完成有用的工作，然后进入休眠状态。它应该保持休眠，直到其中一个future可以取得进展，然后再次唤醒执行下一轮，然后再次进入休眠状态。

##### Waking Up

决定何时重新检查给定的future的条件各不相同。它可能是“当网络数据包到达此端口时”，“当鼠标光标移动时”，“当有人在此通道上发送消息时”，“当CPU接收到特定中断时”，甚至是“经过了这么长时间”。除此之外，开发人员可以编写自己的包装多个其他future的future，因此可能有多个唤醒条件。有些future甚至可能引入自己完全定制的唤醒事件。

- 为了适应这些多种用例，Rust引入了Waker的概念：一种唤醒执行器以表示可以进行进展的方式。Waker是使整个与future相关的机制工作的关键。执行器构造一个与执行器进入休眠机制集成的Waker，并将Waker传递给它轮询的任何Future。如何实现呢？通过Future::poll的额外参数，这是我迄今为止对你隐藏的。对此我感到抱歉。清单8-13给出了Future的最终和真实的定义-不再有谎言！

```rust

trait Future {
  type Output;
  fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output>;
}
```

清单8-13：具有Context的实际Future trait

- &mut Context包含Waker。参数是一个Context，而不是直接的Waker，这样我们就可以在需要时为futures增加额外的上下文。
- Waker的主要方法是wake（以及引用变体wake_by_ref），当future可以再次取得进展时应该调用它。wake方法不接受任何参数，其效果完全由构造Waker的执行器定义。你看，Waker在执行器上是秘密泛型的。更准确地说，构造Waker的对象可以决定在调用Waker::wake时发生什么，当克隆Waker时发生什么，以及当丢弃Waker时发生什么。所有这些都是通过手动实现的虚函数表来实现的，它的功能类似于我们在第2章中讨论的动态分派。
- 构建一个Waker是一个相对复杂的过程，对于使用一个Waker来说，其机制并不是非常重要，但是你可以在标准库的RawWakerVTable类型中看到构建块。它有一个构造函数，接受wake和wake_by_ref的函数指针，以及Clone和Drop。RawWakerVTable通常在所有执行器的Waker之间共享，它与一个原始指针捆绑在一起，用于保存每个Waker实例的特定数据（比如它所属的future），并转换为RawWaker。然后将其传递给Waker::from_raw，以生成一个安全的Waker，可以传递给Future::poll。

##### Fulfilling the Poll Contract

到目前为止，我们已经绕过了future在Waker上的实际操作。这个想法相当简单：如果Future::poll返回Poll::Pending，那么在future下次能够取得进展时，它的责任是确保有某个东西调用提供的Waker上的wake方法。大多数futures通过仅在其他future也返回Poll::Pending时返回Poll::Pending来履行这个属性；通过这种方式，它可以轻松地满足poll的约定，因为内部future必须遵循相同的约定。但是不能一直这样下去。在某个点上，你会遇到一个不轮询其他futures而是执行诸如写入网络套接字或尝试在通道上接收等操作的future。这些通常被称为Leaf futures，因为它们没有子级。Leaf future没有内部future，而是直接表示可能尚未准备好返回结果的某些资源。

**注意**，poll约定是为了正确性而需要在清单8-4中进行递归调用6。

- Leaf future通常有两种形式：一种是等待在同一进程内发生的事件（比如通道接收器），另一种是等待在进程外部发生的事件（比如TCP数据包读取）。等待内部事件的Leaf future通常遵循相同的模式：将Waker存储在代码可以找到的位置，并在生成相关事件时调用Waker的wake方法。例如，考虑一个必须等待内存通道上的消息的Leaf future。它将其Waker存储在发送方和接收方之间共享的通道部分中，然后返回Poll::Pending。当发送方稍后向通道中注入消息时，它会注意到等待接收方留下的Waker，并在从发送中返回之前调用Waker的wake方法。现在接收方被唤醒，poll约定得到了遵守。

- 处理外部事件的Leaf future更加复杂，因为生成事件的代码对future和waker一无所知。最常见的情况是生成代码是操作系统内核，它知道磁盘何时准备好或计时器何时到期，但也可能是调用Rust回调的C库或其他外部实体。一个包装外部资源的Leaf future可以启动一个执行阻塞系统调用（或等待C回调）的线程，然后使用内部唤醒机制，但这样做是浪费的；每次操作需要等待时都会启动一个线程，并且会有很多单次使用的线程闲置等待。

- 相反，执行器往往提供了与执行器在后台进行通信的Leaf future的实现，以安排与操作系统的适当交互。具体如何协调取决于执行器和操作系统，但大致上来说，执行器会跟踪它下次进入休眠时应该监听的所有事件源。当Leaf future意识到它必须等待外部事件时，它会更新该执行器的状态（因为它是由执行器创建提供的）以包括该外部事件源和它自己的Waker。当执行器无法再取得进展时，它会收集所有待处理的Leaf future等待的事件源，并对操作系统进行一个大的阻塞调用，告诉操作系统在任何Leaf future等待的资源有新事件时返回。在Linux上，通常使用epoll系统调用来实现；Windows、BSD、macOS和几乎所有其他操作系统都提供类似的机制。当该调用返回时，执行器会对所有与操作系统报告的事件相关的Waker调用wake方法，从而履行了poll约定。

**注意** Reactor是执行器的一部分，Leaf future在其中注册事件源，并且当执行器没有更多有用的工作要做时，它会等待Reactor。虽然可以将执行器和Reactor分开，但将它们捆绑在一起通常会提高性能，因为两者可以更容易地进行协同优化。

- 紧密集成的Leaf future和执行器之间的关系的一个连锁效应是，来自一个执行器crate的Leaf future通常不能与不同的执行器一起使用。或者至少，除非Leaf future的执行器也在运行，否则它们不能被使用。当Leaf future存储其Waker并注册其等待的事件源时，它构建时所使用的执行器需要设置该状态并且需要运行，以便实际监视事件源并最终调用wake。有一些解决方法，比如如果没有正在运行的执行器，Leaf future可以生成一个执行器，但这并不总是可取的，因为这意味着应用程序可能在同一时间内透明地运行多个执行器，这可能会降低性能并且在调试时必须检查多个执行器的状态。
- 希望支持多个执行器的库crate必须对其Leaf 资源进行泛型化。例如，一个库可以存储一个泛型的T: AsyncRead + AsyncWrite，而不是使用特定执行器的TcpStream或File future类型。然而，目前尚未就这些特性的具体形式和所需的特性达成一致，因此目前要使代码真正泛型化执行器相对困难。例如，虽然AsyncRead和AsyncWrite在生态系统中有些常见（或者在必要时可以轻松适应），但目前还没有用于在后台运行future（我们稍后将讨论的spawning）或表示计时器的特性。

##### Waking Is a Misnomer

- 你可能已经意识到，Waker::wake似乎并不一定会唤醒任何东西。例如，对于外部事件（如前一节所述），执行器已经是唤醒状态，它似乎没有必要再调用属于该执行器的Waker的wake方法！实际上，Waker::wake有点名不副实——它实际上是在告诉执行器某个特定的future是可运行的。也就是说，它告诉执行器在适当的时候一定要轮询这个特定的future，而不是再次进入休眠状态，因为这个future可以取得进展。如果执行器当前正在休眠，这可能会唤醒执行器，使其去轮询该future，但这更像是一个副作用，而不是它的主要目的。

- 对于执行器来说，知道哪些future是可运行的有两个原因。首先，它需要知道何时可以停止轮询一个future并进入休眠状态；仅仅轮询每个future直到返回Poll::Pending是不够的，因为轮询后面的future可能会使之前的future能够取得进展。考虑一种情况，两个future通过通道相互传递消息。当你轮询其中一个时，另一个变为就绪状态，反之亦然。在这种情况下，执行器永远不应该进入休眠状态，因为总是有更多的工作要做。
- 其次，知道哪些future是可运行的可以让执行器避免不必要地轮询futures。如果执行器管理着成千上万个待处理的futures，它不应该只因为一个事件使其中一个可运行而轮询所有的futures。如果这样做，执行异步代码的速度将变得非常慢。

##### Tasks and Subexecutors

- 异步程序中的future形成了一棵树：一个future可以包含任意数量的其他future，这些future又可以包含其他future，一直到与waker交互的叶子future。每棵树的根是您提供给执行器的主要“运行”函数的future。这些根future被称为任务（tasks），它们是执行器和future树之间的唯一接触点。执行器在任务上调用poll，并且从那时起，每个包含的future的代码必须确定要轮询哪个内部future，一直到相关的叶子future。
执行器通常为它们轮询的每个任务构造一个单独的Waker，以便在稍后调用wake时，它们知道哪个任务刚刚变为可运行，并可以将其标记为可运行。这就是RawWaker中的原始指针的作用——在共享各种Waker方法的代码的同时区分任务之间的区别。当执行器最终轮询一个任务时，该任务从Future::poll的顶部开始运行，并从那里决定如何到达更深层的可以取得进展的future。由于每个future只知道自己的字段，而不知道整个树，所以所有这些都是通过调用poll来实现的，每个调用都遍历树中的一条边。
- 选择要轮询的内部future的选择通常是显而易见的，但并非总是如此。在async/await中，要轮询的future是我们正在等待的那个。但是在等待多个future中的第一个取得进展（通常称为select），或者等待一组future中的所有future（通常称为join）的情况下，有很多选择。必须做出这种选择的future基本上是一个子执行器。它可以轮询所有的内部future，但这样做可能非常浪费。相反，这些子执行器通常在调用任何内部future的poll之前，将它们收到的Waker与poll的Context一起包装在自己的Waker类型中。在包装代码中，它们在调用原始Waker的wake之前，将刚刚轮询的future标记为自己状态中的可运行状态。这样，当执行器最终再次轮询子执行器的future时，子执行器可以查看自己的内部状态，找出是哪个内部future导致了当前的poll调用，然后只轮询那些内部future。
**在异步代码中的锁定**
在异步代码中调用同步代码时，你必须小心，因为执行器线程执行当前任务的时间是不会用于运行其他任务的时间。如果一个任务在没有返回给执行器的情况下占用当前线程的时间很长，这可能发生在执行阻塞系统调用（如std::sync::sleep）、运行不会偶尔让出执行权的子执行器，或者在没有await的紧密循环中运行时，那么当前执行器线程负责的其他任务在此期间将无法运行。通常，这会导致某些任务能够取得进展（例如客户端连接）和实际执行之间的长时间延迟。
- 一些多线程执行器实现了工作窃取技术，空闲的执行器线程从繁忙的执行器线程中窃取任务，但这只是一种缓解措施，而不是解决方案。最终，你可能会遇到所有执行器线程都被阻塞的情况，因此在一个阻塞操作完成之前，没有任务会被执行。
- 通常情况下，在异步上下文中执行计算密集型操作或调用可能阻塞的函数时，应该非常小心。这些操作应该在可能的情况下转换为异步操作，或者在专用线程上执行，然后使用支持异步的原语进行通信，比如通道。一些执行器还提供了机制，用于指示异步代码的特定部分可能会阻塞，或者在可能不会主动让出的循环上下文中主动让出，这可以成为解决方案的一部分。一个好的经验法则是，没有任何一个future应该在超过1毫秒的时间内运行而不返回Poll::Pending。

#### Tying It All Together with spawn

当使用异步执行器时，您可能会遇到一个生成future的操作。现在我们有能力通过示例来探索这意味着什么！首先，考虑清单8-14中的简单服务器实现。

```rust

async fn handle_client(socket: TcpStream) -> Result<()> {
// Interact with the client over the given socket.
}
async fn server(socket: TcpListener) -> Result<()> {
  while let Some(stream) = socket.accept().await? {
    handle_client(stream).await?;
}
}
```

清单8-14：顺序处理连接

- 顶层的server函数本质上是一个大的future，它监听新的连接并在有新连接到达时执行某些操作。
您将该future交给执行器并说“运行这个”，由于您不希望程序立即退出，您可能会让执行器在该future上阻塞。
也就是说，对执行器运行服务器future的调用将不会返回，直到服务器future解析，这可能永远不会发生（可能会有另一个客户端稍后到达）。
- 现在，每当有一个新的客户端连接进来时，清单8-14中的代码会创建一个新的future（通过调用handle_client）来处理该连接。由于处理本身也是一个future，我们等待它然后继续处理下一个客户端连接。
- 这种方法的缺点是我们一次只处理一个连接，没有并发性。一旦服务器接受了一个连接，就会调用handle_client函数，由于我们使用了await，直到handle_client的返回future解析（可能是当客户端离开时），我们才会再次进入循环。
- 我们可以通过保持所有客户端future的集合，并在服务器接受新连接的循环中检查所有客户端future是否可以取得进展来改进这一点。清单8-15展示了可能的实现方式。

```rust


async fn server(socket: TcpListener) -> Result<()> {
  let mut clients = Vec::new();
    loop {
      poll_client_futures(&mut clients)?;
      if let Some(stream) = socket.try_accept()? {
        clients.push(handle_client(stream));
    }
  }
}

```
清单8-15：使用手动执行器处理连接

- 这至少可以同时处理多个连接，但是它非常复杂。而且效率不高，因为现在的代码在已有连接和接受新连接之间来回切换。它必须每次都检查每个连接，因为它不知道哪些连接可以取得进展（如果有的话）。它也不能在任何时候等待，因为那样会阻止其他future取得进展。你可以实现自己的唤醒器，以确保代码只轮询可以取得进展的future，但最终这将走向开发自己的迷你执行器的道路。
- 只使用一个任务来处理服务器的所有客户端连接的另一个缺点是服务器最终变成了单线程。只有一个任务，并且为了轮询它，代码必须持有对任务的Future的独占引用（poll接受Pin<&mut Self>），这只能由一个线程持有。
- 解决方案是将每个客户端future作为自己的任务，并由执行器在任务之间进行多路复用。你可以通过生成future来实现这一点。执行器将继续在服务器future上阻塞，但如果无法在该future上取得进展，它将在后台使用执行机制来在其他任务上取得进展。最重要的是，如果执行器是多线程的，并且你的客户端futures是Send的，它可以并行运行它们，因为它可以同时持有对不同任务的&muts。清单8-16展示了这可能是什么样子。

```rust 

async fn server(socket: TcpListener) -> Result<()> {
  while let Some(stream) = socket.accept().await? {
    // Spawn a new task with the Future that represents this client.
    // The current task will continue to just poll for more connections
    // and will run concurrently (and possibly in parallel) with handle_client.
    spawn(handle_client(stream));
  }
}

```
清单8-16：生成Future以创建更多可以同时轮询的任务

- 当你生成一个Future并将其作为任务时，它有点像生成一个线程。Future在后台继续运行，并与执行器给定的任何其他任务并发地进行多路复用。然而，与生成的线程不同，生成的任务仍然依赖于执行器的轮询。如果执行器停止运行，要么因为你放弃了它，要么因为你的代码不再运行执行器的代码，那些生成的任务将停止取得进展。在服务器示例中，想象一下，如果主服务器Future由于某种原因解析。由于执行器已经将控制权返回给你的代码，它无法继续做任何事情。多线程执行器通常会生成后台线程，即使执行器将控制权返回给用户的代码，它们仍然会继续轮询任务，但并非所有执行器都会这样做，所以在依赖这种行为之前，请检查你的执行器！

#### Summary

在本章中，我们深入了解了Rust中可用的异步构造的内部情况。我们看到了编译器如何实现生成器和自引用类型，以及为什么这项工作对支持我们现在所知的async/await是必要的。我们还探讨了future如何执行，以及唤醒器如何允许执行器在任何给定时刻只有一些任务可以取得进展时进行多路复用。在下一章中，我们将处理Rust中可能是最深入和最受讨论的领域：不安全代码。深呼吸，然后翻开下一页。

### 9.UNSAFE CODE

提到不安全代码往往会引起Rust社区中许多人的强烈反应，也会引起许多旁观者的强烈反应。有些人认为这“没什么大不了”，而其他人则谴责它是“Rust所有承诺的谎言的原因”。在本章中，我希望能够揭开一些不安全代码的面纱，解释什么是不安全代码，什么不是，以及如何安全地使用它。在撰写本文时，以及在您阅读本文时，Rust对不安全代码的精确要求仍在确定中，即使它们都被确定下来，完整的描述也超出了本书的范围。相反，我将尽力为您提供构建块、直觉和工具，以帮助您在大多数不安全代码中进行导航。

- 你从本章中应该得出的主要结论是：不安全代码是Rust为开发者提供的一种机制，用于利用编译器无法检查的不变量。我们将探讨不安全代码是如何实现这一点的，这些不变量可能是什么，以及我们可以通过它做些什么。

**不变量**
在本章中，我将大量讨论不变量。不变量只是一种说法，意味着“你的程序必须正确的东西”。例如，在Rust中，一个不变量是引用（使用&和&mut）不会悬空 - 它们总是指向有效的值。您还可以有特定于应用程序或库的不变量，比如“头指针始终在尾指针之前”或“容量始终是2的幂”。最终，不变量代表了代码正确性所需的所有假设。然而，您可能并不总是意识到代码使用的所有不变量，这就是错误产生的地方。

- 关键是，不安全代码不是绕过Rust的各种规则（如借用检查）的方法，而是一种使用超出编译器能力的推理来强制执行这些规则的方法。当您编写不安全代码时，您有责任确保生成的代码是安全的。在某种程度上，当使用unsafe {}允许不安全操作时，unsafe作为关键字是具有误导性的；它并不意味着包含的代码是不安全的，而是在这个特定的上下文中，该代码被允许执行其他情况下不安全的操作，因为这些操作是安全的。
- 本章的其余部分分为四个部分。我们将首先简要介绍关键字本身的使用方式，然后探讨不安全代码允许您做什么。接下来，我们将查看编写安全的不安全代码时必须遵循的规则。最后，我将给出一些建议，关于如何安全地编写不安全代码。

##### The unsafe Keyword

- 在我们讨论unsafe赋予您的权限之前，我们需要谈谈它的两个不同含义。在Rust中，unsafe关键字具有双重作用：它标记特定的函数为不安全调用，并允许您在特定的代码块中调用不安全功能。例如，清单9-1中的方法被标记为不安全，即使它不包含不安全代码。在这里，unsafe关键字作为对调用者的警告，告诉他们有额外的保证，调用decr的代码必须手动检查。

```rust

impl<T> SomeType<T> {
  pub unsafe fn decr(&self) {
    self.some_usize -= 1;
  }
}

```

清单9-1：一个只包含安全代码的不安全方法

清单9-2展示了第二种用法。在这里，即使方法包含不安全代码，它本身也没有标记为不安全。

```rust

impl<T> SomeType<T> {
  pub fn as_ref(&self) -> &T {
    unsafe { &*self.ptr }
  }
}
```
清单9-2：包含不安全代码的安全方法

- 这两个清单在使用unsafe方面有所不同，因为它们体现了不同的约定。decr要求调用者在调用该方法时要小心，而as_ref则假设调用者在调用其他不安全方法（如decr）时已经小心了。为了理解这一点，想象一下SomeType实际上是一个类似Rc的引用计数类型。尽管decr只是减少一个数字，但这个减少可能通过安全方法as_ref触发未定义行为。如果你调用decr，然后丢弃给定T的倒数第二个Rc，引用计数将降为零，T将被丢弃 - 但程序可能仍然在最后一个Rc上调用as_ref，并得到一个悬空引用。
**注意** 未定义行为描述了在运行时违反语言不变量的程序的后果。一般来说，如果一个程序触发了未定义行为，其结果是完全不可预测的。我们将在本章后面更详细地讨论未定义行为。
- 相反，只要没有办法使用安全代码破坏Rc的引用计数，就可以安全地解引用Rc内部的指针，就像as_ref的代码所做的那样——&self的存在证明指针仍然有效。我们可以利用这一点，为调用者提供一个安全的API，让其访问一个本来是不安全操作的核心部分，这是如何负责地使用不安全代码的关键。
- 由于历史原因，每个不安全函数在 Rust 中都包含一个隐式的不安全块。也就是说，如果你声明了一个不安全函数，你可以在该函数内部调用任何不安全的方法或原始操作。然而，这个决定现在被认为是一个错误，并且正在通过已经被接受和实施的 RFC 2585 进行撤销。这个 RFC 警告说，如果一个不安全函数在内部执行不安全操作而没有显式的不安全块，那么这是一个错误。这个 lint 在 Rust 的Future版本中也可能成为一个硬错误。这个想法是为了减少“脚枪半径”——如果每个不安全函数都是一个巨大的不安全块，那么你可能会在不知情的情况下执行不安全操作！例如，在清单9-1中的decr函数中，根据当前的规则，你也可以添加*std::ptr::null()而不需要任何不安全的注释。
- 作为标记的unsafe和作为启用不安全操作机制的unsafe块之间的区别很重要，因为你必须以不同的方式思考它们。一个unsafe fn向调用者表示，在调用该函数时必须小心，并且必须确保函数的文档中所述的安全不变量成立。
- 与此同时，一个不安全块意味着编写该块的人仔细检查了其中执行的任何不安全操作的安全不变量是否成立。如果你想要一个近似于现实世界的类比，不安全函数是一个无符号合同，要求调用代码的作者“郑重承诺 X、Y 和 Z”。与此同时，unsafe {} 是调用代码的作者对块中包含的所有不安全合同的签署。在我们继续阅读本章的过程中，请记住这一点。

#### Great Power

- 那么，一旦你与 unsafe {} 签署了不安全合同，你可以做什么呢？老实说，并不是很多。或者说，它并没有启用很多新功能。在不安全块内部，你可以解引用原始指针并调用不安全函数。
- 就是这样。从技术上讲，还有一些其他的事情可以做，比如访问可变和外部静态变量，访问联合体的字段，但这些并没有改变讨论的内容。而且，老实说，这已经足够了。这些能力一起让你能够制造各种混乱，比如使用mem::transmute将类型转换为另一个类型，解引用指向不知道哪里的原始指针，将&'a转换为&'static，或者使类型在线程边界上可共享，即使它们不是线程安全的。
- 在这一节中，我们不会过多关注这些能力可能出现的问题。我们将把这些问题留给接下来的无聊、负责任、成熟的部分。相反，我们将看看这些漂亮的新玩具以及我们可以用它们做什么。

##### Juggling Raw Pointers

- 使用unsafe的最基本的原因之一是处理Rust的原始指针类型：*const T和*mut T。你应该将它们视为与&T和&mut T更或多或少相似，只是它们没有生命周期，并且不受与其&对应的相同有效性规则的约束，我们将在本章后面讨论。这些类型通常被称为指针和原始指针，主要是因为许多开发人员本能地将引用称为指针，并且将它们称为原始指针可以更清楚地区分。
- 由于*比&适用的规则较少，即使在不安全块之外，您也可以将引用转换为指针。只有当您想要从*转换为&时，才需要使用不安全块。通常，您会将指针转换回引用，以便对指向的数据进行有用的操作，例如读取或修改其值。因此，常用于指针的操作是unsafe { &_ptr }（或 &mut_）。代码中的*可能看起来很奇怪，因为代码只是构造一个引用，而不是解引用指针，但如果您查看类型，它就有意义；如果您有一个*mut T并且想要一个&mut T，那么&mut ptr只会给您一个&mut _mut T。您需要_来指示您想要的是指针ptr所指向的可变引用。

**POINTER TYPES**
你可能想知道*mut T、*const T和std::ptr::NonNull<T>之间的区别是什么。嗯，确切的规范还在制定中，但*mut T和*const T/NonNull<T>之间的主要实际区别是*mut T在T上是不变的（参见第1章的“生命周期的变化”），而另外两个是协变的。正如名称所示，*const T和NonNull<T>主要的区别在于NonNull<T>不允许是空指针，而*const T允许。

- 在选择这些类型之间时，我给出的最佳建议是根据直觉选择，如果你能够命名相关的生命周期，你会选择使用&mut还是&。如果你会选择使用&，并且你知道指针永远不会为空，那么使用NonNull<T>。它受益于一种称为niche优化的酷炫优化：基本上，由于编译器知道该类型永远不会为空，它可以利用这个信息来表示像Option<NonNull<T>>这样的类型，而不需要额外的开销，因为None情况可以通过将NonNull设置为null指针来表示！空指针值是NonNull<T>类型中的一个niche。如果指针可能为空，使用*const T。如果你会选择使用&mut T，使用*mut T。

##### Unrepresentable Lifetimes

由于原始指针没有生命周期，它们可以在无法在Rust的生命周期系统中静态地表达指向值的存活性的情况下使用，例如在我们在第8章中讨论的生成器中的自指结构中。指向self的指针在self存在的时间内是有效的（并且不移动，这就是Pin的作用），但这不是您通常可以命名的生命周期。虽然整个自指类型可能是'static的，但self指针不是——如果它是静态的，那么即使您将该指针交给其他人，他们也可以在self消失后继续永远使用它！以清单9-3中的类型为例；在这里，我们尝试将组成一个值的原始字节与其存储的表示一起存储。

```rust

struct Person<'a> {
  name: &'a str,
  age: usize,
}

struct Parsed {
  bytes: [u8; 1024],
  parsed: Person<'???>,
}
```

清单9-3：尝试命名自引用引用的生命周期，但失败了

- Person内部的引用希望引用存储在Parsed中的字节数据，但我们无法为该引用从Parsed中分配生命周期。它既不是'static，也不是类似'self（不存在的），因为如果移动Parsed，引用将不再有效。
- 由于指针没有生命周期，它们可以绕过这个问题，因为您不需要能够命名生命周期。相反，您只需要确保在使用指针时它仍然有效，这就是当您编写 unsafe { &*ptr } 时所做的。在清单9-3的示例中，Person将存储一个 *const str，然后在适当的时候将其不安全地转换为 &str，以确保指针仍然有效。
- 类似的问题也出现在像Arc这样的类型中，它具有指向某个值的指针，该值在某个时期内被多个引用共享，但该时期只有在运行时最后一个Arc被丢弃时才知道。这个指针有点像'static，但实际上并不是——就像在自引用的情况下一样，当最后一个Arc引用消失时，指针将不再有效，因此生命周期更像是'self。在Arc的近亲Weak中，生命周期也是“当最后一个Arc消失时”，但由于Weak不是Arc，生命周期甚至与'self都没有关联。因此，Arc和Weak都在内部使用原始指针。

##### 指针算术

- 使用原始指针，您可以进行任意的指针算术，就像在C语言中一样，通过使用.offset()、.add()和.sub()将指针移动到同一分配内的任何字节位置。这在高度优化的数据结构（如哈希表）中最常用，其中为每个元素存储额外的指针会增加太多开销，并且无法使用切片。这些是相当特殊的用例，在本书中我们不会进一步讨论它们，但我鼓励您阅读hashbrown::RawTable的代码（<https://github.com/rust-lang/hashbrown/>）以了解更多信息！
- 即使您不打算将指针转换为引用，调用指针算术方法也是不安全的。这样做的原因有几个，但主要原因是将指针指向超出其最初指向的分配末尾是非法的。这样做会触发未定义行为，编译器可以决定吞噬您的代码，并将其替换为只有编译器能理解的任意荒谬代码。如果您确实使用这些方法，请仔细阅读文档！

##### To Pointer and Back Again

通常情况下，当你需要使用指针时，是因为你有一些普通的Rust类型，比如引用、切片或字符串，你需要暂时转换为指针的世界，然后再回到原始的普通类型。因此，一些关键的标准库类型提供了一种将它们转换为原始组成部分的方法，例如切片的指针和长度，以及使用这些部分将它们重新构建回整体的方法。例如，你可以使用as_ptr获取切片的数据指针，使用.len获取切片的长度。然后，你可以使用这些值来调用std::slice::from_raw_parts来重建切片。Vec、Arc和String也有类似的方法，返回底层分配的原始指针，而Box则有Box::into_raw和Box::from_raw，它们执行相同的操作。

##### Playing Fast and Loose with Types

有时，你有一个类型T，并希望将其视为其他类型U。无论是因为你需要进行快速的零拷贝解析，还是因为你需要处理一些生命周期，Rust为你提供了一些（非常不安全的）工具来实现这一点。

- 这些中第一个也是最常用的是指针类型转换：你可以将*const T转换为任何其他*const U（mut也是如此），而且你甚至不需要使用unsafe来进行转换。只有当你稍后尝试将转换后的指针用作引用时，不安全性才会发挥作用，因为你必须断言原始指针实际上可以用作指向它所指向的类型的引用。
- 当与外部函数接口（FFI）一起工作时，这种类型的指针转换特别方便——您可以将任何Rust指针转换为*const std::ffi::c_void或*mut std::ffi::c_void，然后将其传递给期望void指针的C函数。同样，如果您从C中获得了一个之前传递的void指针，您可以轻松地将其转换回原始类型。
- 当你想将一系列字节解释为普通数据时，指针转换也很有用——比如整数、布尔值、字符和数组，或者#[repr(C)]结构体等这些类型，或者直接将这些类型写入字节流而不进行序列化。如果你想尝试这样做，需要记住很多安全不变量，但我们将在以后讨论这个问题。

##### Calling Unsafe Functions

- 可以说，unsafe最常用的功能是它使您能够调用不安全函数。在堆栈的更深层次，大多数这些函数之所以不安全，是因为它们在某个基本层次上操作原始指针，但在堆栈的较高层次，您主要通过函数调用与不安全交互。
- 调用不安全函数可能会带来无限的可能性，这完全取决于你所交互的库。但一般来说，不安全函数可以分为三类：与非Rust接口交互的函数、跳过安全检查的函数和具有自定义不变量的函数。

##### Foreign Function Interfaces

- Rust允许您使用extern块声明由Rust以外的语言定义的函数和静态变量（我们将在第11章中详细讨论）。当您声明这样一个块时，您告诉Rust在最终的程序二进制链接时，其中的项将由某个外部源实现，比如您正在集成的C库。由于extern存在于Rust的控制之外，它们本质上是不安全的。如果您从Rust调用C函数，一切都不确定——它可能覆盖整个内存内容，并破坏您整齐排列的所有引用，使其成为指向内核中随机指针的引用。同样，extern静态变量可以随时被外部代码修改，并且可能被填充有与其声明类型完全不符的坏字节。然而，在不安全块中，只要您愿意为extern的另一侧遵守Rust的规则，您就可以尽情访问它们。

##### I’ll Pass on Safety Checks

- 通过引入额外的运行时检查，一些不安全操作可以完全变为安全。例如，访问切片中的项是不安全的，因为您可能尝试访问超出切片长度的项。但是，考虑到这个操作是多么常见，如果索引到一个切片是不安全的，那将是不幸的。相反，安全的实现包括边界检查，如果您提供的索引超出了切片的范围，它们要么引发 panic，要么返回一个 Option。这样，即使您传入超出切片长度的索引，也不会导致未定义行为。另一个例子是哈希表，在哈希表中，它会对您提供的键进行哈希，而不是让您自己提供哈希；这确保您永远不会使用错误的哈希来访问键。
- 然而，在追求终极性能的过程中，一些开发者可能会发现这些安全检查在最紧密的循环中增加了一些额外的开销。为了满足对性能要求极高的情况，并且调用者知道索引在范围内，许多数据结构提供了特定方法的替代版本，这些方法没有这些安全检查。这些方法通常在名称中包含unchecked一词，以表示它们盲目地相信提供的参数是安全的，并且不执行任何繁琐、缓慢的安全检查。一些例子包括NonNull::new_unchecked、slice::get_unchecked、NonZero::new_unchecked、Arc::get_mut_unchecked和str::from_utf8_unchecked。
- 在实践中，不安全方法的安全性和性能的权衡很少值得。与性能优化一样，先进行测量，然后再进行优化。

##### Custom Invariants

大多数使用不安全的操作都依赖于自定义不变量。也就是说，它们依赖于 Rust 本身提供的不变量之外的不变量，这些不变量特定于特定的应用程序或库。由于如此多的函数属于这个类别，很难给出一个好的一般性总结。相反，我将给出一些在实践中可能遇到并希望使用的具有自定义不变量的不安全函数的示例：

###### MaybeUninit::assume_init

- MaybeUninit类型是在Rust中存储不合法值的几种方式之一。您可以将MaybeUninit<T>视为一个可能在当前时刻不合法使用的T。例如，MaybeUninit<NonNull>允许持有空指针，MaybeUninit<Box>允许持有悬空的堆指针，MaybeUninit<bool>允许持有数字3的位模式（通常应为0或1）。如果您逐位构造一个值或处理将最终变为有效值的零值或未初始化内存（例如通过调用std::io::Read::read进行填充），这将非常有用。assume_init函数断言MaybeUninit现在持有类型T的有效值，因此可以将其用作T。

##### ManuallyDrop::drop


ManuallyDrop类型是围绕类型T的包装类型，当ManuallyDrop被丢弃时，不会丢弃T。换句话说，它将外部类型（ManuallyDrop）的丢弃与内部类型（T）的丢弃分离开来。它通过DerefMut<Target = T>实现对T的安全访问，但也提供了一个drop方法（与Drop trait的drop方法分开），用于丢弃包装的T而不丢弃ManuallyDrop。也就是说，尽管丢弃了T，但drop函数采用&mut self的形式，因此将ManuallyDrop留在原地。如果您必须显式丢弃一个无法移动的值，例如在Drop trait的实现中，这将非常有用。一旦该值被丢弃，再次尝试访问T将不再安全，这就是为什么调用drop是不安全的原因——它断言T将永远不会再次被访问。


##### std::ptr::drop_in_place

drop_in_place允许您通过指向该值的指针直接调用值的析构函数。这是不安全的，因为在调用后，指针指向的对象将被留在原地，所以如果某些代码尝试解引用该指针，将会出现问题！这种方法在您可能希望重用内存（例如在区块分配器中）并且需要在原地丢弃旧值而不回收周围内存时特别有用。

##### Waker::from_raw

在第8章中，我们讨论了Waker类型以及它由数据指针和一个包含手动实现的vtable的RawWaker组成。一旦构建了Waker，vtable中的原始函数指针（如wake和drop）可以从安全代码中调用（分别通过Waker::wake和drop(waker)）。Waker::from_raw是异步执行器断言其vtable中的所有指针实际上都是有效的函数指针，并遵循RawWakerVTable文档中设定的约定。

##### std::hint::unreachable_unchecked

hint模块包含一些向编译器提供关于周围代码的提示的函数，但实际上不会生成任何机器代码。
特别是，unreachable_unchecked函数告诉编译器在运行时不可能到达代码的某个部分。
这反过来允许编译器基于这个知识进行优化，比如消除到该位置的条件分支。
与unreachable!宏不同，如果代码确实到达了相应的行，它会引发panic，而错误的unreachable_unchecked的影响很难预测。
编译器优化可能会导致奇怪和难以调试的行为，更不用说你的程序将在它认为是真实的情况下继续运行，而实际上并非如此！

##### std::ptr::{read,write}_{unaligned,volatile}

- ptr模块包含一些函数，让您可以使用不符合Rust对指针的一般假设的奇怪指针。其中第一对函数是read_unaligned和write_unaligned，它们允许您访问指向T的指针，即使T的存储方式不符合T的对齐方式（请参见第2章中关于对齐的部分）。如果T直接包含在字节数组中或以其他方式与其他值一起紧密打包而没有适当的填充，可能会发生这种情况。第二对值得注意的函数是read_volatile和write_volatile，它们允许您操作指向非正常内存的指针。具体来说，这些函数总是访问给定的指针（即使连续两次读取相同的指针，它们也不会被缓存在寄存器中），并且编译器不会重新排序与其他volatile访问相关的访问。在处理不由正常DRAM内存支持的指针时，volatile操作非常有用，我们将在第11章中进一步讨论这个问题。
- 最终，这些方法是不安全的，因为它们解引用给定的指针（而且是对拥有的T进行解引用），所以作为调用者，您需要对与此操作相关的所有合同进行签署。

##### std::thread::Builder::spawn_unchecked

我们熟悉并喜爱的普通 thread::spawn 要求提供的闭包是 'static 的。这个限制源于这样一个事实：被创建的线程可能运行的时间不确定；如果我们被允许使用对调用者栈的引用，调用者可能在被创建的线程退出之前就返回了，使得引用无效。然而，有时候你知道调用者中的某个非 'static 值将会在被创建的线程之后继续存在。这可能发生在你在丢弃相关值之前加入线程，或者在你知道被创建的线程不再使用该值之后严格地丢弃该值。这就是 spawn_unchecked 的用武之地——它没有 'static 限制，因此只要你愿意签署合同，保证不会发生任何不安全的访问，就可以实现这些用例。但要小心 panic；如果调用者发生 panic，它可能会提前丢弃值，导致被创建的线程中出现未定义行为！

- 需要注意的是，所有这些方法（实际上是标准库中的所有不安全方法）都提供了明确的文档，说明它们的安全不变量，这对于任何不安全方法都应该是这样的。

###### Implementing Unsafe Traits

不安全特性不是使用不安全，而是实现不安全。这是因为不安全代码允许依赖于不安全特性实现的正确性（由特性文档定义）。例如，要实现不安全特性Send，您需要编写unsafe impl Send for .... 像不安全函数一样，不安全特性通常具有在特性文档中指定的自定义不变量。因此，很难将不安全特性作为一个整体进行讨论，因此在这里我将给出一些值得介绍的标准库中的常见示例。

###### Send and Sync

Send和Sync特性表示类型在跨线程边界发送或共享是安全的。我们将在第10章中更详细地讨论这些特性，但现在你需要知道的是它们是自动特性，所以编译器通常会为大多数类型自动实现它们。但是，与自动特性一样，如果类型中的任何成员本身不是Send或Sync，那么Send和Sync将不会被实现。

- 在不安全代码的上下文中，这个问题主要是由于原始指针引起的，原始指针既不是Send也不是Sync。乍一看，这似乎是合理的：编译器无法知道谁还可能拥有对同一值的原始指针，以及他们可能在此刻如何使用它，所以这种类型如何安全地跨线程发送呢？然而，作为经验丰富的不安全开发者，这个论点似乎是脆弱的——毕竟，解引用原始指针已经是不安全的，那么处理Send和Sync的不变量为什么会有所不同呢？

- 严格来说，裸指针可以同时是Send和Sync。问题在于，如果它们是Send和Sync，那么包含裸指针的类型也会自动成为Send和Sync，即使其作者可能没有意识到这一点。开发者可能会不安全地解引用裸指针，而从未考虑过如果这些类型在线程边界上被发送或共享会发生什么，从而无意中引入未定义行为。相反，裸指针类型阻止了这些自动实现，作为对不安全代码的额外保护，要求作者明确地签署合同，表示他们也遵循了Send和Sync的不变量。

**注意** 在实现Send和Sync的不安全代码中，常见的错误是忘记为泛型参数添加约束：unsafe impl<T: Send> Send for MyUnsafeType<T> {}。

##### GlobalAlloc

GlobalAlloc trait 是在 Rust 中实现自定义内存分配器的方式。在本书中我们不会过多讨论这个主题，但这个 trait 本身是很有趣的。列表 9-4 给出了 GlobalAlloc trait 的必需方法。

```rust

pub unsafe trait GlobalAlloc {
  pub unsafe fn alloc(&self, layout: Layout) ->*mut u8;
  pub unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout);

}
```

清单 9-4：具有必需方法的 GlobalAlloc trait

- 在其核心，GlobalAlloc trait 有一个用于分配新内存块的方法 alloc，和一个用于释放内存块的方法 dealloc。Layout 参数描述了类型的大小和对齐方式，正如我们在第2章中讨论的那样。这些方法都是不安全的，并且需要调用者遵守一些安全不变量。
- GlobalAlloc 本身也是不安全的，因为它对 trait 的实现者施加了限制，而不是对方法的调用者。只有 trait 的不安全性才能确保实现者同意遵守 Rust 自身对其内存分配器的不变量的假设，例如标准库中 Box 的实现。如果该 trait 不是不安全的，实现者可以以一种安全的方式实现 GlobalAlloc，从而产生不对齐的指针或错误大小的分配，这将在其他假设分配是合理的安全代码中触发不安全性。这将违反安全代码不应该能够触发其他安全代码中的内存不安全的规则，从而引发各种混乱。

##### Surprisingly Not Unpin


- Unpin特性并不是不安全的，这让许多Rust开发者感到惊讶。即使在阅读第8章之后，这可能对你来说也是个惊喜。毕竟，该特性应该确保自引用类型在被移动后不会失效（也就是在它们被放入Pin之后）。因此，Unpin可以安全地从Pin中移除类型，这似乎有些奇怪。
- Unpin不是不安全特性的主要原因有两个。首先，这是不必要的。为你控制的类型实现Unpin并不意味着你可以安全地固定或解固一个!Unpin类型；这仍然需要通过调用Pin::new_unchecked或Pin::get_unchecked_mut来进行不安全操作。其次，对于你控制的任何类型，已经有一种安全的方法可以解固它：Drop特性！当你为一个类型实现Drop时，即使你的类型之前存储在一个Pin中并且是!Unpin的，你仍然可以通过&mut self来访问它，而不需要任何不安全操作。Pin::new_unchecked的不变量必须得到维护，以便首先创建这样一个!Unpin类型的Pin。

##### When to Make a Trait Unsafe

- 在实际应用中，很少有不安全的特性，但所有不安全的特性都遵循相同的模式。
如果一个安全代码假设该特性被正确实现，但实际上没有正确实现，那么它可能会导致内存不安全，那么这个特性应该是不安全的。
- 在这里，Send特性是一个很好的例子 - 安全代码可以轻松地生成一个线程并将值传递给该生成的线程，但如果Rc是Send的话，这个操作序列可能会导致内存不安全。考虑一下如果您克隆了一个Rc<Box>并将其发送到另一个线程会发生什么：两个线程可能会同时尝试释放Box，因为它们没有正确地同步对Rc的引用计数的访问。

- Unpin特性是一个很好的反例。虽然可能编写不安全的代码，如果Unpin的实现不正确，会触发内存不安全，但没有完全安全的代码会因为Unpin的实现而触发内存不安全。确定一个特性是否可以是安全的并不总是容易的（实际上，在RFC过程的大部分时间里，Unpin特性都是不安全的），但你总是可以在特性上采取保守的方式，将其标记为不安全，然后在后面的过程中将其标记为安全，如果你意识到这是正确的情况！只需记住，这是一种不兼容的变化。

- 还要记住，仅仅因为一个trait的不正确（甚至是恶意）实现可能会造成很多混乱，并不意味着将其标记为不安全是一个好的理由。不安全标记首先应该用于突出内存不安全的情况，而不仅仅是可能触发业务逻辑错误的情况。例如，Eq、Ord、Deref和Hash traits都是安全的，即使世界上可能存在很多代码，如果面对一个恶意实现，比如每次调用都返回不同的随机哈希值的Hash，那么这些代码可能会出现混乱。这也适用于不安全代码——几乎肯定存在不安全的代码，如果存在这样的Hash实现，它将在内存上不安全——但这并不意味着Hash应该是不安全的。对于每次解引用都指向不同（但有效）目标的Deref实现也是如此。这样的不安全代码依赖于Hash或Deref的一个合同，而这个合同实际上并不成立；Hash从未声称它是确定性的，Deref也没有。或者更准确地说，这些实现的作者从未使用不安全关键字来做出这样的声明！

**注意** Eq、Hash和Deref等特性的一个重要含义是，不安全代码只能依赖于安全代码的安全性，而不是其正确性。这不仅适用于特性，还适用于所有不安全/安全代码的交互。

#### Great Responsibility

- 到目前为止，我们主要关注的是您可以使用不安全代码做的各种事情。但是，只有在安全的情况下，不安全的代码才能够这样做。即使不安全的代码可以解引用原始指针，它也必须只在它知道该指针在那个时刻作为指向其指针的引用是有效的，并且符合Rust对引用的所有正常要求的情况下才能这样做。换句话说，不安全的代码被赋予了可以用于执行不安全操作的工具，但它必须只使用这些工具来执行安全操作。
- 这就引出了一个问题，首先，什么是安全的？何时可以安全地解引用指针？何时可以安全地转换两种不同的类型？在本节中，我们将探讨在使用不安全代码的强大功能时需要牢记的一些关键不变量，了解一些常见的陷阱，并熟悉一些帮助您编写更安全的不安全代码的工具。
- 关于Rust代码安全性的确切规则仍在制定中。在撰写本文时，不安全代码指南工作组正在努力确定所有的可行和不可行之处，但仍有许多问题没有得到解答。本节中的大部分建议已经基本确定，但我会确保指出任何不确定的地方。如果有什么问题，我希望本节能教会你在编写不安全代码时要小心做出假设，并在将代码声明为生产就绪之前仔细检查Rust参考文档。

##### What Can Go Wrong?

- 如果违反了不安全代码必须遵守的规则，我们就无法详细讨论会发生什么。假设您同时从多个线程对一个值进行可变访问，构造一个不对齐的引用，或者解引用一个悬空指针，那么现在会发生什么呢？
- 不是最终安全的不安全代码被称为具有未定义行为。未定义行为通常以以下三种方式之一显现：完全不显现、通过可见错误或通过不可见的损坏。第一种情况是幸运的情况——您编写了一些真正不安全的代码，但编译器生成了一段在您运行代码的计算机上以合理方式执行的代码。不幸的是，这种幸福是非常脆弱的。如果一个新的、稍微聪明一点的编译器版本出现，或者一些周围的代码导致编译器应用另一种优化，那么代码可能不再执行合理的操作，而转变为更糟糕的情况之一。即使相同的代码由相同的编译器编译，如果在不同的平台或主机上运行，程序可能会表现出不同的行为！这就是为什么即使一切看起来都正常，也要避免未定义行为的重要性。不这样做就像是因为你在第一次中幸存下来，所以要玩第二轮俄罗斯轮盘赌一样。
- 显式错误是最容易捕捉到的未定义行为。例如，如果您解引用空指针，您的程序很可能会崩溃并显示错误，然后您可以调试并找到根本原因。这种调试可能本身很困难，但至少您会收到一个通知，告诉您出现了问题。显式错误也可以以较轻微的方式表现出来，例如死锁、输出混乱或打印但不触发程序退出的恐慌，所有这些都告诉您代码中存在错误，您需要去修复它。
- 最糟糕的未定义行为的表现是没有立即可见的效果，但程序状态被隐式地损坏。交易金额可能与应该的金额略有偏差，备份可能被悄无声息地损坏，或者内部内存的随机位可能暴露给外部客户端。未定义行为可能导致持续的损坏或极少发生的中断。未定义行为的挑战之一是，正如其名称所示，非安全的不安全代码的行为未定义 - 编译器可能完全消除它，极大地改变代码的语义，甚至错误地编译周围的代码。这对您的程序产生的影响完全取决于相关代码的行为。未定义行为的不可预测影响是为什么所有未定义行为都应被视为严重错误的原因，无论它当前如何表现。

**为什么会有未定义行为？**
在关于未定义行为的讨论中，经常会提到一个观点，即编译器应该在代码出现未定义行为时发出错误，而不是执行奇怪和不可预测的操作。这样一来，编写不良的不安全代码几乎是不可能的！

- 不幸的是，这是不可能的，因为未定义行为很少是明确或明显的。相反，通常情况下，编译器会在假设代码遵循规范的情况下应用优化。直到运行时才能确定这是否成立，很难预测其效果。也许优化仍然有效，没有发生任何问题；但也可能不是这样，代码的语义与未优化版本略有不同。
- 如果我们告诉编译器开发者他们不允许对底层代码做任何假设，实际上我们告诉他们不能执行他们目前非常成功实现的广泛优化范围。几乎所有复杂的优化都对所涉及的代码根据语言规范做出了假设。
- 如果你想要一个很好的例子，展示了规范和编译器优化在奇怪的方式下如何相互作用，很难归咎于谁，我推荐阅读Ralf Jung的博文“We Need Better Language Specs”（<https://www.ralfj.de/blog/2020/12/14/provenance.html>）。

##### Validity

在编写不安全代码之前，理解有效性的概念可能是最重要的，它规定了给定类型中哪些值是有效的，或者更不正式地说，类型的值的规则。这个概念比听起来的要简单，让我们深入一些具体的例子。

###### Reference Types

Rust对其引用类型可以持有的值非常严格。具体来说，引用不能悬空，必须对齐，并且必须始终指向其目标类型的有效值。此外，对于给定内存位置，共享引用和独占引用不能同时存在，多个独占引用也不能同时存在。无论您的代码是否使用这些引用，这些规则都适用——即使您立即丢弃它，也不允许创建空引用！

- 共享引用还有一个额外的约束，即在引用的生命周期内，被引用的值不允许发生变化。也就是说，被引用的值在其生命周期内必须保持完全相同。这适用于传递性，因此如果您有一个对包含*mut T的类型的&，即使您可以使用unsafe编写代码来通过该*mut对T进行变异，也不允许这样做。唯一的例外是由UnsafeCell类型包装的值。所有其他提供内部可变性的类型，如Cell、RefCell和Mutex，内部都使用UnsafeCell。
- Rust对引用的严格规则的一个有趣结果是，在很多年里，无法安全地对使用repr(Rust)的紧凑或部分未初始化的结构体的字段取引用。由于repr(Rust)使类型的布局未定义，获取字段的地址的唯一方法是写成&some_struct.field as*const_。然而，如果some_struct是紧凑的，那么some_struct.field可能不对齐，因此创建对它的&是非法的！此外，如果some_struct没有完全初始化，那么some_struct引用本身也无法存在！在Rust 1.51.0中，稳定了ptr::addr_of!宏，它添加了一种直接获取字段引用的机制，而无需先创建引用，从而解决了这个特定的问题。在内部，它使用了称为原始引用（不要与原始指针混淆）的东西，它直接创建指向操作数的指针，而不是通过引用进行中转。原始引用在RFC 2582中引入，但在撰写本文时尚未稳定。

###### Primitive Types

Rust的一些原始类型对其可以持有的值有限制。例如，bool被定义为1字节大小，但只允许持有值0x00或0x01，而char不允许持有代理项或大于char::MAX的值。大多数Rust的原始类型，事实上大多数Rust的类型，也不能从未初始化的内存构造出来。这些限制可能看起来是任意的，但实际上往往源于需要启用否则不可能的优化。

- 这一点在我们之前讨论指针类型时简要提到的niche优化是一个很好的例子。简而言之，niche优化在某些情况下将枚举的鉴别值隐藏在封装类型中。例如，由于引用永远不可能是全零，Option<&T>可以使用全零表示None，从而避免额外的字节（加上填充）来存储鉴别字节。编译器可以以相同的方式优化布尔值，并且可能进一步优化。考虑类型Option<Option<bool>>。由于编译器知道bool只能是0x00或0x01，它可以自由地使用0x02表示Some(None)，并使用0x03表示None。非常好和整洁！但是，如果有人将字节0x03视为布尔值，并将该值放入以这种方式优化的Option<Option<bool>>中，将会发生糟糕的事情。
- 值得重申的是，Rust编译器当前是否实现了这种优化并不重要。重要的是它是允许的，因此您编写的任何不安全代码必须符合该约定，否则如果行为发生变化，可能会在以后遇到错误。

###### Owned Pointer Types

- 拥有内存的类型，如Box和Vec，通常会受到与独占引用指向的内存相同的优化，除非它们通过共享引用明确地访问。具体而言，编译器假设指向的内存不会在其他地方共享或别名，并基于该假设进行优化。例如，如果你从一个Box中提取指针，然后使用相同的指针构造两个Box，并将它们包装在ManuallyDrop中以防止双重释放，那么你很可能会进入未定义行为的领域。即使你只通过共享引用访问内部类型，情况也是如此。（我说“很可能”是因为这在语言参考中尚未完全解决，但已经形成了一个大致的共识。）

###### Storing Invalid Values

- 有时候你需要存储一个当前类型无效的值。最常见的例子是，如果你想为某种类型T分配一块内存，然后从网络中读取字节。在所有字节都被读取之前，内存不会成为一个有效的T。即使你只是尝试将字节读入一个u8的切片中，你也必须先将这些u8清零，因为从未初始化的内存构造一个u8也是未定义的行为。
- MaybeUninit<T> 类型是 Rust 处理无效值的机制。MaybeUninit<T> 精确地存储一个 T（它是 #[repr(transparent)]），但编译器不会对该 T 的有效性做任何假设。它不会假设引用是非空的，Box<T> 不会悬空，或者 bool 只能是 0 或 1。这意味着在 MaybeUninit 中持有由未初始化内存支持的 T 是安全的（正如其名称所示）。MaybeUninit 在其他不安全代码中也是一个非常有用的工具，用于临时存储可能无效的值。也许你需要存储一个别名的 Box<T>，或者暂时存储一个 char 的代理项，MaybeUninit 就是你的朋友。
你通常只会对 MaybeUninit 做三件事情：使用 MaybeUninit::uninit 方法创建它，使用 MaybeUninit::as_mut_ptr 写入其内容，或者在其再次有效时使用 MaybeUninit::assume_init 获取内部的 T。
- 如其名称所示，uninit 创建一个与 T 大小相同的 MaybeUninit<T>，最初包含未初始化的内存。as_mut_ptr 方法为您提供了一个指向内部 T 的原始指针，您可以对其进行写入；没有任何限制阻止您从中读取，但从任何未初始化的位读取是未定义行为。最后，unsafe 的 assume_init 方法消耗 MaybeUninit<T> 并将其内容作为 T 返回，前提是后备内存现在组成一个有效的 T。
清单 9-5 展示了我们如何使用 MaybeUninit 安全地初始化一个字节数组，而无需显式地将其清零。

```rust


fn fill(gen: impl FnMut() -> Option<u8>) {
  let mut buf = [MaybeUninit::<u8>::uninit(); 4096];
  let mut last = 0;
  for (i, g) in std::iter::from_fn(gen).take(4096).enumerate() {
    buf[i] = MaybeUninit::new(g);
    last = i + 1;
  }
  // Safety: all the u8s up to last are initialized.
  let init: &[u8] = unsafe {
  MaybeUninit::slice_assume_init_ref(&buf[..last])
  };
// ... do something with init ...
}
```

清单 9-5：使用 MaybeUninit 安全地初始化数组

- 虽然我们可以将buf声明为[0; 4096]，但这将要求函数在执行之前先将所有这些零写入堆栈，即使它很快就会再次覆盖它们。通常情况下，这不会对性能产生明显影响，但如果这是在一个非常热的循环中，可能会有影响！在这里，我们允许数组保留在调用函数时堆栈上存在的任何值，然后只覆盖我们最终需要的部分。

**注意** 要小心部分初始化内存的丢弃。如果恰好在 MaybeUninit<T> 完全初始化之前发生 panic，你需要小心只丢弃现在有效的部分 T（如果有的话）。你可以简单地丢弃 MaybeUninit 并忘记后备内存，但如果它持有一个 Box，你可能会导致内存泄漏！

###### Panics

- 确保使用不安全操作的代码是安全的一个重要但经常被忽视的方面是，代码必须准备好处理 panic。特别是，正如我们在第5章中简要讨论过的那样，Rust在大多数平台上的默认 panic 处理程序不会在 panic 时崩溃程序，而是会展开当前线程。展开 panic 会有效地丢弃当前作用域中的所有内容，从当前函数返回，丢弃包围函数作用域中的所有内容，依此类推，一直到当前线程的第一个栈帧为止。如果您在不安全代码中没有考虑到展开，可能会遇到麻烦。例如，考虑清单 9-6 中的代码，它试图一次性高效地将多个值推入 Vec 中。

```rust 


impl<T: Default> Vec<T> {
  pub fn fill_default(&mut self) {
    let fill = self.capacity() - self.len();
    if fill == 0 { return; }
    let start = self.len();
    unsafe {
    self.set_len(start + n);
    for i in 0..fill {
      *self.get_unchecked_mut(start + i) = T::default();
      }
    }
  }
}
```
清单 9-6：使用默认值填充向量的看似安全的方法

- 如果调用 T::default 引发 panic，那么这段代码会发生什么呢？首先，fill_default 将丢弃所有的局部值（只是整数），然后返回。调用者也会做同样的操作。在堆栈的某个位置，我们到达了 Vec 的所有者。当所有者丢弃向量时，我们就有了一个问题：向量的长度现在表示我们拥有比实际生成的 T 更多的 T，这是由于调用 set_len 导致的。例如，如果第一次调用 T::default 在我们打算填充八个元素时引发 panic，那么 Vec::drop 将在实际包含未初始化内存的八个 T 上调用 drop！
- 在这种情况下，修复方法很简单：代码在写入所有元素后必须更新长度。如果我们没有仔细考虑非安全代码在展开 panic 时对正确性的影响，我们可能不会意识到存在问题。
- 当你检查代码时，要注意可能引发 panic 的语句，并考虑如果发生 panic，你的代码是否安全。或者，检查是否可以确信所讨论的代码永远不会发生 panic。特别注意调用用户提供的代码的任何情况，在这些情况下，你无法控制 panic，并且应该假设用户代码会发生 panic。
- 当你使用 ? 运算符从函数中提前返回时，也会出现类似的情况。如果这样做，请确保即使不执行函数中的其余代码，你的代码仍然是安全的。? 运算符很少会让你措手不及，因为你明确选择了它，但还是值得注意。

###### Casting

正如我们在第2章中讨论的那样，即使两个不同的类型都是#[repr(Rust)]，它们在内存中的表示方式可能也不同，即使它们具有相同类型和相同顺序的字段。这意味着在两个不同类型之间进行类型转换是否安全并不总是明显的。事实上，Rust甚至不能保证具有相同布局的泛型参数的单个类型的两个实例在内存中的表示方式相同。例如，在清单9-7中，A和B不能保证具有相同的内存表示。

```rust 

struct Foo<T> {
  one: bool,
  two: PhantomData<T>,
}
struct Bar;
struct Baz;

type B = Foo<Baz>;
type A = Foo<Bar>;

```

清单 9-7：类型布局是不可预测的。

- 在不安全代码中进行类型转换时，repr(Rust)的不确定性是需要牢记的重要因素——即使两个类型感觉上应该是可以互换的，实际上并不一定如此。在具有不同表示的两个类型之间进行转换很容易导致未定义行为。在撰写本文时，Rust社区正在积极解决类型表示的确切规则，但目前很少提供保证，所以我们必须根据这些规则编写代码。
- 即使相同的类型被保证具有相同的内存表示，当类型被嵌套时，仍然会遇到相同的问题。例如，虽然UnsafeCell<T>、MaybeUninit<T>和T实际上只是持有一个T，你可以自由地在它们之间进行转换，但一旦你有一个Option<MaybeUninit<T>>，情况就不同了。尽管Option<T>可以利用niche优化（使用某个无效的T值来表示Option的None），但MaybeUninit<T>可以持有任何位模式，因此该优化不适用，并且必须保留一个额外的字节用于Option的鉴别器。
- 带有包装类型时，不仅仅是优化可能导致布局发散。以清单9-8中的代码为例；在这里，Wrapper<PhantomData<u8>>和Wrapper<PhantomData<i8>>的布局完全不同，尽管提供的类型都是空的！

```rust

struct Wrapper<T: SneakyTrait> {
  item: T::Sneaky,
  iter: PhantomData<T>,
}
trait SneakyTrait {
  type Sneaky;
}
impl SneakyTrait for PhantomData<u8> {
  type Sneaky = ();
}
impl SneakyTrait for PhantomData<i8> {
  type Sneaky = [u8; 1024];
}
```
清单 9-8：包装类型使得类型转换变得困难。

- 这并不意味着在 Rust 中你永远不能进行类型转换。当你控制涉及的所有类型及其 trait 实现时，或者类型是 #[repr(C)] 时，情况会变得更容易。你只需要意识到 Rust 对内存表示几乎没有提供任何保证，并相应地编写代码！

##### The Drop Check

Rust借用检查器本质上是一种复杂的工具，用于在编译时确保代码的安全性，这也是Rust能够表达代码“安全性”的方式。借用检查器如何工作超出了本书的范围，但是其中一个检查，即drop检查，在某些细节上值得详细介绍，因为它对不安全代码有一些直接的影响。为了理解drop检查，让我们暂时站在Rust编译器的角度，看一下两个代码片段。首先，看一下清单9-9中的三行代码，它获取一个可变引用并在之后立即对同一个变量进行修改。

```rust

let mut x = true;
let foo = Foo(&mut x);
x = false;
```
清单 9-9：Foo的实现决定了这段代码是否应该编译

- 在不知道Foo的定义的情况下，你能否判断这段代码是否应该编译？当我们设置x = false时，仍然有一个foo挂在那里，它将在作用域结束时被丢弃。我们知道foo包含了对x的可变借用，这意味着修改x所需的可变借用是非法的。但是允许它有什么问题呢？事实证明，只有当Foo实现了Drop时，允许修改x才会有问题——如果Foo没有实现Drop，那么我们知道Foo在最后一次使用后不会再触及对x的引用。由于最后一次使用在我们需要独占引用进行赋值之前，我们可以允许这段代码！另一方面，如果Foo实现了Drop，我们不能允许这段代码，因为Drop实现可能使用对x的引用。
- 现在你已经热身了，看一下清单9-10。在这个不那么直观的代码片段中，可变引用被深埋了起来。

```rust

fn barify<’a>(_: &’a mut i32) -> Bar<Foo<’a>> { .. }
let mut x = true;
let foo = barify(&mut x);
x = false;

```

清单 9-10：Foo和Bar的实现决定了这段代码是否应该编译

- 再次，在不知道Foo和Bar的定义的情况下，你能否判断这段代码是否应该编译？让我们考虑一下如果Foo实现了Drop但Bar没有实现Drop的情况，因为这是最有趣的情况。通常情况下，当一个Bar超出作用域或被丢弃时，它仍然需要丢弃Foo，这意味着代码应该被拒绝，原因与之前相同：Foo::drop可能会访问对x的引用。然而，Bar可能根本不直接包含Foo，而是只包含一个PhantomData<Foo<'a>>或者一个&'static Foo<'a>，在这种情况下，代码实际上是可以的——即使Bar被丢弃，Foo::drop也不会被调用，对x的引用也不会被访问。这是我们希望编译器接受的代码，因为人类可以确定这是可以的，即使编译器很难检测到这一点。
- 我们刚刚讨论的逻辑就是drop检查。通常情况下，它不会对不安全代码产生太大影响，因为其默认行为与用户的期望相符，但有一个重要的例外：悬垂的泛型参数。想象一下，你正在实现自己的Box<T>类型，并且有人像我们在清单9-9中所做的那样将一个&mut x放入其中。你的Box类型需要实现Drop来释放内存，但它在除了丢弃之外不会访问T。由于丢弃一个&mut不会做任何事情，所以在最后一次访问Box之后但在其被丢弃之前，代码可以完全放心地再次访问&mut x！为了支持这样的类型，Rust有一个不稳定的功能叫做dropck_eyepatch（因为它使得drop检查部分失效）。这个功能很可能永远保持不稳定，并且只作为一个临时的逃生通道，直到找到一个合适的机制。dropck_eyepatch功能添加了一个#[may_dangle]属性，你可以在类型的Drop实现中为泛型生命周期和类型添加作为前缀，告诉drop检查机制在丢弃之后不会再使用注解的生命周期或类型。你可以这样使用它：

```rust

unsafe impl<#[may_dangle] T> Drop for ..
```

- 这个逃生通道允许类型声明一个给定的泛型参数在 Drop 中不被使用，这使得像 Box<&mut T> 这样的用例成为可能。然而，如果你的 Box<T> 持有一个原始堆指针 *mut T，并且使用 #[may_dangle] 允许 T 悬垂，那么就会引入一个新的问题。具体来说，*mut T 会让 Rust 的 drop 检查认为你的 Box<T> 不拥有 T，因此也不会调用 T::drop。结合 may_dangle 断言，在 Box<T> 被丢弃时不访问 T，drop 检查现在会认为拥有一个 Box<T>，其中 T 不会在 Box 被丢弃之前存活（就像清单 9-10 中我们缩短的 &mut x）。但事实并非如此，因为我们确实调用了 T::drop，它可能会访问到 x 的引用。幸运的是，修复很简单：我们添加一个 PhantomData<T>，告诉 drop 检查即使 Box<T> 不持有任何 T，并且在丢弃时不会访问 T，它仍然拥有一个 T，并且在 Box 被丢弃时会丢弃一个 T。清单 9-11 展示了我们假设的 Box 类型的样子。

```rust

struct Box<T> {
t: NonNull<T>, // NonNull not _mut for covariance (Chapter 1)
_owned: PhantomData<T>, // For drop check to realize we drop a T
}
unsafe impl<#[may_dangle] T> for Box<T> { /_ ... _/ }

```

清单 9-11：Box 的定义在 drop 检查方面具有最大的灵活性

- 这种交互是微妙且容易被忽视的，但它只会在使用不稳定的#[may_dangle]属性时出现。希望这个小节能作为一个警告，以便当你将来在代码中看到不安全的impl Drop时，你会知道要寻找PhantomData<T>！

**注意** 关于 Drop 的不安全代码的另一个考虑是确保在 self 被丢弃后，仍然让 T 继续存在的 Type<T>。例如，如果你正在实现延迟垃圾回收，你还需要添加 T: 'static。否则，如果 T = WriteOnDrop<&mut U>，后续对 T 的访问或丢弃可能会触发未定义行为！

#### Coping with Fear

通过本章的学习，你可能比之前更害怕不安全的代码。虽然这是可以理解的，但重要的是要强调，编写安全的不安全代码不仅是可能的，而且大多数情况下并不那么困难。关键是要确保你小心处理不安全的代码；这是一半的斗争。在诉诸不安全代码之前，请确保没有安全的实现可供使用。
在本章的剩余部分，我们将介绍一些技术和工具，可以帮助你在无法避免使用不安全代码时对其正确性更有信心。

##### Manage Unsafe Boundaries

诱人的是，在局部范围内推理不安全性；也就是说，在你刚刚编写的不安全代码块中考虑它是否安全，而不太考虑它与代码库的其他部分的交互。不幸的是，这种局部推理经常会带来麻烦。一个很好的例子是Unpin trait——你可能为你的类型编写一些代码，使用Pin::new_unchecked来生成类型字段的固定引用，当你编写它时，这段代码可能是完全安全的。但是在以后的某个时间点，你（或其他人）可能为该类型添加了一个安全的Unpin实现，突然间，不安全的代码就不再安全了，尽管它与新的实现毫不相干！

- 安全性是只能在与不安全代码相关的所有代码的隐私边界处进行检查的属性。这里的隐私边界不是一个正式的术语，而是试图描述“与不安全位相关的代码的任何部分”。例如，如果你在模块bar中声明了一个公共类型Foo，并标记为pub或pub(crate)，那么同一crate中的任何其他代码都可以为Foo实现方法和特性。因此，如果你的不安全代码的安全性取决于Foo不实现特定的特性或具有特定签名的方法，那么你需要记住在为Foo添加impl时重新检查该不安全代码的安全性。另一方面，如果Foo对整个crate不可见，那么只有一个更小的范围可以添加有问题的实现，因此，意外添加破坏安全不变性的实现的风险相应降低。如果Foo是私有的，那么只有当前模块和任何子模块可以添加这样的实现。
- 同样的规则也适用于字段的访问：如果不安全代码的安全性取决于类型字段上的某些不变量，那么任何可以访问这些字段的代码（包括安全代码）都在不安全代码的隐私边界内。在这里，最小化隐私边界是最好的方法——无法访问字段的代码无法破坏你的不变量！
- 由于不安全代码通常需要这种广泛的推理，最佳实践是尽可能将不安全性封装在代码中。以单个模块的形式提供不安全性，并努力为该模块提供完全安全的接口。这样，你只需要审查该模块的内部以确保不变量。或者更好的是，将不安全的部分放在自己的crate中，这样你就不会意外留下任何漏洞！
- 然而，并不总是可能将复杂的不安全交互完全封装到一个安全的接口中。在这种情况下，尝试缩小必须是不安全的公共接口的范围，这样你只需要很少的接口，给它们起一个清晰表达需要小心的名称，然后严格记录它们。
- 有时候，人们会诱惑地去掉内部API上的不安全标记，这样你就不必在代码中到处写unsafe {}了。毕竟，在你的代码中，你知道如果之前调用了bazzify，就永远不会调用frobnify，对吗？去掉不安全标记可以使代码更清晰，但从长远来看通常是一个糟糕的决定。一年后，当你的代码库增长，你已经忽略了一些安全不变量，并且“只想快速地拼凑这个功能”，很有可能你会无意中违反其中一个不变量。而且，即使你从不犯错误，其他贡献者呢？最终，更干净的代码不足以去除故意嘈杂的不安全标记。

##### Read and Write Documentation

不言而喻，如果你编写了一个不安全的函数，你必须记录调用该函数的条件。在这里，清晰和完整都很重要。不要遗漏任何不变量，即使你已经在其他地方写过它们。如果你有一个需要特定全局不变量的类型或模块，即对于类型的所有使用，这些不变量必须始终保持不变，那么在每个不安全函数的文档中提醒读者他们也必须遵守全局不变量。开发人员通常以临时的、按需的方式阅读文档，所以你可以假设他们可能没有仔细阅读你精心编写的模块级文档，需要给他们一个提示。

- 可能不太明显的是，你还应该记录所有不安全的实现和代码块，可以将其视为提供证明，证明你确实遵守了所需操作的契约。例如，slice::get_unchecked要求提供的索引在切片的范围内；当你调用该方法时，在它上面加上一条注释，解释你如何知道索引确实保证在范围内。在某些情况下，不安全代码块所需的不变量可能很多，你的注释可能会很长。这是件好事。我曾多次通过尝试为不安全代码块编写安全注释，然后在中途意识到我实际上没有遵守一个关键不变量而发现错误。当你不得不修改这段代码并确保它仍然安全时，你也会感谢自己。同样，你的项目贡献者也会感谢你，他们刚刚遇到这个不安全调用，并希望理解发生了什么。

- 在你深入编写不安全代码之前，我也强烈建议你阅读《Rustonomicon》（<https://doc.rust-lang.org/nomicon/>）。有很多细节很容易被忽视，如果你不了解它们，它们会给你带来麻烦。我们在本章中涵盖了其中的许多内容，但多了解一些也无妨。在你有疑问时，你还应该大量使用Rust参考手册。它经常更新，如果你对某个假设是否正确有一丝丝不确定，参考手册会指出。如果没有，考虑提出一个问题，以便将其添加进去！

##### Check Your Work

好的，你已经编写了一些不安全的代码，你已经反复检查了所有的不变量，并且认为它已经准备好了。在投入生产之前，有一些自动化工具可以帮助你运行测试套件（你有测试套件吗？）。

- 首先是Miri，中级中间表示解释器。Miri不会将你的代码编译成机器代码，而是直接解释Rust代码。这使得Miri对程序的运行有更多的可见性，从而可以检查你的程序是否做了一些明显错误的事情，比如从未初始化的内存中读取数据。Miri可以捕捉到许多非常微妙且特定于Rust的错误，对于编写不安全代码的人来说是一个救命稻草。
- 不幸的是，由于Miri必须解释代码来执行它，所以在Miri下运行的代码通常比编译后的代码运行得慢得多。因此，Miri应该只用于执行测试套件。它只能检查实际运行的代码，因此无法捕捉到测试套件未触及的代码路径中的问题。你应该将Miri视为测试套件的扩展，而不是替代品。
- 还有一些被称为sanitizer的工具，它们会在运行时对机器代码进行插装以检测错误行为。这些工具的开销和准确性各不相同，但其中一个广受喜爱的工具是Google的AddressSanitizer。它可以检测到许多内存错误，比如使用已释放的内存、缓冲区溢出和内存泄漏，这些都是不正确的不安全代码的常见症状。与Miri不同，这些工具操作的是机器代码，因此通常速度相当快，通常在相同数量级内。但与Miri一样，它们只能分析实际运行的代码，因此一个可靠的测试套件至关重要。
- 使用这些工具的关键是通过持续集成流水线自动化运行它们，以便在每次更改时运行，并确保随着发现错误而逐渐添加回归测试。随着测试套件质量的提高，这些工具在捕捉问题方面变得更加出色，因此通过在修复已知错误时添加新的测试，你可以获得双倍的回报！
- 最后，不要忘记在不安全代码中大量使用断言。引发panic总比触发未定义行为要好！如果可能的话，使用断言检查所有的假设，甚至是像usize的大小这样的东西，如果你依赖它来确保安全性。如果你担心运行时成本，可以利用debug_assert_宏和if cfg!(debug_assertions) || cfg!(test)结构，只在调试和测试环境中执行它们。
**一座纸牌屋？**
不安全代码可能违反Rust的所有安全保证，这经常被用作Rust整个安全论点是虚伪的理由。人们担心的是，只需要一个不正确的不安全代码，整个系统就会崩溃，所有的安全性都会丧失。因此，这种论点的支持者有时会主张至少只有不安全代码才能调用不安全代码，以便不安全性在应用程序的最高层面上可见。
- 这个论点是可以理解的——Rust代码的安全性确实依赖于所有传递的不安全代码的安全性。而且，如果其中一些不安全代码是不正确的，它可能对整个程序的安全性产生影响。然而，这个论点忽略了一个事实，即所有成功的安全语言都提供了一种语言扩展的机制，这些扩展在（安全的）表面语言中无法表达，通常以C或汇编的形式编写的代码。就像Rust依赖于其不安全代码的正确性一样，那些语言的安全性依赖于这些扩展的正确性。
- Rust的不同之处在于它没有单独的扩展语言，而是允许以一种类似于Rust的方言（不安全的Rust）编写扩展。这使得安全代码和不安全代码之间的集成更加紧密，从而减少了由于两者之间的接口不匹配或开发人员只熟悉其中一种而导致的错误的可能性。这种更紧密的集成还使得更容易编写分析不安全代码与安全代码交互正确性的工具，例如Miri。由于不安全的Rust在任何不是显式不安全的操作中仍然受到借用检查器的限制，因此仍然存在许多安全检查，而在开发人员必须转向像C这样的语言时则不存在。


#### Summary

在本章中，我们已经介绍了使用unsafe关键字所带来的能力，以及通过利用这些能力所承担的责任。我们还讨论了编写不安全的unsafe代码的后果，以及你应该将unsafe视为一种向编译器发誓的方式，即你已经手动检查了所指示的代码仍然是安全的。在下一章中，我们将深入探讨Rust中的并发性，并了解如何让你闪亮的新计算机上的所有核心朝着同一个方向努力！

### 10 CONCURRENCY (AND PARALLELISM)

通过本章，我希望为您提供所有关于并发的信息和工具，以便您能够在Rust程序中有效地利用并发，为您的库实现并发使用的支持，并正确使用Rust的并发原语。我不会直接教您如何实现并发数据结构或编写高性能的并发应用程序。相反，我的目标是给您足够的了解底层机制，以便您能够自己使用它们来满足您的需求。 

- 并发有三种形式：单线程并发（如我们在第8章中讨论的async/await），单核多线程并发和多核并发，后者可以实现真正的并行处理。每种形式都允许以不同的方式交错执行程序中的并发任务。如果考虑操作系统调度和抢占的细节，甚至还有更多的子形式，但我们不会深入探讨这些。
- 在类型级别上，Rust只表示并发的一个方面：多线程。一个类型要么可以安全地被多个线程使用，要么不可以。即使你的程序有多个线程（因此是并发的），但只有一个核心（因此不是并行的），Rust必须假设如果有多个线程，可能存在并行性。我们将讨论的大多数类型和技术都适用于两个线程实际上是否并行执行，因此为了保持语言简单，我将在本章中使用“并发”一词来表示“事物几乎同时运行”。当区分重要时，我会明确指出。
- Rust对基于类型的安全多线程的处理非常巧妙，它不是编译器的一个特性，而是开发人员可以扩展的库特性，用于开发复杂的并发契约。由于线程安全是通过类型系统中的Send和Sync实现和边界来表达的，这些实现和边界会传播到应用程序代码，因此整个程序的线程安全性仅通过类型检查来进行检查。
- 《Rust编程语言》已经涵盖了大部分关于并发的基础知识，包括Send和Sync特性、Arc和Mutex以及通道。因此，在这里我不会重复讲述太多，除非在其他主题的特定上下文中值得重复一些内容。相反，我们将看看是什么使并发变得困难，并介绍一些常见的并发模式，以应对这些困难。我们还将探讨并发和异步的交互方式（以及它们不交互的方式），然后深入介绍如何使用原子操作来实现更底层的并发操作。最后，我将在本章结束时给出一些建议，以便在处理并发代码时保持理智。

#### The Trouble with Concurrency

在我们深入研究并发编程的良好模式和Rust的并发机制的细节之前，值得花些时间了解为什么并发在第一时间就具有挑战性。也就是说，为什么我们需要特殊的模式和机制来处理并发代码？

##### 正确性

并发中的主要困难在于协调对共享资源的访问，特别是写访问。如果有很多线程想要共享一个资源，仅仅是为了读取它，那通常很容易：将其放入Arc中或将其放入可以获取到`&'static`的位置，然后就完成了。但是一旦有任何一个线程想要写入，就会出现各种问题，通常以数据竞争的形式出现。简而言之，当一个线程在第二个线程正在访问该状态时更新共享状态时，就会发生数据竞争，无论是为了读取还是更新。如果没有额外的保护措施，第二个线程可能会读取部分被覆盖的状态，破坏第一个线程写入的部分内容，或者根本看不到第一个线程的写入！总的来说，所有的数据竞争都被认为是未定义行为。

- 数据竞争是一个更广泛的问题类别的一部分，主要发生在并发环境中：竞态条件。竞态条件发生在一系列指令中可能有多种结果的情况下，这取决于系统中其他事件的相对时间。这些事件可以是执行特定代码的线程，定时器的触发，网络数据包的到达，或者任何其他时间可变的事件。竞态条件与数据竞争不同，它们本质上并不是坏事，并且不被视为未定义行为。然而，当发生特别奇怪的竞态条件时，它们往往成为错误的温床，正如您在本章中将看到的。

###### Performance

通常，开发人员引入并发性到他们的程序中，希望提高性能。更准确地说，他们希望通过利用更多的硬件资源，每秒执行更多的操作。这可以在单个核心上通过让一个线程在等待时运行另一个线程来实现，也可以在多个核心上通过让线程同时执行工作来实现，每个核心上一个线程，否则这些工作将在一个核心上串行执行。当开发人员谈论并发时，他们通常指的是后一种性能提升，这通常以可扩展性的术语来描述。在这个上下文中，可扩展性意味着“该程序的性能随着核心数量的增加而提高”，这意味着如果给予程序更多的核心，它的性能会提高。

- 虽然实现这样的加速是可能的，但比看起来更困难。在可扩展性方面的终极目标是线性可扩展性，即核心数量加倍会使程序每单位时间完成的工作量加倍。线性可扩展性通常也被称为完美可扩展性。然而，在现实中，很少有并发程序能够实现这样的加速。更常见的是亚线性扩展，即吞吐量随着从一个核心到两个核心的增加而近似线性增加，但添加更多核心会产生递减的回报。有些程序甚至会出现负扩展，即为程序提供更多核心的访问权限会降低吞吐量，通常是因为许多线程都在争夺某个共享资源。
- 可以将一群人试图弹爆一张气泡纸的情况作为一个类比来帮助理解——一开始增加更多的人会有帮助，但在某个点上，由于拥挤使得每个人的工作更加困难，你会遇到收益递减的情况。如果参与的人非常低效，你的团队可能会站在那里讨论谁应该下一个弹气泡，最终一个气泡都没有弹掉！这种在并行执行的任务之间发生干扰的情况被称为争用，是良好扩展性的死敌。争用可以以多种方式产生，但主要的罪魁祸首是互斥、共享资源耗尽和伪共享。

###### Mutual Exclusion

当只允许一个并发任务在任何时候执行特定的代码段时，我们称该代码段的执行是互斥的——如果一个线程执行它，其他线程就不能同时执行。这个典型的例子是互斥锁（mutex），它明确地强制只有一个线程能够进入程序代码的特定临界区。然而，互斥也可以隐式地发生。例如，如果你启动一个线程来管理共享资源，并通过一个mpsc通道向其发送作业，那么该线程实际上实现了互斥，因为一次只有一个这样的作业可以执行。

- 当调用操作系统或库函数时，也可能发生互斥，这些函数在内部强制对关键部分进行单线程访问。例如，多年来，标准的内存分配器对某些分配需要互斥，这使得内存分配成为在其他高度并行的程序中产生显著争用的操作。同样，许多看起来应该是独立的操作系统操作，比如在同一个目录中创建两个不同名称的文件，可能最终必须在内核中按顺序进行。
**注意** 可扩展的并发分配是jemalloc内存分配器的存在理由！

- 互斥是并行加速的最明显障碍，因为根据定义，它强制执行程序的某个部分的串行执行。即使您使程序的其余部分与核心数量完美匹配，您可以实现的总加速度仍受到互斥串行部分长度的限制。请注意您的互斥部分，并努力将其限制在仅在严格必要的地方。

**注意** 对于理论上有兴趣的人来说，由于互斥代码段的限制，可以使用阿姆达尔定律来计算可实现的加速比。

###### Shared Resource Exhaustion

不幸的是，即使您在任务内部实现了完美的并发性，任务需要与之交互的环境本身可能并不完全可扩展。内核每秒只能处理有限数量的TCP套接字发送，内存总线一次只能进行有限数量的读取，您的GPU对并发的容量也是有限的。对此没有解决办法。在实践中，环境通常是完美可扩展性破裂的地方，解决这些问题往往需要大量的重新设计（甚至是新的硬件！），因此在本章中我们不会再详细讨论这个主题。只需记住，可扩展性很少是您可以“实现”的东西，更多的是您努力追求的东西。

###### False Sharing

当两个本不应该争用的操作却发生争用时，就会发生伪共享，从而阻止了有效的同时执行。这通常是因为这两个操作在某个共享资源上发生了交叉，尽管它们使用的是该资源的不相关部分。

- 最简单的例子是锁过度共享，其中一个锁保护了一些复合状态，而两个在其他方面独立的操作都需要获取该锁来更新它们各自的状态部分。这意味着这些操作必须串行执行，而不是并行执行。在某些情况下，可以将单个锁拆分为两个，每个锁用于不同的部分，从而使操作可以并行进行。然而，并不总是直接将锁拆分成这样——状态可能共享一个单一的锁，因为某个第三个操作需要锁定整个状态的所有部分。通常情况下，仍然可以拆分锁，但必须小心不同线程获取拆分锁的顺序，以避免死锁，当两个操作尝试以不同的顺序获取锁时可能会发生死锁（如果你感兴趣，可以查找“哲学家就餐问题”）。或者，对于某些问题，您可以通过使用基础算法的无锁版本来完全避免临界区，尽管这些也很难正确实现。最终，虚假共享是一个难以解决的问题，并没有一个通用的解决方案——但识别问题是一个好的开始。
- 一个更微妙的伪共享示例发生在CPU级别，正如我们在第2章中简要讨论过的。CPU在内部以缓存行的形式操作内存，而不是单个字节，以分摊内存访问的成本。例如，在大多数Intel处理器上，缓存行大小为64字节。这意味着每个内存操作实际上读取或写入的是64字节的倍数。当两个核心想要更新落在同一个缓存行上的两个不同字节的值时，伪共享就会发生；尽管这些更新在逻辑上是不相交的，但它们必须按顺序执行。
- 这种伪共享可能看起来太低级而无关紧要，但实际上它会严重影响应用程序的并行加速。想象一下，你分配了一个整数值的数组，用于指示每个线程完成了多少操作，但这些整数都落在同一个缓存行中 - 现在，所有本来可以并行执行的线程都会在每个操作上争夺那个缓存行。如果操作相对较快，你的大部分执行时间可能都会花在争夺这些计数器上！
- 避免虚假的缓存行共享的技巧是对值进行填充，使其大小与缓存行相同。这样，相邻的两个值总是落在不同的缓存行上。但是，这样做会增加数据结构的大小，所以只有在基准测试表明存在问题时才使用这种方法。

**可扩展性的代价**
并发性的一个有些正交的方面是引入并发性的成本。编译器非常擅长优化单线程代码——毕竟，它们已经这样做很长时间了——而单线程代码往往可以避免使用较昂贵的保护措施（如锁、通道或原子指令）。
总的来说，并发的各种成本可能使并行程序比其单线程对应程序更慢，无论核心数量如何！这就是为什么在优化和并行化之前和之后都进行测量非常重要的原因：结果可能会让你惊讶。
如果你对这个话题感兴趣，我强烈推荐你阅读Frank McSherry在2015年发表的论文《Scalability! But at what COST?》（<https://www.frankmcsherry.org/assets/COST.pdf>），其中揭示了一些特别严重的“昂贵扩展”示例。

#### Concurrency Models

Rust有三种常见的并发模式：共享内存并发、工作池和actor模式。详细介绍每种添加并发的方式需要一本专门的书籍，所以在这里我将重点介绍这三种模式。

##### Shared Memory

共享内存并发在概念上非常简单：线程通过操作彼此共享的内存区域来进行协作。这可以采用由互斥锁保护的状态的形式，或者存储在支持多线程并发访问的哈希映射中。许多线程可以在不相交的数据片段上执行相同的任务，例如，如果许多线程在Vec的不相交子范围上执行某个函数，或者它们可以执行需要一些共享状态的不同任务，例如在数据库中，一个线程处理用户对表的查询，而另一个线程在后台优化用于存储该表的数据结构。
- 当使用共享内存并发时，你选择的数据结构非常重要，特别是如果涉及的线程需要密切合作。普通的互斥锁可能无法扩展到非常小的核心数量之外，读写锁可能允许更多并发读取，但写入速度较慢，分片的读写锁可能允许完全可扩展的读取，但写入会产生很大的干扰。同样，一些并发哈希映射可能追求全面的性能表现，而其他一些则专注于例如并发读取而写入很少的情况。总的来说，在共享内存并发中，你希望使用专门为接近目标用例的数据结构，这样你就可以利用优化，以在你的应用程序关心的性能方面进行权衡，而不关心其他方面。
- 共享内存并发适用于需要多个线程共同更新某个共享状态的情况，而这种更新方式不可交换。也就是说，如果一个线程需要使用某个函数f更新状态s，而另一个线程需要使用某个函数g更新状态，且f(g(s)) != g(f(s))，那么共享内存并发可能是必要的。如果不是这种情况，其他两种模式可能更适合，因为它们往往会导致更简单和更高效的设计。
**注意** 一些问题有已知的算法，可以在没有使用锁的情况下提供并发的共享内存操作。随着核心数量的增加，这些无锁算法可能比基于锁的算法更具扩展性，尽管它们通常由于复杂性而具有较慢的每个核心性能。在性能问题上，始终先进行基准测试，然后寻找替代解决方案。

##### Worker Pools

在工作池模型中，许多相同的线程从共享的作业队列中接收作业，然后完全独立地执行它们。例如，Web服务器通常有一个处理传入连接的工作池，而用于异步代码的多线程运行时通常使用工作池来集体执行应用程序的所有Future任务（或者更准确地说，是顶级任务）。
- 共享内存并发和工作池之间的界限通常很模糊，因为工作池倾向于使用共享内存并发来协调它们从队列中获取作业以及如何将未完成的作业返回到队列中。例如，假设您正在使用数据并行库rayon在并行中对向量的每个元素执行某个函数。在幕后，rayon会启动一个工作池，将向量分割成子范围，然后将子范围分配给工作池中的线程。当工作池中的线程完成一个范围时，rayon会安排它开始处理下一个未处理的子范围。向量在所有工作线程之间共享，并且线程通过支持工作窃取的共享内存队列类似的数据结构进行协调。
- 工作窃取是大多数工作池的关键特性。基本原理是，如果一个线程提前完成了工作，并且没有更多未分配的工作可用，那么该线程可以窃取已经分配给其他工作线程但尚未开始的任务。并不是所有的任务完成所需的时间都相同，因此即使每个工作线程都分配了相同数量的任务，有些工作线程可能会比其他工作线程更快地完成任务。这些提前完成的线程不应该坐在那里等待那些执行时间较长的任务完成，而是应该帮助那些落后的线程，以便整个操作能够更早地完成。
- 实现支持这种工作窃取的数据结构并不容易，因为线程不断尝试从彼此那里窃取工作会带来显著的开销，但这个特性对于高性能的工作池至关重要。如果你发现自己需要一个工作池，通常最好使用一个已经经过大量工作的工作池，或者至少重用现有工作池的数据结构，而不是从头开始编写一个。
- 当每个线程执行的工作相同，但其操作的数据不同时，工作池是一个很好的选择。在rayon并行映射操作中，每个线程执行相同的映射计算；它们只是在底层数据的不同子集上执行。在多线程异步运行时中，每个线程只是简单地调用Future::poll；它们只是在不同的future上调用它。如果您开始区分线程池中的线程，那么可能需要选择不同的设计。
**连接池**
连接池是一个共享内存结构，它保存一组已建立的连接，并将它们分配给需要连接的线程。这是管理与外部服务的连接的库中常见的设计模式。
如果一个线程需要连接，但没有可用的连接，要么建立一个新的连接，要么强制线程阻塞。当线程完成一个连接时，它将该连接返回给连接池，从而使其可供可能正在等待的其他线程使用。
- 通常，连接池最困难的任务是管理连接的生命周期。连接可以以最后一个使用它的线程设置的任何状态返回到池中。因此，连接池必须确保与连接相关的任何状态（无论是客户端还是服务器端）都已重置，以便当连接随后被另一个线程使用时，该线程可以像获得一个新的专用连接一样操作。

##### Actors

Acotor并发模型在许多方面与工作池模型相反。工作池有许多相同的线程共享一个作业队列，而Acotor模型有许多单独的作业队列，每个队列对应一个作业“主题”。每个作业队列都输入到特定的Acotor中，该Acotor处理与应用程序状态的一个子集相关的所有作业。该状态可以是数据库连接、文件、度量收集数据结构或任何其他您可以想象到许多线程可能需要访问的结构。无论是什么，一个单独的Acotor拥有该状态，如果某个任务想要与该状态交互，它需要向拥有的Acotor发送一条消息，总结它希望执行的操作。当拥有的Acotor接收到该消息时，它执行指定的操作，并向询问的任务返回操作的结果（如果相关）。由于Acotor具有对其内部资源的独占访问权，除了消息传递所需的同步机制外，不需要任何锁或其他同步机制。
- Acotor模式的一个关键点是Acotor之间相互通信。例如，负责日志记录的Acotor如果需要写入文件和数据库表，它可能会向负责每个操作的Acotor发送消息，要求它们执行相应的操作，然后继续处理下一个日志事件。通过这种方式，Acotor模型更像是一个网络，而不是一个轮子上的辐条——用户对Web服务器的请求可能从一个负责该连接的Acotor开始，但在满足用户请求之前，可能会传递给系统中更深层次的Acotor产生数十、数百甚至数千条消息。
- Acotor模型并不要求每个Acotor都拥有自己的线程。相反，大多数Acotor系统建议应该有大量的Acotor，因此每个Acotor应该映射到一个任务而不是一个线程。毕竟，Acotor只在执行时需要对其封装的资源进行独占访问，并不关心它们是否在自己的线程上。事实上，Acotor模型经常与工作池模型结合使用——例如，使用多线程异步运行时Tokio的应用程序可以为每个Acotor生成一个异步任务，然后Tokio将每个Acotor的执行作为其工作池中的一个作业。因此，给定Acotor的执行可能会在工作池中的线程之间移动，因为Acotor进行暂停和恢复，但每次Acotor执行时，它都保持对其封装资源的独占访问。
- Acotor并发模型非常适合当您有许多相对独立的资源，并且在每个资源内部几乎没有或根本没有并发机会的情况下。例如，操作系统可能对每个硬件设备都有一个负责的Acotor，而Web服务器可能对每个后端数据库连接都有一个Acotor。如果您只需要少数Acotor，工作在Acotor之间的工作不均衡，或者某些Acotor变得很大，那么Acotor模型可能效果不佳，在这些情况下，您的应用程序可能会受到系统中单个Acotor执行速度的瓶颈限制。由于每个Acotor都希望对其所在的世界片段拥有独占访问权，因此您无法轻松地并行执行该瓶颈Acotor的执行。

#### Asynchrony and Parallelism

正如我们在第8章中讨论的那样，Rust中的异步性使得并发成为可能，而无需并行性 - 我们可以使用选择和连接等构造来使单个线程轮询多个Future，并在其中一个、一些或全部完成时继续执行。由于没有涉及并行性，使用Future的并发性并不基本要求这些Future是可发送的（Send）。即使将Future作为额外的顶级任务来运行也不基本要求Send，因为单个执行器线程可以同时管理多个Future的轮询。

- 然而，在大多数情况下，应用程序既需要并发性又需要并行性。例如，如果一个Web应用程序为每个传入连接构建一个Future，并且同时有许多活动连接，那么它可能希望异步执行器能够利用主机计算机上的多个核心。这不会自然发生：您的代码必须明确告诉执行器哪些Future可以并行运行，哪些不能。
- 特别是，执行器需要提供两个信息，以便让它知道可以将Future的工作分散到一个线程池中。第一个信息是相关的Future是可发送的（Send）- 如果它们不是可发送的，执行器就不允许将这些Future发送到其他线程进行处理，因此无法实现并行性；只有构造这样的Future的线程才能对其进行轮询。
- 第二个信息是如何将Future分割为可以独立运行的任务。这与第8章中关于任务与Future的讨论有关：如果一个巨大的Future包含了一些Future实例，它们本身对应可以并行运行的任务，那么执行器仍然必须调用顶层Future的轮询，并且必须从单个线程中进行，因为轮询需要 &mut self。因此，要实现Future的并行性，您必须显式地生成您希望能够并行运行的Future。此外，由于第一个要求，用于执行此操作的执行器函数将要求传入的Future是可发送的（Send）。

**异步同步原语**
大多数用于阻塞代码的同步原语（例如std::sync）也有异步版本。存在异步通道、互斥锁、读写锁、屏障和各种其他类似构造的异步变体。我们需要这些原语，因为如第8章所讨论的，在Future内部阻塞会阻塞执行器可能需要执行的其他工作，因此是不可取的。
- 然而，这些原语的异步版本通常比它们的同步对应版本慢，因为需要额外的机制来执行必要的唤醒操作。因此，在异步上下文中，即使使用不会阻塞执行器的情况下，您可能仍希望使用同步的同步原语。例如，虽然通常获取互斥锁可能会阻塞很长时间，但对于一个特定的互斥锁来说，这可能并不是真实的情况，也许它只会很少地被获取，并且只会在很短的时间内被获取。在这种情况下，阻塞一段时间直到互斥锁再次可用可能实际上不会引起任何问题。您需要确保在持有MutexGuard时不要放弃或执行其他长时间运行的操作，但除此之外，您不应该遇到问题。
- 然而，像这样的优化总是要先进行测量，只有在同步原语带来显著性能改进时才选择同步原语。如果没有带来性能改进，那么在异步上下文中使用同步原语引入的额外问题可能不值得。

#### Lower-Level Concurrency

标准库提供了std::sync::atomic模块，该模块提供了访问底层CPU原语的功能，高级构造如通道和互斥锁都是基于这些原语构建的。这些原语以原子类型的形式提供，名称以Atomic开头，例如AtomicUsize、AtomicI32、AtomicBool、AtomicPtr等，还有Ordering类型和两个名为fence和compiler_fence的函数。在接下来的几节中，我们将逐个讨论这些内容。
- 这些类型是用于构建需要在线程之间进行通信的任何代码的基本组件。互斥锁、通道、屏障、并发哈希表、无锁栈以及所有其他同步构造最终都依赖于这几个基本原语来完成它们的工作。它们也可以单独使用，用于轻量级线程之间的协作，其中重量级的同步（如互斥锁）是过度的——例如，用于递增共享计数器或将共享布尔值设置为true。
- 原子类型是特殊的，因为它们在多个线程尝试并发访问时具有定义好的语义。这些类型都支持（大部分）相同的API：load、store、fetch_*和compare_exchange。在本节的其余部分，我们将看看它们的作用、如何正确使用它们以及它们的用途。但首先，我们必须讨论低级内存操作和内存顺序。

##### Memory Operations

通常，我们非正式地将访问变量称为“从内存中读取”或“写入内存”。实际上，在代码使用变量和实际访问内存硬件的CPU指令之间有很多机制。至少在高层次上理解这些机制是很重要的，以了解并发内存访问的行为方式。

- 当程序读取变量的值或给变量赋新值时，编译器决定要生成哪些指令。它可以对代码进行各种转换和优化，可能会重新排序程序语句，消除它认为是多余的操作，或者使用CPU寄存器而不是实际内存来存储中间计算结果。编译器在这些转换上受到一些限制，但最终只有一部分变量访问会变成内存访问指令。
- 在CPU级别上，内存指令有两种主要形式：加载和存储。加载将字节从内存中的某个位置拉入CPU寄存器，而存储将字节从CPU寄存器存储到内存中的某个位置。加载和存储每次操作一小块内存：通常是现代CPU上的8个字节或更少。如果变量访问跨越的字节数超过了单个加载或存储可以访问的范围，编译器会自动将其转换为多个适当的加载或存储指令。CPU在执行程序指令时也有一定的灵活性，以更好地利用硬件并提高程序性能。例如，现代CPU在没有彼此依赖关系时经常并行执行指令，甚至可以无序执行。在每个CPU和计算机的DRAM之间还有几层缓存，这意味着根据挂钟时间，对给定内存位置的加载可能不一定能看到对该内存位置的最新存储。
- 在大多数代码中，编译器和CPU只能以不影响结果程序语义的方式转换代码，因此这些转换对程序员来说是不可见的。然而，在并行执行的上下文中，这些转换可能对应用程序行为产生重大影响。因此，CPU通常提供多个不同版本的加载和存储指令，每个指令对于CPU如何重新排序它们以及如何与其他CPU上的并行操作交错具有不同的保证。类似地，编译器（或者更准确地说，编译器编译的语言）提供了不同的注解，您可以使用这些注解来强制执行某些内存访问的特定执行约束。在Rust中，这些注解以原子类型及其方法的形式提供，我们将在本节的其余部分详细介绍它们。

##### Atomic Types

Rust的原子类型之所以被称为原子类型，是因为它们可以以原子方式访问——也就是说，原子类型变量的值是一次性写入的，并且永远不会使用多个存储进行写入，从而保证对该变量的加载不会观察到只有部分字节组成的值发生了更改，而其他部分尚未更改（尚未）。通过与非原子类型进行对比，可以更容易地理解这一点。例如，将一个新值重新分配给类型为(i64, i64)的元组通常需要两个CPU存储指令，每个8字节值一个。如果一个线程执行了这两个存储操作，另一个线程（如果我们忽略借用检查器）可以在第一个存储操作之后但第二个存储操作之前读取元组的值，从而得到元组值的不一致视图。它将读取第一个元素的新值和第二个元素的旧值，这个值实际上从未被任何线程存储过。

- CPU只能以原子方式访问特定大小的值，因此只有少数几种原子类型，它们都位于atomic模块中。每种原子类型都是CPU支持原子访问的大小之一，有多个变体，用于区分值是否为有符号以及区分原子usize和指针（指针与usize大小相同）。此外，原子类型具有显式的加载和存储值的方法，以及一些稍后会介绍的更复杂的方法，以便程序员编写的代码与生成的CPU指令之间的映射更清晰。例如，AtomicI32::load执行对有符号32位值的单个加载，而AtomicPtr::store执行对指针大小（在64位平台上为64位）值的单个存储。

##### Memory Ordering
大多数原子类型的方法都接受一个Ordering类型的参数，该参数决定了原子操作所受到的内存顺序限制。在不同的线程中，对原子值的加载和存储可能会被编译器和CPU按照每个原子操作所请求的内存顺序进行交错。在接下来的几节中，我们将看到一些示例，说明控制顺序对于获得预期的语义在编译器和CPU中是重要且必要的。

- 内存顺序经常让人感到反直觉，因为我们人类习惯从上到下阅读程序，并想象它们按行执行 - 但这不是代码在硬件上实际执行的方式。内存访问可以重新排序，甚至完全省略，并且一个线程上的写入可能不会立即对其他线程可见，即使程序顺序中的后续写入已经被观察到。

- 可以这样理解：每个内存位置都会看到来自不同线程的一系列修改，而不同内存位置的修改序列是独立的。如果两个线程T1和T2都写入内存位置M，那么即使按照使用秒表测量的时间，T1先执行，T2对M的写入仍然可能在M上看起来先发生，除非两个线程之间存在其他约束。实际上，计算机在确定给定内存位置的值时不考虑挂钟时间，只关注程序员对什么构成有效执行的执行约束。例如，如果T1写入M，然后创建线程T2，然后T2写入M，计算机必须将T1的写入识别为先发生，因为T2的存在依赖于T1。
- 如果这很难理解，不要担心——内存顺序可能令人费解，而语言规范往往使用非常精确但不太直观的措辞来描述它。我们可以构建一个更容易理解的心智模型，尽管有点简化，但是我们可以将重点放在底层的硬件架构上。非常基本地说，计算机内存被结构化为一个树状层次结构的存储，其中叶子节点是CPU寄存器，根节点是物理内存芯片上的存储，通常称为主内存。在两者之间有几层缓存，层次结构的不同层可以驻留在不同的硬件上。当线程对内存位置执行存储操作时，实际发生的是CPU启动了对给定CPU寄存器中的值的写入请求，然后该请求必须沿着内存层次结构向主内存传递。当线程执行加载操作时，请求沿着层次结构向上流动，直到命中具有可用值的层，然后从那里返回。问题就在这里：在所有缓存更新之前，写入不会在所有地方可见，但其他CPU可以同时对同一内存位置执行指令，这会导致奇怪的问题。因此，内存顺序是一种请求精确语义的方式，用于描述多个CPU对特定内存位置进行特定操作时发生的情况。
- 有了这个理解，让我们来看一下Ordering类型，这是我们作为程序员可以用来指定额外约束的主要机制。
- Ordering被定义为一个枚举类型，其变体如列表10-1所示。

```rust

enum Ordering {
  Relaxed,
  Release,
  Acquire,
  AcqRel,
  SeqCst
}

```
列表10-1：Ordering的定义

- 每个变体对从源代码到执行语义的映射施加了不同的限制，我们将在本节的其余部分逐个探讨每个变体。

##### 松散顺序

松散顺序实际上对于并发访问值没有提供任何保证，除了访问是原子的。特别是，松散顺序不会对不同线程之间的内存访问的相对顺序提供任何保证。这是最弱的内存顺序形式。列表10-2展示了一个简单的程序，其中两个线程使用Ordering::Relaxed访问两个原子变量。

```rust 

static X: AtomicBool = AtomicBool::new(false);
static Y: AtomicBool = AtomicBool::new(false);
let t1 = spawn(|| {
1 let r1 = Y.load(Ordering::Relaxed);
2 X.store(r1, Ordering::Relaxed);
});
let t2 = spawn(|| {
3 let r2 = X.load(Ordering::Relaxed);
4 Y.store(true, Ordering::Relaxed)
});

```
代码清单10-2：使用Ordering::Relaxed的两个竞争线程

- 查看作为t2生成的线程，您可能会期望r2永远不会为true，因为在读取X之后，直到同一线程将true分配给Y的行之后，所有值都为false。然而，使用松散的内存顺序，这种结果是完全可能的。原因是CPU允许重新排序涉及的加载和存储操作。让我们详细说明一下发生了什么，以使r2 = true成为可能。
- 首先，CPU注意到4不必在3之后发生，因为4不使用3的任何输出或副作用。也就是说，4对3没有执行依赖性。因此，CPU决定为了使程序运行更快而重新排序它们。CPU因此先执行4，将Y设置为true，即使3尚未运行。然后，操作系统将t2置于休眠状态，线程t1执行几条指令，或者t1在另一个核心上执行。在t1中，编译器确实必须先运行1，然后运行2，因为2依赖于1中读取的值。因此，t1从Y（由4写入）中读取true到r1，然后将其写回X。最后，t2执行3，读取X并得到true，就像2写入的那样。
- 松散的内存顺序允许此执行，因为它对并发执行没有额外的约束。也就是说，在松散的内存顺序下，编译器只需确保对任何给定线程的执行依赖性得到尊重（就像没有原子操作一样）；它不需要对并发操作的交错做出任何承诺。重新排序3和4在单线程执行中是允许的，因此在松散顺序下也是允许的。
- 在某些情况下，这种重新排序是可以接受的。例如，如果您有一个仅用于跟踪指标的计数器，那么它在相对于其他指令的执行时间上并不重要，Ordering::Relaxed就可以接受。在其他情况下，这可能是灾难性的：例如，如果您的程序使用r2来确定安全保护是否已经设置好，从而错误地认为它们已经设置好。
- 当编写不使用原子操作的代码时，通常不会注意到这种重新排序 - CPU必须保证代码与每个线程实际执行的代码之间没有可观察的差异，因此一切似乎都按照您编写的顺序运行。这被称为尊重程序顺序或评估顺序；这些术语是同义词。

##### Acquire/Release Ordering

在内存顺序层次结构的下一个步骤中，我们有Ordering::Acquire、Ordering::Release和Ordering::AcqRel（acquire加上release）。在高层次上，这些建立了一个存储在一个线程中和加载在另一个线程中的执行依赖关系，并限制了操作在该加载和存储之间的重新排序方式。关键是，这些依赖关系不仅建立了一个存储和加载单个值之间的关系，还对涉及的线程中的其他加载和存储施加了顺序约束。这是因为每个执行都必须尊重程序顺序；如果线程B中的加载对线程A中的某个存储有依赖关系（A中的存储必须在B中的加载之前执行），那么在该加载之后，B中的任何读取或写入也必须在A中的存储之后发生。

**注意**，Acquire内存顺序只能应用于加载操作，Release只能应用于存储操作，而AcqRel则可以应用于既加载又存储的操作（例如fetch_add）。
具体而言，这些内存顺序对执行施加了以下限制：

1. 加载和存储不能被向前移动到具有Ordering::Release的存储之后。
2. 加载和存储不能被向后移动到具有Ordering::Acquire的加载之前。
3. Ordering::Acquire加载变量必须看到在Ordering::Release存储之前发生的所有存储。

- 为了了解这些内存顺序如何改变事物，代码清单10-3再次显示了代码清单10-2，但将内存顺序更改为Acquire和Release。

```rust 

static X: AtomicBool = AtomicBool::new(false);
static Y: AtomicBool = AtomicBool::new(false);
let t1 = spawn(|| {
let r1 = Y.load(Ordering::Acquire);
X.store(r1, Ordering::Release);
});
let t2 = spawn(|| {
1 let r2 = X.load(Ordering::Acquire);
2 Y.store(true, Ordering::Release)
});
```
代码清单10-3：使用Acquire/Release内存顺序的代码清单10-2

- 这些额外的限制意味着t2不再可能看到r2 = true。要理解原因，请考虑代码清单10-2中奇怪结果的主要原因：1和2的重新排序。第一个限制，对具有Ordering::Release的存储的限制，规定我们不能将1移动到2之下，所以一切都很好！
- 但是，这些规则在这个简单示例之外也很有用。例如，想象一下你实现了一个互斥锁。你希望确保线程在持有锁时运行的任何加载和存储操作只在实际持有锁时执行，并且对于稍后获取锁的任何线程都可见。这正是Release和Acquire让你能够做到的。通过执行一个Release存储来释放锁，并执行一个Acquire加载来获取锁，你可以保证临界区中的加载和存储永远不会被移动到锁实际被获取之前或锁被释放之后！

**注意**：在某些CPU架构（如x86）上，硬件保证了Acquire/Release内存顺序，并且使用Ordering::Release和Ordering::Acquire与Ordering::Relaxed相比没有额外的成本。但在其他架构上，情况并非如此，如果将原子操作切换到Relaxed，程序可能会看到加速，因为它可以容忍较弱的内存顺序保证。

##### Sequentially Consistent Ordering

顺序一致性内存顺序（Ordering::SeqCst）是我们可以访问的最强内存顺序。它的确切保证有些难以确定，但总体上，它要求不仅每个线程都能看到与Acquire/Release一致的结果，而且所有线程都能看到彼此相同的顺序。这与Acquire和Release的行为形成对比最能体现出来。具体而言，Acquire/Release内存顺序不能保证如果两个线程A和B原子地加载由另外两个线程X和Y写入的值，A和B将以一致的模式看到X相对于Y的写入时间。这相当抽象，所以请考虑列表10-4中的示例，它展示了Acquire/Release内存顺序可能产生意外结果的情况。之后，我们将看到顺序一致性内存顺序如何避免这种特定的意外结果。

```rust 

static X: AtomicBool = AtomicBool::new(false);
static Y: AtomicBool = AtomicBool::new(false);
static Z: AtomicI32 = AtomicI32::new(0);
let t1 = spawn(|| {
X.store(true, Ordering::Release);
});
let t2 = spawn(|| {
Y.store(true, Ordering::Release);
});
let t3 = spawn(|| {
while (!X.load(Ordering::Acquire)) {}
1 if (Y.load(Ordering::Acquire)) {
Z.fetch_add(1, Ordering::Relaxed); }
});
let t4 = spawn(|| {
while (!Y.load(Ordering::Acquire)) {}
2 if (X.load(Ordering::Acquire)) {
Z.fetch_add(1, Ordering::Relaxed); }
});
```
代码清单10-4：使用Acquire/Release内存顺序的奇怪结果

- 两个线程t1和t2分别将X和Y设置为true。线程t3等待X变为true；一旦X为true，它检查Y是否为true，如果是，则将1添加到Z中。线程t4则等待Y变为true，然后检查X是否为true，如果是，则将1添加到Z中。现在的问题是：在所有线程终止后，Z可能的值是什么？在展示答案之前，请根据前一节中Release和Acquire内存顺序的定义尝试自己解决这个问题。
- 首先，让我们回顾一下Z被增加的条件。线程t3在观察到X为true后，如果观察到Y也为true，则增加Z；这只有在t2在t3评估1处的加载之前运行时才会发生。相反，线程t4在观察到Y为true后，如果观察到X也为true，则增加Z；这只有在t1在t4评估2处的加载之前运行时才会发生。为了简化解释，让我们暂时假设每个线程运行一次。
- 逻辑上，Z可以增加两次，如果线程按照顺序1、2、3、4运行 - X和Y都设置为true，然后t3和t4运行以满足它们增加Z的条件。类似地，如果线程按照顺序1、3、2、4运行，Z可以简单地增加一次。这满足了t4增加Z的条件，但不满足t3的条件。然而，让Z为0似乎是不可能的：如果我们想要阻止t3增加Z，t2必须在t3之后运行。由于t3只有在t1之后运行，这意味着t2在t1之后运行。然而，t4直到t2运行后才会运行，所以t1必须在t4运行时运行并将X设置为true，因此t4将增加Z。
- 我们无法使Z为0主要是因为我们人类倾向于线性解释的倾向；这发生了，然后发生了这个，然后发生了这个。计算机没有受到相同的限制，不需要将所有事件都放入单个全局顺序中。Release和Acquire的规则中没有任何规定，要求t3必须观察到与t1和t2相同的执行顺序，就像t4观察到的那样。对于计算机来说，让t3观察到t1先执行，而让t4观察到t2先执行是完全合理的。在这种情况下，t3观察到Y为false，这是在观察到X为true之后存储的（这意味着t2在t1之后运行），而在同一执行中，t4观察到X为false，这是在观察到Y为true之后存储的（这意味着t2在t1之前运行），这是完全合理的，即使对我们这些凡人来说似乎有些荒谬。
- 正如我们之前讨论的，Acquire/Release只要求Ordering::Acquire加载变量必须看到在Ordering::Release存储之前发生的所有存储。在刚才讨论的顺序中，计算机确实遵守了这个属性：t3看到X == true，并且确实看到t1在设置X = true之前的所有存储 - 没有存储。它还看到Y == false，这是由主线程在程序启动时存储的，因此没有相关的存储需要担心。类似地，t4看到Y = true，并且在设置Y = true之前看到了t2的所有存储 - 同样，没有存储。它还看到X == false，这是由主线程存储的，并且没有前置存储。没有违反规则，但它似乎不对。
- 我们的直觉期望是可以将线程放入某个全局顺序中，以理解每个线程所看到和执行的内容，但在这个例子中，Acquire/Release内存顺序并不是这样。为了实现更接近直觉期望的结果，我们需要顺序一致性。
顺序一致性要求参与原子操作的所有线程协调起来，以确保每个线程观察到的内容与（或至少表面上与）某个单一的共同执行顺序相对应。这样更容易进行推理，但也更昂贵。
- 使用Ordering::SeqCst标记的原子加载和存储指令指示编译器采取任何额外的预防措施（例如使用特殊的CPU指令）来保证这些加载和存储的顺序一致性。确切的形式化定义相当复杂，但顺序一致性基本上确保如果您从所有线程的相关SeqCst操作中观察，您可以将线程执行放入某个顺序中，以使加载和存储的值都能匹配上。
- 如果我们将代码清单10-4中的所有内存顺序参数替换为SeqCst，那么在所有线程退出后，Z不可能为0，就像我们最初预期的那样。在顺序一致性下，必须能够说t1肯定在t2之前运行，或者t2肯定在t1之前运行，因此不允许t3和t4看到不同的顺序，因此Z不能为0。

##### Compare and Exchange

除了load和store之外，Rust的所有原子类型都提供了一个名为compare_exchange的方法。该方法用于原子地和有条件地替换一个值。您提供compare_exchange方法的最后一个观察到的原子变量的值以及您希望用来替换原始值的新值，它只会在您最后观察到的值仍然与您观察到的值相同时才进行替换。为了理解为什么这很重要，请看一下代码清单10-5中的（错误的）互斥锁实现。该实现使用静态原子变量LOCK来跟踪锁是否被持有。我们使用布尔值true来表示锁被持有。要获取锁，线程等待LOCK为false，然后再次将其设置为true；然后它进入其临界区并在完成工作（f）后将LOCK设置为false以释放锁。

```rust 

static LOCK: AtomicBool = AtomicBool::new(false);
fn mutex(f: impl FnOnce()) {
// Wait for the lock to become free (false).
while LOCK.load(Ordering::Acquire)
{ /* .. TODO: avoid spinning .. _/ }
// Store the fact that we hold the lock.
LOCK.store(true, Ordering::Release);
// Call f while holding the lock.
f();
// Release the lock.
LOCK.store(false, Ordering::Release);
}
```
代码清单10-5：一个错误的互斥锁实现

这个实现大部分都是正确的，但是有一个严重的缺陷 - 两个线程可能同时看到LOCK == false，并且都离开while循环。然后它们都将LOCK设置为true，并且都进入了临界区，这正是mutex函数应该防止的！

代码清单10-5中的问题在于，在我们加载原子变量的当前值和随后更新它之间存在一个间隙，在此期间，另一个线程可能会运行并读取或触摸其值。正是这个问题，compare_exchange解决了 - 它只有在其值仍然与先前读取的值匹配时才交换原子变量的值，并且否则通知您该值已更改。代码清单10-6展示了使用compare_exchange进行修正的实现。

```rust

static LOCK: AtomicBool = AtomicBool::new(false);
fn mutex(f: impl FnOnce()) {
// Wait for the lock to become free (false).
loop {
let take = LOCK.compare_exchange(
false,
true,
Ordering::AcqRel,
Ordering::Relaxed
);
match take {
Ok(false) => break,
Ok(true) | Err(false) => unreachable!(),
186 Chapter 10
Err(true) => { /_ .. TODO: avoid spinning .. _/ }
}
}
// Call f while holding the lock.
f();
// Release the lock.
LOCK.store(false, Ordering::Release);
}
```
代码清单10-6：互斥锁的修正实现

- 这次我们在循环中使用compare_exchange，并通过compare_exchange的第一个和第二个参数来检查锁当前是否未被持有，并在适当的情况下存储true以获取锁。可以将调用解读为“仅在当前值为false时存储true”。compare_exchange方法返回一个Result，表示值是否成功更新（Ok）或无法更新（Err）。无论哪种情况，它都返回当前值。对于AtomicBool来说，这并不太有用，因为如果操作失败，我们知道值必须是什么，但对于AtomicI32之类的类型，更新后的当前值将让您快速重新计算要存储的值，然后无需再次加载即可尝试。

**注意** 注意，compare_exchange仅检查值是否与传入的当前值相同。如果其他线程修改了原子变量的值，然后将其重新设置为原始值，对该变量的compare_exchange仍将成功。这通常被称为A-B-A问题。

- 与简单的加载和存储不同，compare_exchange需要两个Ordering参数。第一个是“成功顺序”，它决定在值成功更新时compare_exchange所表示的加载和存储应使用的内存顺序。第二个是“失败顺序”，它决定在加载的值与预期的当前值不匹配时加载的内存顺序。这两个顺序是分开的，以便开发人员可以给CPU一些灵活性，以便在适当的情况下重新排序失败时的加载和存储，从而提高执行性能，但仍然可以在成功时获得正确的顺序。在这种情况下，可以重新排序锁获取循环的失败迭代中的加载和存储，但不能以使其超出临界区的方式重新排序加载和存储。
- 尽管其接口很简单，但compare_exchange是一个非常强大的同步原语 - 事实上，已经有理论证明，您可以仅使用compare_exchange构建所有其他分布式一致性原语！因此，当您深入研究实现细节时，它是许多同步构造的主力军。
- 但请注意，compare_exchange要求单个CPU对底层值具有独占访问权，因此它是一种硬件级别的互斥。这反过来意味着compare_exchange很快就会成为可扩展性瓶颈：一次只有一个CPU可以取得进展，因此在您的代码中有一部分不会随着核心数量的增加而扩展。实际上，情况可能比这更糟糕 - CPU必须协调以确保一次只有一个CPU对变量的compare_exchange成功（如果您对MESI协议感兴趣，请查看一下它是如何工作的），并且随着涉及的CPU越多，这种协调的成本将呈二次增长！
**COMPARE_EXCHANGE_WEAK**
仔细阅读文档的读者会注意到compare_exchange有一个名为compare_exchange_weak的可疑表亲，并想知道它们之间的区别。compare_exchange的弱变体即使原子变量的值仍然与用户传入的预期值匹配，也允许失败，而强变体在这种情况下必须成功。

- 这可能看起来很奇怪 - 除非值已更改，否则原子值交换如何失败？答案在于没有本地compare_exchange操作的系统架构。例如，ARM处理器使用锁定加载和条件存储操作，其中条件存储将失败，如果与关联的锁定加载读取的值相比，自从加载后还没有写入该值。Rust标准库通过在循环中调用这对指令来实现ARM上的compare_exchange，并且仅在条件存储成功后才返回。这使得代码清单10-6变得不必要低效 - 我们最终得到了一个嵌套循环，这需要更多的指令并且更难优化。由于我们已经在这种情况下有一个循环，我们可以使用compare_exchange_weak，删除Err(false)上的unreachable！()，并在ARM上获得更好的机器代码以及在x86上相同的编译代码！

##### 获取方法

获取方法（fetch_add、fetch_sub、fetch_and等）旨在允许更高效地执行可交换的原子操作，即无论它们以何种顺序执行，都具有有意义的语义。这样做的动机是compare_exchange方法非常强大，但也很昂贵 - 如果两个线程都想更新一个单一的原子变量，一个线程会成功，而另一个线程会失败并需要重试。如果涉及许多线程，它们都必须协调对底层值的顺序访问，并且在失败时会有大量自旋。

对于可交换的简单操作，我们可以告诉CPU在原子变量上执行什么操作，而不是因为另一个线程修改了该值而失败并重试。然后，当CPU最终获得独占访问时，它将在当前值上执行该操作。想象一个AtomicUsize，它计算一组线程完成的操作数量。如果两个线程同时完成一个作业，无论哪个线程先更新计数器，只要它们的增量都被计数即可。

获取方法实现了这些可交换操作。它们在一步中执行读取和存储操作，并保证存储操作在持有该方法返回的值时执行在原子变量上。例如，AtomicUsize::fetch_add(1, Ordering::Relaxed)永远不会失败 - 它总是将1添加到AtomicUsize的当前值中，无论它是什么，并在添加线程的1时返回AtomicUsize的值。

获取方法往往比compare_exchange更高效，因为它们不需要线程在多个线程争用访问变量时失败和重试。一些硬件架构甚至具有专门的获取方法实现，随着涉及的CPU数量增加，它们的扩展性更好。然而，如果足够多的线程尝试操作相同的原子变量，这些操作将开始变慢，并且由于所需的协调，展现出次线性的扩展性。通常，显着提高并发算法性能的最佳方法是将有争议的变量分割为更少的原子变量，每个变量都较少有争议，而不是从compare_exchange切换到获取方法。

**注意** 获取更新方法的命名有些误导性 - 在幕后，它实际上只是一个compare_exchange_weak循环，因此其性能特征更接近compare_exchange而不是其他获取方法。

#### 理智的并发

编写正确且高性能的并发代码比编写顺序代码更困难；您不仅需要考虑可能的执行交错，还需要考虑代码与编译器、CPU和内存子系统的交互。在如此多的陷阱中，很容易想要举起双手，完全放弃并发。在本节中，我们将探讨一些技术和工具，可以帮助确保您编写正确的并发代码，而不必（太多地）担心。

##### 从简单开始

事实证明，简单、直接、易于理解的代码更有可能是正确的。这个原则也适用于并发代码 - 总是从您能想到的最简单的并发设计开始，然后进行测量，只有在测量结果显示存在性能问题时，才优化您的算法。

要在实践中遵循这个提示，首先使用不需要复杂使用原子操作或大量细粒度锁的并发模式。从运行顺序代码的多个线程开始，并通过通道进行通信，或通过锁进行协作，然后使用您关心的工作负载对结果性能进行基准测试。这种方式比实现复杂的无锁算法或将锁分割成一千个片段以避免伪共享的方式更不容易出错。对于许多用例来说，这些设计已经足够快了；事实证明，为了使通道和锁性能良好，已经投入了大量的时间和精力！如果简单方法对于您的用例来说足够快，为什么要引入更复杂和容易出错的代码呢？

如果基准测试显示存在性能问题，那么确定您的系统中哪个部分扩展性较差。专注于在可能的情况下以小的调整来解决瓶颈，并尽可能地进行小的调整。也许只需将锁分成两部分而不是转向并发哈希表，或者引入另一个线程和通道而不是实现无锁的工作窃取队列。如果是这样，请这样做。

即使在直接使用原子操作等情况下，直到有明确的优化需求，也要保持简单 - 首先使用Ordering::SeqCst和compare_exchange，然后根据具体证据进行迭代，以确定它们是否成为必须处理的瓶颈。

##### 编写压力测试

作为作者，您对代码中可能隐藏的错误有很多了解，但并不一定知道这些错误是什么（至少目前还不知道）。编写压力测试是发现一些隐藏错误的好方法。压力测试不一定执行复杂的步骤，而是让许多线程并行执行相对简单的操作。
- 例如，如果您正在编写一个并发哈希映射，一个压力测试可能是让N个线程插入或更新键，M个线程读取键，以使这些M+N个线程很可能经常选择相同的键。这样的测试不测试特定的结果或值，而是尝试触发操作的许多可能交错，希望错误的交错可能会显露出来。
- 压力测试在许多方面类似于模糊测试；而模糊测试会为给定函数生成许多随机输入，压力测试则生成许多随机的线程和内存访问调度。与模糊测试器一样，压力测试只能检测到代码中的断言；它们无法告诉您不会以易于发现的方式（如断言失败或其他类型的恐慌）表现出来的错误。因此，建议在低级并发代码中添加断言，或者如果您担心特别热的循环中的运行时成本，可以使用debug_assert_。

##### 使用并发测试工具

编写并发代码的主要挑战是处理不同线程执行的所有可能交错的方式。正如我们在列表10-4中看到的Ordering::SeqCst示例，不仅线程调度很重要，还有给定线程在任何给定时间点上可能观察到的内存值。编写执行每个可能的合法执行的测试不仅繁琐而且困难 - 您需要对线程执行的时间和读取返回的值有非常低级别的控制，而操作系统可能无法提供。

##### 使用Loom进行模型检查

幸运的是，已经存在一个工具可以简化这种执行探索，即loom crate。鉴于本书和Rust crate的相对发布周期，我不会在这里给出如何使用Loom的示例，因为到您阅读本书时，它们可能已经过时了，但我会概述它的功能。

- Loom希望您编写专用的测试用例，以闭包的形式传递给Loom模型。该模型跟踪所有跨线程的交互，并尝试智能地探索这些交互的所有可能迭代，通过多次执行测试用例闭包。为了检测和控制线程交互，Loom为标准库中的所有类型提供了替代类型，这些类型允许线程彼此协调；这包括std::sync和std::thread下的大多数类型，以及UnsafeCell和其他一些类型。在运行Loom测试时，Loom期望您的应用程序使用这些替代类型。替代类型与Loom执行器相关联，并执行双重功能：它们作为重新调度点，以便Loom可以选择在每个可能的线程交互点之后运行哪个操作，并通知Loom考虑新的可能交错。实质上，Loom为每个可能的多个执行交错点构建了一棵树，然后尝试依次执行所有这些交错点。
- Loom尝试完全探索您提供的测试用例的所有可能执行，这意味着它可以发现仅在极少数执行中出现的错误，这些错误在压力测试中可能需要一百年才能发现。虽然对于较小的测试用例来说很好，但通常不可行将这种严格的测试应用于更大的测试用例，这些测试用例测试更复杂的操作序列或需要同时运行多个线程。Loom将花费太长时间来获得代码的良好覆盖率。因此，您可能希望告诉Loom仅考虑可能执行的子集，Loom的文档中有更多详细信息。
- 与压力测试类似，Loom只能捕获作为panic表现出来的错误，因此这是在并发代码中放置一些断言的又一个原因！在许多情况下，甚至值得为并发代码添加额外的状态跟踪和簿记指令，以提供更好的断言。

##### 使用ThreadSanitizer进行运行时检查

对于较大的测试用例，您最好通过Google出色的ThreadSanitizer（也称为TSan）运行测试几次。TSan通过在每个内存访问之前放置额外的簿记指令来自动增强您的代码。然后，当您的代码运行时，这些簿记指令会更新和检查一个特殊的状态机，标记任何指示存在问题的竞争内存操作。例如，如果线程B写入某个原子值X，但未与写入X的先前值的线程同步（这里有很多手势），则表示存在写/写竞争，这几乎总是一个bug。

- 由于TSan只观察您的代码运行而不像Loom一样反复执行它，它通常只会为程序的运行时添加一个恒定的因子开销。尽管这个因子可能很大（在撰写本文时为5-15倍），但它仍然足够小，以便您可以在合理的时间内执行即使是最复杂的测试用例。
- 在撰写本文时，要使用TSan，您需要使用Rust编译器的nightly版本，并传入-Zsanitizer=thread命令行参数（或在RUSTFLAGS中设置），但希望以后这将成为一个标准支持的选项。还提供了其他检查器，例如检查越界内存访问、使用后释放、内存泄漏和读取未初始化内存的检查器，您可能还希望将并发测试套件运行通过这些检查器！

**海森堡Bug**
海森堡Bug是在尝试研究它们时似乎消失的Bug。在尝试调试高度并发的代码时，这种情况经常发生；用于调试问题的附加工具会改变并发事件的相对时序，并可能导致触发Bug的执行交错不再发生。

- 造成并发Bug消失的一个特别常见原因是使用打印语句，这是最常见的调试技术之一。打印语句对并发Bug产生如此大的影响有两个原因。首先，相对而言，向用户的终端（或标准输出指向的位置）打印某些内容需要相当长的时间，特别是如果您的程序产生大量输出。写入终端至少需要一个往返到操作系统内核来执行写入，但写入可能还必须等待终端自己从进程的输出中读取到自己的缓冲区中。所有这些额外的时间可能会延迟操作，以至于先前与其他线程中的操作竞争的操作的竞争条件消失。
- 第二个原因是打印到标准输出（通常）受到锁的保护。如果您查看标准库中的Stdout类型，您会看到它持有一个Mutex，用于保护对输出流的访问。它这样做是为了防止多个线程同时写入时输出混乱 - 没有锁定，给定行可能会有来自多个线程写入的字符，但使用锁定，线程将轮流写入。不幸的是，获取输出锁是另一个线程同步点，每个打印线程都会参与其中。这意味着如果您的代码之前由于两个线程之间缺少同步而损坏，或者仅仅因为两个线程之间的特定竞争是可能的，添加打印语句可能会作为副作用修复该Bug！
- 通常情况下，当您发现似乎是海森堡Bug时，尝试找到其他缩小问题的方法。这可能涉及使用Loom或TSan，使用gdb或lldb，或者使用仅在最后打印的每个线程的内存中的日志。许多日志框架也会努力避免在发出日志事件的关键路径上进行同步点，因此切换到其中之一可能会使您的生活更轻松。作为额外的奖励，修复特定Bug后留下的良好日志可能会在以后派上用场。我个人非常喜欢tracing crate，但市场上有很多好的选择。

#### 总结

在本章中，我们首先介绍了并发Rust中常见的正确性和性能陷阱，以及成功的并发应用程序倾向于使用的一些高级并发模式来解决这些陷阱。我们还探讨了异步Rust如何在没有并行性的情况下实现并发，以及如何在异步Rust代码中显式引入并行性。然后，我们深入探讨了Rust的许多不同的低级并发原语，包括它们的工作原理、差异和用途。最后，我们探讨了编写更好的并发代码的技术，并介绍了像Loom和TSan这样的工具，可以帮助您验证该代码。在下一章中，我们将继续深入研究Rust的低级别，通过深入研究外部函数接口，允许Rust代码直接链接到其他语言编写的代码。

### 11.FOREIGN FUNCTION INTERFACES

并不是所有的代码都是用Rust编写的。我知道这很令人震惊。偶尔，您需要与其他语言编写的代码进行交互，无论是从Rust调用该代码，还是允许该代码调用您的Rust代码。您可以通过外部函数接口（FFI）实现这一点。

#### 编译和链接的一些说明

编译器速成课时间！了解将代码转换为可运行二进制文件的复杂过程的大致概念将有助于您更好地理解外部函数接口（FFI）。您知道，编译器不是一个单一的程序，而是（通常）被分解为几个较小的程序，每个程序执行不同的任务，并按顺序运行。从高层次来看，编译有三个不同的阶段 - 编译、代码生成和链接，由三个不同的组件处理。

- 第一阶段由大多数人倾向于认为是“编译器”的部分执行，它处理类型检查、借用检查、单态化和其他与给定编程语言相关的功能。该阶段不生成机器代码，而是生成使用大量注释的抽象机器操作的代码的低级表示。然后，将该低级表示传递给代码生成工具，该工具生成实际可在给定CPU上运行的机器代码。
- 这两个操作合在一起，不必一次性对整个代码库进行大规模处理。相反，代码库可以切分为较小的块，然后并行地通过编译。例如，只要它们之间没有依赖关系，Rust通常会独立并行地编译不同的crate。它还可以

##### 使用extern跨界

外部函数接口（FFI）最终都是关于访问源自应用程序Rust代码之外的字节。为此，Rust提供了两个主要的构建块：符号和调用约定。符号是分配给二进制文件中特定地址的名称，允许您在外部源和Rust代码之间共享内存（无论是用于数据还是代码），而调用约定提供了对如何调用存储在共享内存中的函数的共同理解。我们将依次查看每个构建块。

##### 符号

编译器从您的代码生成的任何二进制文件都充满了符号 - 您定义的每个函数或静态变量都有一个指向其在编译二进制文件中位置的符号。通用函数甚至可能有多个符号，每个函数的单态化都会生成一个符号！

- 通常情况下，您不必考虑符号 - 它们由编译器在二进制文件中传递函数或静态变量的最终地址时内部使用。这是编译器在生成最终机器代码时知道每个函数调用应该定位到内存中的哪个位置，或者如果您的代码访问静态变量，则从何处读取的方式。由于您通常不直接在代码中引用符号，编译器默认为它们选择半随机的名称 - 您的代码中可能有两个名为foo的函数，但编译器将为它们生成不同的符号，以避免混淆。

- 但是，当您想要调用一个不同时编译的函数或访问静态变量时，使用随机名称的符号是行不通的，例如使用不同语言编写的代码，因此由不同的编译器编译。如果变量的符号具有不断变化的半随机名称，您无法告诉Rust有关在C中定义的静态变量。同样，如果您无法为Rust函数生成稳定的名称，也无法告诉Python的FFI接口有关Rust函数。

- 要使用具有外部来源的符号，我们还需要一种方法以某种方式告诉Rust有关变量或函数，以便编译器将在其他地方查找相同的符号，而不是定义自己的符号（我们稍后将讨论搜索方式）。否则，我们将得到两个相同的函数或静态变量的符号，并且不会发生共享。实际上，很可能编译会失败，因为引用该符号的任何代码都不知道要使用哪个定义（即哪个地址）！

##### 注意

关于术语的一个快速说明：符号可以声明多次，但只能定义一次。每个符号的每个声明在链接时都将链接到相同的单个定义。如果找不到声明的定义，或者存在多个定义，则链接器将报错。

##### An Aside on Compilation and Linking

编译器速成课时间！对将代码转换为可运行二进制文件的复杂过程有一个大致的了解将有助于您更好地理解外部函数接口（FFI）。您知道，编译器不是一个单一的程序，而是（通常）被分解为几个较小的程序，每个程序执行不同的任务，并按顺序运行。从高层次来看，编译有三个不同的阶段 - 编译、代码生成和链接，由三个不同的组件处理。

- 第一阶段由大多数人倾向于认为是“编译器”的部分执行，它处理类型检查、借用检查、单态化和其他与给定编程语言相关的功能。该阶段不生成机器代码，而是生成使用大量注释的抽象机器操作的代码的低级表示。然后，将该低级表示传递给代码生成工具，该工具生成实际可在给定CPU上运行的机器代码。
- 这两个操作合在一起，不必一次性对整个代码库进行大规模处理。相反，代码库可以切分为较小的块，然后并行地通过编译。例如，只要它们之间没有依赖关系，Rust通常会独立并行地编译不同的crate。它还可以单独调用代码生成工具以并行处理独立的crate。甚至在一个crate的多个较小的切片中，Rust通常也可以分别编译！
- 一旦生成了应用程序的每个部分的机器代码，这些部分就可以被连接在一起。这是通过链接阶段由链接器完成的，不出所料。链接器的主要工作是将代码生成产生的所有二进制文件（称为目标文件）连接在一起，然后将对符号的每个引用替换为该符号的最终内存地址。这就是您可以在一个crate中定义一个函数并从另一个crate中调用它，但仍然可以单独编译这两个crate的方式。
- 链接器使FFI能够工作。它不关心每个输入目标文件是如何构建的；它只是忠实地将所有目标文件链接在一起，然后解析任何共享符号。一个目标文件可能最初是Rust代码，一个可能是C代码，一个可能是从互联网下载的二进制blob；只要它们都使用相同的符号名称，链接器就会确保生成的机器代码使用任何共享符号的正确交叉引用地址。
- 符号可以静态链接或动态链接。静态链接是最简单的，因为对符号的每个引用只是被该符号的定义的地址替换。另一方面，动态链接将每个对符号的引用与一段生成的代码相关联，该代码在程序运行时尝试找到符号的定义。稍后我们将更详细地讨论这些链接模式。Rust通常默认为Rust代码使用静态链接，而对于FFI使用动态链接。

##### Using extern

extern关键字是允许我们将符号声明为存在于外部接口中的机制。具体来说，它声明了一个在其他地方定义的符号的存在。在列表11-1中，我们在Rust中定义了一个名为RS_DEBUG的静态变量，通过FFI使其可供其他代码使用。我们还声明了一个名为FOREIGN_DEBUG的静态变量，其定义未指定，但将在链接时解析。

```rust
# [no_mangle]

pub static RS_DEBUG: bool = true;
extern {
static FOREIGN_DEBUG: bool;
}
```

代码清单11-1：通过FFI公开Rust静态变量，并访问其他地方声明的变量

- #[no_mangle]属性确保RS_DEBUG在编译过程中保留该名称，而不是由编译器分配另一个符号名称，例如用于区分程序中其他（非FFI）RS_DEBUG静态变量的名称。由于它是crate的公共API的一部分，变量也被声明为pub，尽管在标记为#[no_mangle]的项上，这个注解不是严格必需的。请注意，我们不使用extern来定义RS_DEBUG，因为它在这里被定义。它仍然可以从其他语言中链接访问。
- 包围FOREIGN_DEBUG静态变量的extern块表示此声明是指向Rust将在链接时根据相同符号的定义所在位置学习的位置。由于它在其他地方定义，我们不给它一个初始化值，只给它一个类型，该类型应与定义处使用的类型匹配。因为Rust对定义静态变量的代码一无所知，因此无法检查您是否为符号声明了正确的类型，因此FOREIGN_DEBUG只能在unsafe块内访问。

**注意** Rust中的静态变量默认情况下是不可变的，无论它们是否在extern块中。这些变量始终可以从任何线程中访问，因此可变访问会带来数据竞争的风险。您可以将静态变量声明为mut，但如果这样做，访问它将变得不安全。

- 声明FFI函数的过程非常相似。在代码清单11-2中，我们使hello_rust对非Rust代码可访问，并引入外部的hello_foreign函数。

```rust
# [no_mangle]
pub extern fn hello_rust(i: i32) { ... }
extern {
fn hello_foreign(i: i32);
}
```

代码清单11-2：通过FFI公开Rust函数，并通过FFI访问其他地方定义的函数

- 构建块与代码清单11-1中的相同，唯一的区别是Rust函数使用extern fn声明，我们将在下一节中探讨。
- 如果存在给定外部符号（如FOREIGN_DEBUG或hello_foreign）的多个定义，您可以使用#[link]属性显式指定该符号应链接到的库。如果不这样做，链接器将报错，表示找到了该符号的多个定义。例如，如果在extern块前面加上#[link(name = "crypto")]，则表示告诉链接器将任何符号（无论是静态变量还是函数）与名为"crypto"的链接库解析。您还可以通过在Rust代码中注释其声明来重命名外部静态变量或函数，使用#[link_name = "<actual_symbol_name>"]，然后该项将链接到您希望的任何名称。类似地，您可以使用#[export_name = "<export_symbol_name>"]重命名要导出的Rust项。

#### 链接类型

`#[link]`还接受kind参数，它指定了块中的项应如何链接。参数默认为"dylib"，表示与C兼容的动态链接。另一种kind值是"static"，它表示块中的项应在编译时完全链接（即静态链接）。这实际上意味着外部代码直接嵌入到编译器生成的二进制文件中，因此不需要在运行时存在。还有其他几种类型，但它们较少见，超出了本书的范围。

- 静态链接和动态链接之间存在几个权衡。主要考虑因素是安全性、二进制文件大小和分发。首先，动态链接往往更安全，因为它使得独立升级库更容易。动态链接允许在包含您的代码的二进制文件上升级您的代码链接的库，而无需重新编译您的代码。例如，如果libcrypto获得了安全更新，用户可以在主机上更新crypto库并重新启动二进制文件，更新的库代码将自动使用。使用静态编译，库的代码被硬编码到二进制文件中，因此用户必须使用升级版本的库重新编译您的代码才能获得更新。
- 动态链接还倾向于生成较小的二进制文件。由于静态编译将任何链接的代码包含到最终的二进制输出中，并且该代码进一步引入的任何代码，因此会产生较大的二进制文件。使用动态链接，每个外部项只包含一个小的包装代码，该代码在运行时加载指定的库，然后转发访问。
- 到目前为止，静态链接可能看起来并不那么吸引人，但它在分发方面有一个巨大的优势：易于分发。使用动态链接，任何想要运行包含您的代码的二进制文件的人也必须拥有您的代码链接的任何库。不仅如此，他们还必须确保他们拥有的每个库的版本与您的代码所期望的兼容。这对于像glibc或OpenSSL这样在大多数系统上都可用的库来说可能没问题，但对于更不常见的库来说，这是一个问题。然后，用户需要知道他们应该安装该库，并且必须寻找它以便运行您的代码！使用静态链接，库的代码直接嵌入到二进制输出中，因此用户不需要自己安装它。
- 最终，静态链接和动态链接之间没有正确的选择。动态链接通常是一个很好的默认选择，但对于特别受限的部署环境或非常小型或利基的库依赖项，静态编译可能是更好的选择。请根据实际情况做出判断！

##### Calling Conventions

符号决定了函数或变量的定义位置，但这还不足以允许跨FFI边界进行函数调用。为了调用任何语言中的外部函数，编译器还需要知道其调用约定，该约定规定了用于调用函数的汇编代码。我们不会在这里详细介绍每个调用约定的技术细节，但作为一般概述，调用约定规定了：

- 如何设置调用的堆栈帧
- 如何传递参数（是在堆栈上还是在寄存器中，按顺序还是按相反顺序）
- 函数返回时如何告诉函数跳回到哪里
- 在函数完成后，如何在调用者中恢复各种CPU状态，如寄存器

Rust有自己独特的调用约定，它不是标准化的，并且允许编译器随时间改变。只要所有函数定义和调用都由同一个Rust编译器编译，这是可以的，但如果您希望与外部代码进行互操作，这将是一个问题，因为外部代码不知道Rust的调用约定。
如果您没有声明其他内容，每个Rust函数都会隐式地声明为extern "Rust"。在列表11-2中，使用extern关键字本身是extern "C"的简写，意思是“使用标准的C调用约定”。之所以有这个简写，是因为在几乎所有的FFI情况下，您都希望使用C调用约定。

**注意** 展开通常只适用于常规的Rust函数。如果您在不是extern "Rust"的Rust函数的末尾展开，您的程序将中止。在FFI边界上展开到外部代码是未定义行为。通过RFC 2945，Rust获得了一个新的extern声明，extern "C-unwind"；这允许在特定情况下跨FFI边界展开，但如果您希望使用它，应该仔细阅读RFC。

Rust还支持许多其他调用约定，您可以在extern关键字后面提供一个字符串来指定。例如，extern "system"表示使用操作系统标准库接口的调用约定，目前与"C"相同，除了Win32使用"stdcall"调用约定。通常情况下，除非您使用特定于平台或高度优化的外部接口，否则很少需要显式提供调用约定，所以只使用extern（即extern "C"）就可以了。

**注意** 函数的调用约定是其类型的一部分。也就是说，类型extern "C" fn()与fn()（或extern "Rust" fn()）不同，而extern "system" fn()又与它们不同。

**其他二进制文件**
通常情况下，您只需编译Rust代码以运行其测试或构建要分发或运行的二进制文件。与许多其他语言不同，您通常不会编译Rust库以分发给其他人 - 如果运行类似cargo publish的命令，它只会将您的crate源代码打包并上传到crates.io。这主要是因为将通用代码分发为源代码以外的任何形式都很困难。由于编译器将每个泛型函数单态化为提供的类型参数，并且这些类型可能在调用者的crate中定义，因此编译器必须访问函数的泛型形式，这意味着没有优化的机器代码！

- 严格来说，Rust确实会编译二进制库文件，称为rlibs，它们包含了解析泛型类型所需的信息，但它们特定于使用的确切编译器，并且通常无法以有意义的方式分发。
- 那么，如果您想在Rust中编写一个库，然后希望从另一种编程语言中进行接口调用，该怎么办呢？解决方案是生成与C兼容的库文件，形式为动态链接库（Unix上的.so文件，macOS上的.dylib文件，Windows上的.dll文件）和静态链接库（Unix/macOS上的.a文件，Windows上的.lib文件）。这些文件看起来像由C代码生成的文件，因此也可以被其他知道如何与C交互的语言使用。
- 要生成这些与C兼容的二进制文件，您需要在Cargo.toml文件的[lib]部分的crate-type字段中设置值。该字段接受一个值数组，通常只是"lib"，表示标准的Rust库（一个rlib）。如果您的crate显然不是库（例如，如果它是一个过程宏），Cargo会自动应用一些启发式规则来设置该值，但最佳实践是如果您生成的不是一个传统的Rust库，则显式设置该值。
- 这里有许多不同的crate类型，但这里相关的是"cdylib"和"staticlib"，它们分别生成动态链接和静态链接的与C兼容的库文件。请记住，当您生成这些二进制文件类型之一时，只有公开可用的符号可用 - 即公共和#[no_mangle]静态变量和函数。诸如类型和常量之类的东西将不可用，即使它们被标记为pub，因为它们在二进制库文件中没有有意义的表示形式。

#### 跨语言边界的类型

在使用FFI时，类型布局非常重要；如果一种语言以某种方式布局共享数据，而FFI边界的另一侧的语言期望以不同的方式布局，那么两侧将以不一致的方式解释数据。在本节中，我们将看看如何使类型在FFI上匹配，并在跨语言边界时要注意的其他类型方面。

##### 类型匹配

类型不会在FFI边界上共享。当您在Rust中声明一个类型时，该类型信息在编译时完全丢失。在另一侧传递的只是构成该类型值的位。
因此，您需要在边界的两侧都声明该位的类型。当您声明类型的Rust版本时，首先必须确保类型中包含的基本类型匹配。例如，如果在边界的另一侧使用C，并且C类型使用int，那么Rust代码最好使用完全相同的Rust等效类型：i32。为了简化这个过程，对于使用类似C类型的接口，Rust标准库为您提供了正确的C类型，位于std::os::raw模块中，其中定义了类型c_int = i32，类型c_char = i8/u8（取决于char是否有符号），类型c_long = i32/i64（取决于目标指针宽度），等等。

**注意** 特别注意C中奇怪的整数类型，如__be32。这些类型通常不能直接转换为Rust类型，最好将其保留为类似[u8; 4]的形式。例如，__be32始终以大端字节序编码，而Rust的i32使用当前平台的字节序。

- 对于更复杂的类型，如向量和字符串，通常需要手动进行映射。例如，由于C倾向于将字符串表示为以0字节结尾的字节序列，而不是使用单独存储长度的UTF-8编码字符串，通常不能在FFI上使用Rust的字符串类型。相反，假设另一侧使用C风格的字符串表示，您应该使用std::ffi::CStr和std::ffi::CString类型分别用于借用和拥有的字符串。对于向量，您可能需要使用指向第一个元素的原始指针，然后单独传递长度 - 对于这一点，Vec::into_raw_parts方法可能会很有用。
- 对于包含其他类型的类型，例如结构体和联合体，您还需要处理布局和对齐方式。正如我们在第2章中讨论的那样，Rust默认以未定义的方式布局类型，因此至少您将希望使用#[repr(C)]来确保该类型具有确定的布局和与FFI边界上使用的布局和对齐方式相对应的对齐方式（可能和希望）。如果接口还为该类型指定了其他配置，例如手动设置其对齐方式或删除填充，您将需要相应地调整#[repr]。
- Rust枚举类型具有多种可能的C风格表示，具体取决于枚举是否包含数据。考虑一个没有数据的枚举，如下所示：

```rust
enum Foo { Bar, Baz }
```

- 使用#[repr(C)]，类型Foo使用与C编译器为具有相同数量变体的枚举选择的大小相同的单个整数进行编码。第一个变体的值为0，第二个变体的值为1，依此类推。您还可以手动为每个变体分配值，如清单11-3所示。

```rust
# [repr(C)]
enum Foo {
  Bar = 1,
  Baz = 2,
}
```

代码清单11-3：为无数据的枚举定义显式的变体值
**注意** 从技术上讲，规范指定第一个变体的值为0，每个后续变体的值比前一个变体的值大1。如果您为某些变体手动设置了值但没有为其他变体设置值，这将产生差异 - 没有设置的变体将从您最后设置的变体继续。

- 但是，您应该小心将C中的类似枚举类型映射到Rust中，因为只有定义的变体的值对于枚举类型的实例是有效的。这在处理C风格的枚举时往往会遇到问题，因为它们通常更像是位集，其中变体可以按位OR在一起以产生封装多个变体的值。例如，在代码清单11-3中，通过取Bar | Baz生成的值为3在Rust中是无效的！如果您需要模拟使用枚举表示一组可以单独设置和取消设置的位标志的C API，请考虑使用围绕整数类型的新类型包装器，并为每个变体提供关联常量以及各种Bit*特性的实现以提高人性化。或者使用bitflags crate。
**注意** 对于无字段的枚举，您还可以将数字类型传递给#[repr]，以使用与isize不同的类型。例如，#[repr(u8)]将使用单个无符号字节编码鉴别器。对于带有数据的枚举，您可以传递`# [repr(C, u8)]`以获得相同的效果。
- 对于包含数据的枚举，#[repr(C)]属性会导致枚举使用标记联合表示。也就是说，它在内存中由一个#[repr(C)]结构体表示，该结构体有两个字段，第一个字段是鉴别器，如果没有变体具有字段，则编码方式与之相同，第二个字段是每个变体的数据结构的联合体。具体示例，请参见代码清单11-4中的枚举和相关表示。

```rust
# [repr(C)]

enum Foo {
Bar(i32),
Baz { a: bool, b: f64 }
}
// is represented as

# [repr(C)]

enum FooTag { Bar, Baz }

# [repr(C)]

struct FooBar(i32);

# [repr(C)]

struct FooBaz{ a: bool, b: f64 }

# [repr(C)]

union FooData {
bar: FooBar,
baz: FooBaz,
}

# [repr(C)]

struct Foo {
tag: FooTag,
data: FooData
}

```

代码清单11-4：使用#[repr(C)]的Rust枚举表示为标记联合。

**FFI中的特殊优化**
在第9章中，我们讨论了特殊优化，即Rust编译器使用无效的位模式来表示不包含数据的枚举变体。这种优化的保证意味着它与FFI之间有一个有趣的交互。具体来说，这意味着可以始终使用Option包装的指针类型在FFI类型中表示可空指针。例如，可空函数指针可以表示为Option<extern fn(...)>, 可空数据指针可以表示为Option<*mut T>。如果提供了全零位模式值，它们将自动执行正确的操作，并在Rust中表示为None。

##### 分配

当您分配内存时，该分配属于其分配器，并且只能由该相同的分配器释放。这适用于在Rust中使用多个分配器的情况，也适用于在Rust和FFI边界的另一侧使用某个分配器进行内存分配的情况。您可以自由地将指针发送到边界并访问该内存，但是当涉及释放内存时，它需要返回给适当的分配器。

- 大多数FFI接口将具有两种处理分配的配置：要么调用方提供数据指针以指向内存块，要么接口公开专用的释放方法，应将任何分配的资源在不再需要时返回给这些方法。代码清单11-5显示了一些来自OpenSSL库的签名的Rust声明示例，这些签名使用实现管理的内存。

```rust
// One function allocates memory for a new object.
extern fn ECDSA_SIG_new() -> *mut ECDSA_SIG;
// And another accepts a pointer created by new
// and deallocates it when the caller is done with it.
extern fn ECDSA_SIG_free(sig:*mut ECDSA_SIG);

```

代码清单11-5：实现管理的内存接口

- 函数ECDSA_SIG_new和ECDSA_SIG_free形成一对，调用者需要调用new函数，使用返回的指针尽可能长时间（可能通过将其依次传递给其他函数）并在完成引用的资源后将指针传递给free函数。假设实现在new函数中分配内存，并在free函数中释放它。如果这些函数在Rust中定义，new函数可能会使用Box::new，而free函数将调用Box::from_raw，然后丢弃值以运行其析构函数。
代码清单11-6显示了一个调用者管理的内存示例。

```rust
// An example of caller-managed memory.
// The caller provides a pointer to a chunk of memory,
// which the implementation then uses to instantiate its own types.
// No free function is provided, as that happens in the caller.
extern fn BIO_new_mem_buf(buf: *const c_void, len: c_int) ->*mut BIO
```

代码清单11-6：调用者管理的内存接口

- 在这里，BIO_new_mem_buf函数由调用者提供后备内存。调用者可以选择在堆上分配内存，或者使用任何其他机制来获取所需的内存，然后将其传递给库。然后，责任在于调用者确保内存在不再被FFI实现需要时进行释放！
- 您可以在您的FFI API中使用这两种方法，甚至可以混合使用它们。作为一个经验法则，如果可行的话，允许调用者传递内存，因为这样可以给调用者更多自由来管理内存。例如，调用者可能在某个自定义操作系统上使用高度专门化的分配器，并且可能不想被强制使用您的实现所使用的标准分配器。如果调用者可以传递内存，它甚至可以避免完全分配，而是使用堆栈内存或重用已分配的内存。但是，请记住，调用者管理的接口的人机工程学通常更加复杂，因为调用者现在必须做所有的工作来确定要分配多少内存，并在调用您的库之前设置它。
- 在某些情况下，调用者甚至无法预先知道要分配多少内存-例如，如果您的库的类型是不透明的（因此调用者不知道）或者可以随时间变化，调用者将无法预测分配的大小。同样，如果您的代码在运行时需要分配更多的内存，例如，如果您正在动态构建图形，则所需的内存量可能会在运行时动态变化。在这种情况下，您将不得不使用实现管理的内存。
- 当您被迫做出权衡时，对于任何大型或频繁的内容，请使用调用者分配的内存。在这些情况下，调用者很可能最关心自己控制分配。对于其他任何情况，您的代码可能会分配并公开每个相关类型的析构函数。

##### 回调函数

您可以在FFI边界上传递函数指针，并通过这些指针调用引用的函数，只要函数指针的类型具有与函数的调用约定匹配的extern注释。也就是说，您可以在Rust中定义一个extern "C" fn(c_int) -> c_int，然后将对该函数的引用作为回调传递给C代码，C代码最终会调用该回调。

- 在使用回调时，需要小心处理panic，因为在除了extern "Rust"之外的函数末尾发生panic的行为是未定义的。Rust编译器当前会在检测到这种panic时自动中止，但这可能不是您想要的行为。相反，您可能希望使用std::panic::catch_unwind在任何标记为extern的函数中检测panic，然后将panic转换为与FFI兼容的错误。

##### 安全性

当编写Rust FFI绑定时，实际与FFI进行交互的大部分代码将是不安全的，并且主要围绕原始指针展开。然而，您的目标应该是最终在FFI之上呈现一个安全的Rust接口。要做到这一点，主要是仔细阅读您正在封装的不安全接口的不变量，然后通过Rust类型系统在安全接口中确保您遵守所有这些不变量。安全封装外部接口的三个最重要的元素是准确捕获&与&mut、适当实现Send和Sync，并确保指针不能被意外混淆。接下来，我将介绍如何强制执行每个元素。

##### 引用和生命周期

如果有可能外部代码会修改给定指针后面的数据，请确保安全的Rust接口通过使用&mut来获得对相关数据的独占引用。否则，安全包装器的用户可能会意外读取外部代码同时修改的内存，这将导致灾难性后果！

- 您还应该充分利用Rust的生命周期，以确保所有指针的生命周期与FFI所需的时间一样长。例如，想象一个外部接口，它允许您创建一个Context，然后允许您从该Context创建一个Device，并要求Context在Device存在期间保持有效。在这种情况下，任何安全的接口的实现都应该通过在Device中持有与创建Device的Context相关联的借用的生命周期来强制执行该要求。

##### Send和Sync

除非外部库明确说明这些类型是线程安全的，否则不要为外部库的类型实现Send和Sync！安全的Rust封装的工作是确保安全的Rust代码不会违反外部代码的不变量，从而触发未定义的行为。

- 有时，您甚至可能希望引入虚拟类型来强制执行外部不变量。例如，假设您有一个事件循环库，其接口如代码清单11-7所示。

```rust

extern fn start_main_loop();
extern fn next_event() -> *mut Event;
```

代码清单11-7：一个期望单线程使用的库

- 现在假设外部库的文档说明只能在调用start_main_loop的同一线程中调用next_event。然而，在这里我们没有可以避免实现Send的类型！相反，我们可以借鉴第3章的方法，引入额外的标记状态来强制执行不变量，如代码清单11-8所示。

```rust
pub struct EventLoop(std::marker::PhantomData<*const ()>);
pub fn start() -> EventLoop {
  unsafe { ffi::start_main_loop() };
  EventLoop(std::marker::PhantomData)
  }
  impl EventLoop {
  pub fn next_event(&self) -> Option<Event> {
  let e = unsafe { ffi::next_event() };
  // ...
  }
}

```

代码清单11-8：通过引入辅助类型来强制执行FFI不变量

空类型EventLoop实际上与底层外部接口没有任何连接，而是强制执行在调用start_main_loop之后才能调用next_event，并且只能在同一线程上调用的约定。通过使EventLoop既不是Send也不是Sync，并持有一个幻影原始指针（它本身既不是Send也不是Sync），可以强制执行“同一线程”部分。

- 在这里，我们使用PhantomData<_const ()>来“取消”Send和Sync自动特性，这有点丑陋和间接。Rust确实有一个不稳定的编译器特性，可以启用负面特性实现，例如impl !Send for EventLoop {}，但是正确实现它非常困难，并且可能需要一些时间才能稳定下来。
- 您可能已经注意到，调用者可以多次调用start_main_loop，无论是在同一线程还是在另一个线程中。如何处理这个问题取决于所讨论的库的语义，所以我将把它作为一个练习留给您。

##### 指针混淆

在许多FFI API中，您不一定希望调用者知道您给它指针的每个内部表示。该类型可能具有调用者不应该干涉的内部状态，或者该状态可能难以以跨语言兼容的方式表示。对于这些情况，C风格的API通常会暴露void指针，以C类型void_表示，它等同于Rust中的*mut std::ffi::c_void。这样的类型擦除指针实际上只是一个指针，不传达任何关于其指向的内容的信息。因此，这些类型的指针通常被称为不透明指针。

- 不透明指针在FFI边界上实际上起到了类型的可见性修饰符的作用-由于方法签名不会说明指针指向的内容，调用者只能按原样传递指针，并使用任何可用的FFI方法来提供对所引用数据的可见性。不幸的是，由于一个*mut c_void与另一个*mut c_void是无法区分的，因此用户可以从一个FFI方法返回的不透明指针直接传递给期望指向不同不透明类型的方法。
- 在Rust中，我们可以做得更好。为了减轻这种指针类型混淆的问题，我们可以避免在FFI中直接使用_mut c_void作为不透明指针，即使实际接口需要一个void_，而是为每个不同的不透明类型构造不同的空类型。例如，在代码清单11-9中，我使用了两个不同的不透明指针类型，它们不能混淆。

```rust 
# [non_exhaustive] #[repr(transparent)] pub struct Foo(c_void)

# [non_exhaustive] #[repr(transparent)] pub struct Bar(c_void)
extern {
pub fn foo() -> *mut Foo;
pub fn take_foo(arg:*mut Foo);
pub fn take_bar(arg: *mut Bar);
}

```

清单11-9：不会混淆的不透明指针类型

- 由于Foo和Bar都是零大小的类型，它们可以在extern方法签名中替代()。更好的是，由于它们现在是不同的类型，Rust不会允许您在需要另一个类型的地方使用其中一个，因此现在不可能使用从foo获取的指针调用take_bar。添加`# [non_exhaustive]`注释确保Foo和Bar类型无法在此crate之外构造。

#### bindgen和构建脚本

对于一个较大的外部库，映射出其Rust类型和externs可能是一项相当繁琐的工作。大型库往往有足够多的类型和方法签名需要匹配，手动编写所有的Rust等价物是耗时的。此外，由于一些特殊情况和C语言的奇特之处，某些模式必然需要更加仔细地思考如何转换。

- 幸运的是，Rust社区开发了一个名为bindgen的工具，它可以极大地简化这个过程，只要你有要与之进行接口交互的C头文件。bindgen本质上将我们在本章中讨论的所有规则和最佳实践，以及其他一些规则，编码到一个可配置的代码生成器中，该生成器接受C头文件并生成相应的Rust等价物。
- bindgen提供了一个独立的二进制文件，用于生成C头文件的Rust代码，这在你想要检查绑定时非常方便。这个过程允许你手动调整生成的绑定，如果有必要的话。另一方面，如果你想在每次构建时自动生成绑定，并且只需在源代码中包含C头文件，bindgen也作为一个库提供，你可以在自定义的构建脚本中调用它。

**注意** 如果直接检入绑定，要记住它们只在生成它们的平台上才是正确的。在构建脚本中生成绑定将专门为当前目标平台生成它们，这样就不太可能引起与平台相关的布局不一致性。

- 通过在Cargo.toml的[package]部分添加build = "<some-file.rs>"，你可以声明一个构建脚本。这告诉Cargo，在编译你的crate之前，应该将<some-file.rs>作为一个独立的Rust程序进行编译和运行；然后才编译你的crate的源代码。构建脚本也有它自己的依赖项，你可以在Cargo.toml的[build-dependencies]部分声明它们。

**注意** 如果将构建脚本命名为build.rs，你不需要在Cargo.toml中声明它。

- 构建脚本在处理FFI时非常有用——它们可以从源代码编译一个捆绑的C库，动态地发现和声明要传递给编译器的额外构建标志，声明额外的文件供Cargo检查以进行重新编译，以及（你猜对了）在运行时动态生成额外的源文件！
- 虽然构建脚本非常灵活，但要小心不要让它们过于依赖运行环境。虽然你可以使用构建脚本来检测Rust编译器版本是否为质数，或者明天伊斯坦布尔是否会下雨，但是将你的编译依赖于这些条件可能会导致其他开发人员意外失败，从而导致开发体验不佳。
- 构建脚本可以将文件写入通过OUT_DIR环境变量提供的特殊目录。在Rust源代码中，编译时可以访问相同的目录和环境变量，以便可以获取构建脚本生成的文件。要从C头文件生成和使用Rust类型，首先让你的构建脚本使用bindgen库的库版本读取一个.h文件，并将其转换为一个名为bindings.rs的文件，放在OUT_DIR中。然后，在你的crate的任何Rust文件中添加以下行，以在编译时包含bindings.rs：

```rust

include!(concat!(env!("OUT_DIR"), "/bindings.rs"));
```

- 由于bindings.rs中的代码是自动生成的，通常最佳实践是将绑定放在它们自己的crate中，并将crate的名称与绑定的库相同，后缀为-sys（例如，openssl-sys）。如果不遵循此做法，发布新版本的库将变得更加痛苦，因为通过Cargo.toml中的links键链接到相同外部库的两个crate在给定的构建中无法共存。您实际上必须一次性升级整个生态系统到库的新主要版本。将绑定分离到它们自己的crate中允许您发布可以逐步采用的包装器crate的新主要版本。分离还允许您在Rust绑定发生更改时（例如，如果升级头文件本身或者bindgen升级导致生成的Rust代码略有变化），切断包装FFI绑定的crate的破坏性发布，而无需同时切断包装FFI绑定的crate的破坏性发布。

**注意**请记住，如果在主要库的公共接口中包含-sys crate的任何类型，将依赖于-sys crate的新主要版本仍然构成对主要库的破坏性更改！

- 如果您的crate生成的是供其他人通过FFI使用的库文件，则还应该发布一个C头文件，以便更容易从其他语言生成对您的库的本机绑定。然而，随着您的crate的变化，该C头文件需要保持最新，这在库规模增大时可能变得麻烦。幸运的是，Rust社区还开发了一个自动化此任务的工具：cbindgen。与bindgen一样，cbindgen是一个构建工具，它也作为二进制文件和库提供，供构建脚本使用。它不是接收C头文件并生成Rust代码，而是接收Rust代码并生成C头文件。由于C头文件代表了crate的FFI的主要可读描述，我建议手动检查它，以确保自动生成的C代码不会过于复杂，尽管通常情况下，cbindgen会生成相当合理的代码。如果不是这样，请报告错误！

**C++**
在本章中，我主要关注C，因为它是描述可以链接的跨语言接口的库最常用的语言。几乎每种编程语言都提供了与C库交互的方式，因为它们是如此普遍。虽然C++在与C相关方面感觉紧密相关，并且许多知名库都是用C++编写的，但是在FFI方面，它是一个完全不同的东西。生成与C头文件匹配的类型和签名相对简单，但对于C++来说情况完全不同。在撰写本文时，bindgen对于生成C++的绑定有相当好的支持，但在人机交互方面还有所欠缺。例如，您通常需要手动调用构造函数、析构函数、重载运算符等。一些C++特性，如模板特化，也根本不受支持。如果您必须与C++进行接口交互，我建议您尝试使用cxx crate。

#### 总结

在本章中，我们介绍了如何使用extern关键字从Rust调用外部代码，以及如何使用它使Rust代码对外部代码可访问。我们还讨论了如何将Rust类型与FFI边界的类型对齐，以及在尝试编写两种不同语言的代码时可能遇到的一些常见问题。最后，我们讨论了bindgen和cbindgen工具，它们使保持FFI绑定最新的体验更加愉快。在下一章中，我们将介绍如何在更受限制的环境中使用Rust，例如嵌入式设备，这些设备可能没有标准库，甚至可能无法进行简单的内存分配操作。

### 12 RUST WITHOUT THE STANDARD LIBRARY

Rust旨在成为一种系统编程语言，但这并不总是很清楚它到底意味着什么。至少，系统编程语言通常被期望允许程序员编写不依赖于操作系统并可以直接在硬件上运行的程序，无论是千核超级计算机还是具有单核ARM处理器、时钟速度为72MHz和256KiB内存的嵌入式设备。

- 在本章中，我们将介绍如何在非常规环境中使用Rust，例如没有操作系统的环境，或者甚至没有动态分配内存的能力的环境！我们的讨论将主要集中在#![no_std]属性上，但我们还将研究Rust的alloc模块、Rust运行时（是的，Rust实际上有一个运行时）以及在这种环境中编写Rust二进制文件时需要进行的一些技巧。

#### 退出标准库

作为一种语言，Rust由多个独立的部分组成。首先是编译器，它规定了Rust语言的语法，并实现了类型检查、借用检查和最终转换为可运行代码。然后是标准库std，它实现了大多数程序所需的有用的常见功能，例如文件和网络访问、时间概念、打印和读取用户输入等。但是std本身也是一个复合库，构建在称为core和alloc的两个更基本的库之上。实际上，std中的许多类型和函数只是从这两个库中重新导出的。

- 核心库位于标准库金字塔的底部，包含仅依赖于Rust语言本身和生成的程序运行的硬件的任何功能，例如排序算法、标记类型、Option和Result等基本类型，原子内存访问方法等低级操作以及编译器提示。核心库的工作方式就像操作系统不存在一样，因此没有标准输入、没有文件系统和没有网络。同样，没有内存分配器，因此看不到Box、Vec和HashMap等类型。
- 在核心库之上是alloc，它包含所有依赖于动态内存分配的功能，例如集合、智能指针和动态分配的字符串（String）。我们将在下一节中回到alloc。
- 大多数情况下，由于std重新导出了core和alloc中的所有内容，开发人员不需要了解这三个库之间的区别。这意味着即使Option在技术上位于core::option::Option中，您也可以通过std::option::Option访问它。
- 但是，在非常规环境中（例如没有操作系统的嵌入式设备），这种区别是至关重要的。虽然使用Iterator或对数字列表进行排序是可以的，但是嵌入式设备可能根本没有有意义的方式来访问文件（因为这需要文件系统）或打印到终端（因为这需要终端）-因此没有File或println！此外，设备的内存可能非常有限，因此动态内存分配是一种您无法承受的奢侈品，因此任何在运行时分配内存的东西都是不可行的-说再见Box和Vec。
- 与其强制开发人员在这些环境中小心避免这些基本结构，不如提供一种方法来仅使用语言的核心功能：#![no_std]属性。这是一个crate级别的属性（#!），它将crate的预导入（参见第213页上的框）从std::prelude切换到core::prelude，以便您不会意外地依赖于可能在目标环境中不起作用的core之外的任何内容。
- 但是，这就是#![no_std]属性的全部功能-它不会阻止您通过extern std显式引入标准库。这可能令人惊讶，因为这意味着标记为#![no_std]的crate实际上可能与不支持std的目标环境不兼容，但这个设计决策是有意的：它允许您将crate标记为no_std兼容，但在启用某些功能时仍然可以使用标准库的功能。例如，许多crate都有一个名为std的功能，启用该功能将可以访问更复杂的API和与std中的类型集成。这使得crate作者既可以为受限用例提供核心实现，又可以为标准平台上的消费者添加额外功能。

**注意** 由于功能应该是增量的，优先选择启用std的功能而不是禁用std的功能。否则，如果消费者的依赖图中的任何crate启用了no-std功能，所有消费者将只能访问不带std支持的基本API，这可能意味着它们依赖的API不可用，导致无法编译。

**预导入**
您是否曾经想过为什么有一些类型和特性（如Box、Iterator、Option和Clone）在每个Rust文件中都可以直接使用，而无需您使用它们？或者为什么您不需要使用标准库中的任何宏（如vec！[]）？原因是每个Rust模块都会自动导入Rust标准预导入，其中包含一个隐式的use std::prelude::rust_2021::*（或其他版本的类似内容），它将所选版本的预导入中的所有导出项引入作用域。预导入模块本身并不特殊，除了这个自动包含之外，它们只是一些关键类型、特性和宏的pub use语句的集合，Rust开发人员希望它们被广泛使用。

#### 动态内存分配

正如我们在第1章中讨论的那样，计算机有许多不同的内存区域，每个区域都有不同的用途。有用于程序代码和静态变量的静态内存，有用于函数局部变量和函数参数的栈，还有用于其他所有内容的堆。堆支持在运行时分配可变大小的内存区域，并且这些分配可以保持多长时间。这使得堆内存非常灵活，因此您可以在各个地方找到它的使用。Vec、String、Arc和Rc以及集合类型都是在堆内存中实现的，这使它们可以随时间的推移增长和缩小，并且可以从函数中返回而不会引发借用检查器的投诉。

- 在幕后，堆实际上只是一个由分配器管理的巨大的连续内存块。分配器提供了堆中不同分配的幻觉，确保这些分配不重叠，并且不再使用的内存区域被重新使用。默认情况下，Rust使用系统分配器，通常是由标准C库指定的分配器。这对大多数用例都很有效，但如果需要，您可以通过GlobalAlloc trait与#[global_allocator]属性覆盖Rust将使用的分配器，后者需要实现用于分配新内存段的alloc方法和用于返回以前的分配以供分配器重用的dealloc方法。
- 在没有操作系统的环境中，通常也无法使用标准C库，因此也无法使用标准系统分配器。因此，#![no_std]还排除了所有依赖于动态内存分配的类型。但是，由于完全可以在没有完整操作系统的情况下实现内存分配器，Rust允许您重新选择仅需要分配器的Rust标准库的部分功能，而无需选择整个std，通过alloc crate。alloc crate与标准Rust工具链一起提供（就像core和std一样），其中包含大多数您喜欢的堆分配类型，如Box、Arc、String、Vec和BTreeMap。HashMap不在其中，因为它依赖于用于键哈希的随机数生成，这是操作系统的功能。要在no_std上下文中使用alloc中的类型，您只需将以前使用use std::导入的那些类型的导入替换为use alloc::即可。但请记住，依赖于alloc意味着您的#![no_std] crate将不再可用于任何禁止动态内存分配的程序，无论是因为它没有分配器还是因为它的内存太少以至于无法进行动态内存分配。

**注意** 某些编程领域（如Linux内核）可能仅在优雅处理内存不足错误（即不引发panic）的情况下允许动态内存分配。对于这种用例，您将希望为您公开的任何可能分配的方法提供try_版本。try_方法应使用任何内部类型的可失败方法（如当前不稳定的Box::try_new或Vec::try_reserve），而不是仅仅引发错误的方法（如Box::new或Vec::reserve），并将这些错误传播给调用者，然后可以适当地处理它们。

- 可能会让您感到奇怪的是，可以编写仅使用core的非平凡crate。毕竟，它们不能使用集合、String类型、网络或文件系统，甚至没有时间的概念！核心只有的技巧是利用堆栈和静态分配。例如，对于一个无堆的向量，您可以预先分配足够的内存-无论是在静态内存中还是在函数的堆栈帧中-以容纳您预计向量能够容纳的最大元素数量，然后使用一个usize来跟踪它当前容纳的元素数量。要将元素推入向量中，您可以写入（静态大小的）数组中的下一个元素，并递增一个变量来跟踪元素的数量。如果向量的长度达到静态大小，下一个推入操作将失败。清单12-1给出了使用const泛型实现的此类无堆向量类型的示例。

```rust
struct ArrayVec<T, const N: usize> {
  values: [Option<T>; N],
  len: usize,
}
impl<T, const N: usize> ArrayVec<T, N> {
  fn try_push(&mut self, t: T) -> Result<(), T> {
  if self.len == N {
    return Err(t);
  }
  self.values[self.len] = Some(t);
    self.len += 1;
    return Ok(());
  }
}
```

清单12-1：一个无堆向量类型

- 我们使ArrayVec对其元素的类型T和最大元素数量N进行泛型化，然后将向量表示为N个可选的T数组。这个结构总是存储N个Option<T>，因此它在编译时具有已知的大小，并且可以存储在堆栈上，但是它仍然可以像向量一样使用运行时信息来确定如何访问数组。

**注意** 我们可以使用[MaybeUninit<T>; N]来实现ArrayVec，以避免Option的开销，但这将需要使用不安全的代码，这在这个示例中是不合适的。

#### The Rust Runtime

你可能听说过Rust没有运行时的说法。虽然从高层次来看这是正确的——它没有垃圾回收器、解释器或内置的用户级调度器——但在严格意义上来说，这并不完全正确。具体而言，Rust确实有一些特殊的代码在你的main函数之前运行，并在你的代码中的某些特殊条件下响应，这实际上是一种简化版的运行时。

##### The Panic Handler

这段特殊代码的第一部分是Rust的panic处理程序。当Rust代码通过调用panic!或panic_any而发生panic时，panic处理程序决定接下来会发生什么。当Rust运行时可用时（大多数提供std的目标都是如此），panic处理程序首先调用通过std::panic::set_hook设置的panic钩子，默认情况下将消息和可选的回溯打印到标准错误流。然后，根据当前编译的panic设置（通过Cargo配置或直接传递给rustc的参数）选择是展开当前线程的堆栈还是终止进程。

- 然而，并非所有目标平台都提供panic处理程序。例如，大多数嵌入式目标平台并不提供，因为在这样的目标平台上，并没有一个单一的实现在所有用途上都是合理的。对于不提供panic处理程序的目标平台，Rust仍然需要知道在发生panic时应该做什么。为此，我们可以使用#[panic_handler]属性来修饰程序中的一个具有fn(&PanicInfo) -> !签名的函数。该函数在程序调用panic时被调用，并以core::panic::PanicInfo的形式传递有关panic的信息。函数对这些信息的处理方式完全未指定，但它永远不能返回（由!返回类型表示）。这一点很重要，因为Rust编译器假设在panic之后不会运行任何代码。
- panic处理程序有许多有效的避免返回的方式。标准的panic处理程序会展开线程的堆栈，然后终止线程，但是panic处理程序也可以使用loop {}来停止线程，中止程序，或者执行对目标平台有意义的任何其他操作，甚至可以重置设备。

##### Program Initialization

与普遍的观念相反，main函数并不是Rust程序中第一个运行的东西。实际上，Rust二进制文件中的main符号实际上指向标准库中的一个名为lang_start的函数。该函数执行Rust运行时的（相当简单的）设置，包括将程序的命令行参数存储在std::env::args可以访问的位置，设置主线程的名称，处理main函数中的panic，程序退出时刷新标准输出，并设置信号处理程序。lang_start函数然后调用在crate中定义的main函数，这样main函数就不需要考虑例如Windows和Linux在如何传递命令行参数方面的差异。

- 这种安排在所有这些设置都是合理且受支持的平台上运行良好，但在嵌入式平台上却存在问题，因为当程序启动时，主内存可能甚至无法访问。在这种情况下，您通常会选择使用#![no_main] crate级别的属性完全排除Rust初始化代码。这个属性完全省略了lang_start，这意味着作为开发人员，您必须弄清楚程序应该如何启动，例如通过声明一个与目标平台的预期启动序列匹配的#[export_name = "main"]函数。

**注意** 在真正没有代码运行之前就跳转到定义的起始符号的平台上（如大多数嵌入式设备），静态变量的初始值甚至可能与源代码中指定的不匹配。在这种情况下，您的初始化函数将需要显式地使用程序二进制文件中指定的初始数据值初始化各个静态内存段。

##### The Out-of-Memory Handler

如果您编写的程序希望使用alloc，但构建的平台没有提供分配器，您必须使用本章前面提到的#[global_allocator]属性来指定要使用的分配器。但是，您还必须指定如果全局分配器无法分配内存时应该发生什么。具体而言，您需要定义一个内存不足处理程序，以指定如果一个不可失败的操作（如Vec::push）需要分配更多内存，但分配器无法提供时应该发生什么。

- 在启用std的平台上，内存不足处理程序的默认行为是将错误消息打印到标准错误流，然后终止进程。然而，在例如没有标准错误的平台上，这显然行不通。在撰写本文时，在这些平台上，您的程序必须使用不稳定的属性#[lang = "oom"]显式定义一个内存不足处理程序。请记住，处理程序几乎肯定应该阻止未来的执行，否则尝试分配的代码将继续执行，而不知道它没有获得所请求的内存！

**注意** 在您阅读本文时，内存不足处理程序可能已经以永久名称（最有可能是#[alloc_error_handler]）稳定下来。还正在进行工作，以赋予默认的std内存不足处理程序与Rust的panic处理程序相同类型的“钩子”功能，以便代码可以通过类似set_alloc_error_hook的方法在运行时更改内存不足的行为。

#### Low-Level Memory Accesses

在第10章中，我们讨论了编译器在将程序语句转换为机器指令时有一定的自由度，以及CPU允许乱序执行指令的余地。通常情况下，编译器和CPU可以利用的快捷方式和优化对程序的语义是不可见的-您通常无法确定两个读取是否相对于彼此重新排序，或者两个从同一内存位置读取是否实际上会导致两个CPU加载指令。这是有意设计的。语言和硬件设计人员仔细指定了程序员在代码运行时通常对其代码的期望，以便您的代码通常按照您的期望执行。

- 然而，no_std编程有时会将您带到“不可见优化”的常规边界之外。特别是，您经常会通过内存映射与硬件设备进行通信，其中设备的内部状态在精心选择的内存区域中可用。例如，在计算机启动时，内存地址范围0xA0000-0xBFFFF映射到一个简单的图形渲染管道；对该范围内的单个字节的写入将更改屏幕上的特定像素（或块，具体取决于模式）。
- 当您与设备映射的内存进行交互时，设备可能会为该内存访问的每个访问实现自定义行为，因此您的CPU和编译器对于常规内存加载和存储的假设可能不再成立。例如，硬件设备通常具有在读取时修改的内存映射寄存器，这意味着读取具有副作用。在这种情况下，如果您连续两次读取相同的内存地址，编译器无法安全地省略内存存储操作！
- 当程序执行突然以代码中未表示的方式转向时，也会出现类似的问题，因此编译器无法预期。如果没有底层操作系统来处理处理器异常或中断，或者进程接收到中断执行被中断，执行的活动代码段将停止，CPU开始执行事件处理程序，处理触发转向的事件。通常情况下，由于编译器可以预测所有可能的执行情况，它会安排其优化，以确保执行不能观察到操作的执行顺序已经发生了乱序或优化。然而，由于编译器无法预测这些异常跳转，它也无法计划它们对其优化是无视的，因此这些事件处理程序实际上可能观察到与原始程序代码中不同顺序的指令。
- 为了处理这些异常情况，Rust提供了无法省略或重新排序与其他volatile操作相关的volatile内存操作。这些操作采用std::ptr::read_volatile和std::ptr::write_volatile的形式。volatile操作非常适合访问内存映射的硬件资源：它们直接映射到内存访问操作，没有编译器的花招，并且保证volatile操作相对于彼此不会重新排序，确保具有可能副作用的硬件操作不会以本来可以互换的方式发生乱序（例如，加载一个地址和存储到不同地址）。不重新排序的保证也有助于异常执行情况，只要任何触及在异常上下文中访问的内存的代码仅使用volatile内存操作。

**注意** 还有一个std::sync::atomic::compiler_fence函数，它可以防止编译器重新排序非volatile内存访问。您很少需要编译器屏障，但它的文档是一个有趣的阅读材料。

**包含汇编代码**
如今，您很少需要编写汇编代码来完成任何给定的任务。但是对于需要在引导时初始化CPU或发出奇怪指令以操作内存映射的低级硬件编程，有时仍然需要使用汇编代码。在撰写本文时，夜间Rust上有一个RFC和一个基本完成的内联汇编语法实现，但尚未稳定下来，因此我不会在本书中讨论语法。

- 在稳定的Rust上仍然可以编写汇编代码-您只需要稍微有些创造力。具体来说，还记得第11章的构建脚本吗？好吧，Cargo构建脚本可以发出某些特殊指令到标准输出，以增强Cargo的标准构建过程，包括cargo:rustc-link-lib=static=xyz将静态库文件libxyz.a链接到最终的二进制文件中，以及cargo:rustc-linksearch:/some/path将/some/path添加到链接对象的搜索路径中。
使用这些指令，我们可以将一个build.rs添加到项目中，该脚本使用目标平台的编译器将独立的汇编文件（.s）编译为目标文件（.o），然后使用适当的归档工具（通常是ar）将其重新打包为静态存档文件（.a）。然后，项目会发出这两个Cargo指令，指向它放置静态存档的位置-可能是在OUT_DIR中-然后我们就可以开始了！如果目标平台不变，甚至可以在发布crate时包含预编译的.a文件，以便消费者无需重新构建它。

#### 防止滥用的硬件抽象

Rust的类型系统在将不安全、复杂和令人不愉快的代码封装在安全、人性化的接口后面方面表现出色。在低级系统编程的复杂世界中，这一点尤为重要，这个世界充斥着从晦涩的手册中提取出来的神奇硬件定义值和神秘的未记录的汇编指令咒语，以使设备处于恰到好处的状态。而且在这个空间中，运行时错误可能会导致更多的用户程序崩溃！在no_std程序中，使用类型系统使不合法的状态无法表示是非常重要的，正如我们在第3章中讨论的那样。如果某些寄存器值的组合不能同时发生，则创建一个单一类型，其类型参数指示相关寄存器的当前状态，并且仅在其上实现合法的转换，就像我们在清单3-2中为火箭示例所做的那样。

**注意** 确保还要查看第3章关于API设计的建议-所有这些都适用于no_std程序的上下文！

- 例如，考虑一对寄存器，在任何给定时间最多只能有一个寄存器处于“开启”状态。清单12-2展示了如何以一种方式在（单线程）程序中表示这一点，使得不可能编写违反该不变式的代码。

```rust
// raw register address -- private submodule
mod registers;
pub struct On;
pub struct Off;
pub struct Pair<R1, R2>(PhantomData<(R1, R2)>);
impl Pair<Off, Off> {
pub fn get() -> Option<Self> {
static mut PAIR_TAKEN: bool = false;
if unsafe { PAIR_TAKEN } {
None
} else {
// Ensure initial state is correct.
registers::off("r1");
registers::off("r2");
unsafe { PAIR_TAKEN = true };
Some(Pair(PhantomData))
}
}
pub fn first_on(self) -> Pair<On, Off> {
registers::set_on("r1");
Pair(PhantomData)
}
// .. and inverse for -> Pair<Off, On>
}
impl Pair<On, Off> {
pub fn off(self) -> Pair<Off, Off> {
registers::set_off("r1");
Pair(PhantomData)
}
}
// .. and inverse for Pair<Off, On>
```

清单12-2：静态确保正确操作

- 这段代码中有几个值得注意的模式。首先，我们通过检查其唯一构造函数中的一个私有静态布尔值，并使所有方法消耗self，确保只有一个Pair实例存在。然后，我们确保初始状态是有效的，并且只有有效的状态转换是可能的，因此不变式必须在全局范围内成立。
- 清单12-2中的第二个值得注意的模式是我们使用PhantomData利用零大小类型，并在静态上表示运行时信息。也就是说，在代码的任何给定点上，类型告诉我们运行时状态必须是什么样的，因此我们不需要在运行时跟踪或检查与寄存器相关的任何状态。当我们被要求启用r1时，无需检查r2是否已经打开，因为类型阻止编写这种情况的程序。

#### 交叉编译

通常，您会在具有完整操作系统和现代硬件设备的计算机上编写no_std程序，但最终在具有93/4位RAM和一个CPU插槽的小型硬件设备上运行。这就需要交叉编译-您需要在开发环境中编译代码，但将其编译为适用于小型硬件设备的代码。然而，交叉编译的重要性不仅限于此。例如，现在越来越常见的做法是使用一个构建流水线为所有消费者平台生成二进制文件，而不是尝试为消费者可能使用的每个平台都建立一个构建流水线，这意味着需要使用交叉编译。

**注意** 如果您实际上是为类似于具有有限内存的设备（甚至是像土豆这样的设备）进行编译，您可能希望将opt-level Cargo配置设置为"s"以优化二进制文件的大小。

- 交叉编译涉及两个平台：主机平台和目标平台。主机平台进行编译，目标平台最终运行编译输出。我们将平台指定为目标三元组，其形式为machine-vendor-os。machine部分指定代码将在其上运行的机器体系结构，例如x86_64、armv7或wasm32，并告诉编译器生成的机器代码使用的指令集。vendor部分通常采用Windows上的pc值，macOS和iOS上的apple值，以及其他地方的unknown值，并且对编译没有实质性影响；它基本上是无关紧要的，甚至可以省略。os部分告诉编译器用于最终二进制文件的格式，因此linux值指定Linux .so文件，windows值指定Windows .dll文件，依此类推。

**注意** 默认情况下，Cargo假设目标平台与主机平台相同，这就是为什么通常不需要告诉Cargo在Linux上编译Linux的原因。但是，有时您可能希望即使目标的CPU和操作系统相同，也使用--target，例如针对libc的musl实现。

- 要告诉Cargo进行交叉编译，只需使用您选择的三元组作为--target <target triple>参数传递给它。然后，Cargo将负责将该信息转发给Rust编译器，以便生成适用于给定目标平台的二进制文件。Cargo还会确保使用适当版本的标准库-毕竟，标准库包含许多条件编译指令（使用#[cfg(...)]），以便调用正确的系统调用并使用正确的特定于体系结构的实现，因此我们不能在目标上使用主机平台的标准库。
- 目标平台还决定了标准库的哪些组件可用。例如，x86_64-unknown-linux-gnu包括完整的std库，而thumbv7m-none-eabi之类的库则不包括，甚至不定义分配器，因此如果您在没有显式定义分配器的情况下使用alloc，将会出现构建错误。这对于测试您编写的代码是否实际上不需要std非常有用（请记住，即使使用#![no_std]，您仍然可以使用std::，因为no_std仅放弃了std预导入）。如果您的持续集成流水线使用--target thumbv7m-none-eabi构建您的crate，任何尝试访问除core之外的组件都将触发构建失败。关键是，这也将检查您的crate是否意外地引入了使用std（或alloc）的依赖项。

**平台支持**
标准的Rust安装程序Rustup默认不会为Rust支持的所有目标三元组安装标准库。这将浪费空间和带宽。相反，您必须使用命令rustup target add来安装适当的标准库版本以供其他目标使用。如果您的目标平台没有标准库的版本，您将需要自己从源代码编译它，方法是添加rust-src Rustup组件，并在构建任何crate时使用Cargo的（当前不稳定的）build-std功能来构建std（和/或core和alloc）。

- 如果您的目标平台不受Rust编译器支持-也就是说，如果rustc甚至不知道您的目标三元组的属性-您将需要更进一步，并使用自定义目标规范来教会rustc有关三元组的属性。如何做到这一点目前是不稳定的，超出了本书的范围，但是搜索“custom target specification json”是一个好的起点。

#### 总结

在本章中，我们介绍了标准库（或者更准确地说，std）之下的内容。我们讨论了core提供的功能，以及如何使用alloc扩展非std范围，并介绍了（微小的）Rust运行时如何使fn main工作。我们还介绍了如何与设备映射的内存进行交互，并处理可能发生在硬件编程的最低级别的非正常执行模式，以及如何在Rust类型系统中安全地封装硬件的一些奇特之处。接下来，我们将从非常小的范围转向非常大的范围，讨论如何浏览、理解甚至为更大的Rust生态系统做出贡献。

### 13 THE RUST ECOSYSTEM

编程很少发生在真空中，如今几乎每个你构建的Rust crate都可能依赖于一些你没有编写的代码。无论这种趋势是好是坏，还是两者兼而有之，都是当今开发者经验的现实。

- 在这个新的相互依赖的世界中，更重要的是要对可用的库和工具有一个扎实的掌握，并及时了解Rust社区所提供的最新和最好的内容。本章将介绍如何利用、跟踪、理解和为Rust生态系统做出贡献。由于这是最后一章，在结束部分，我还将提供一些额外的资源建议，供您继续发展您的Rust技能。

#### 有什么可用的？

尽管相对年轻，但Rust已经拥有一个庞大的生态系统，以至于很难跟踪到所有可用的内容。如果您知道您想要什么，您可能能够通过搜索找到一组合适的crate，然后使用下载统计数据和对每个crate的存储库进行表面检查，以确定哪些可能是合理的依赖关系。然而，还有大量的工具、crate和一般的语言特性，您可能不一定知道要寻找什么，但它们可能会节省您无数小时和困难的设计决策。

- 在本节中，我将介绍一些我多年来发现有用的工具、库和Rust特性，希望它们在某个时候对您也有用！

##### Tools

首先，这里有一些我经常使用的Rust工具，你应该加入你的工具包：

###### cargo-deny

提供了一种对依赖图进行代码检查的方式。在撰写本文时，您可以使用 cargo-deny 来仅允许特定的许可证，禁止某些 crate 或特定 crate 版本，检测已知漏洞的依赖关系或使用 Git 源的 crate，并检测在依赖图中以不同版本出现的 crate。在您阅读本文时，可能已经有更多有用的代码检查功能可用。

###### cargo-expand

展开给定 crate 中的宏，并让您检查输出，这样可以更容易地发现宏转录器或过程宏中的错误。当您编写自己的宏时，cargo-expand 是一个非常有价值的工具。
cargo-hack
帮助您检查您的 crate 是否与启用的任何特性组合都能正常工作。该工具提供了与 Cargo 自身类似的界面（如 cargo check、build 和 test），但它使您能够使用 crate 的所有可能组合（幂集）运行给定命令。

###### cargo-llvm-lines

分析从Rust代码到传递给实际生成机器代码的Rust编译器部分（LLVM）的中间表示（IR）的映射，并告诉您哪些Rust代码生成了最大的IR。这很有用，因为较大的IR意味着较长的编译时间，因此识别生成较大IR的Rust代码（例如，由于单态化）可以突出减少编译时间的机会。

###### cargo-outdated

检查您的依赖项（直接或间接）是否有更新的版本可用。与 cargo update 不同的是，它甚至会告诉您有关新的主要版本的信息，因此它是一个重要的工具，用于检查是否由于过时的主要版本指定而错过了更新的版本。只需记住，如果在接口中公开了依赖项的类型，将主要版本的依赖项升级可能会破坏您的 crate！

###### cargo-udeps

识别在您的Cargo.toml中列出但实际上从未使用的任何依赖项。也许您过去使用过它们，但现在它们已经变得多余，或者可能应该移动到dev-dependencies；无论如何，这个工具可以帮助您减少依赖闭包中的冗余。

- 虽然它们不是专门用于开发Rust的工具，但我强烈推荐fd和ripgrep，它们是对它们的前身find和grep的极好改进，而且它们本身也是用Rust编写的。我每天都使用这两个工具。

##### Libraries

接下来是一些我经常使用的有用但不太知名的crate，我猜我会继续依赖它们很长一段时间：

###### bytes

提供了一种高效的机制，可以在不复制或处理生命周期的情况下传递单个连续内存块的子切片。这在低级网络代码中非常有用，您可能需要多个视图来查看单个字节块，并且复制是不可取的。

###### criterion

一个基于统计的基准测试库，使用数学方法消除基准测试测量中的噪音，并可靠地检测性能变化。如果您的crate中包含微基准测试，几乎肯定应该使用它。

###### cxx

提供了一种从Rust调用C++代码和从C++调用Rust代码的安全、人性化的机制。如果您愿意在事先更彻底地声明接口的情况下投入一些时间，以换取更好的跨语言兼容性，这个库非常值得关注。

###### flume

实现了一个多生产者、多消费者通道，比Rust标准库中的通道更快、更灵活、更简单。它还支持异步和同步操作，因此是两个世界之间的一个很好的桥梁。

###### hdrhistogram

High Dynamic Range (HDR)直方图数据结构的Rust移植版，提供了对广泛值范围的直方图的紧凑表示。无论您当前是跟踪平均值还是最小/最大值，您很可能都应该使用HDR直方图；它可以为您提供更好的指标分布洞察。

###### heapless

提供不使用堆的数据结构。相反，heapless的数据结构都由静态内存支持，这使它们非常适合嵌入式环境或其他不希望进行分配的情况。

###### itertools

通过许多新的便捷方法扩展了标准库中的Iterator trait，用于去重、分组和计算幂集。这些扩展方法可以显著减少代码中的样板代码，例如在一系列值上手动实现一些常见算法，比如同时查找最小值和最大值（Itertools::minmax），或者使用常见模式，如检查迭代器是否只有一个项（Itertools::exactly_one）。

###### nix

在类Unix系统上提供了对系统调用的惯用绑定，相比直接使用类似libc的C兼容FFI类型，可以提供更好的体验。

###### pin-project

提供了宏，用于强制执行已注释类型的固定安全不变式，这些类型为这些类型提供了安全的固定接口。这使您可以避免为自己的类型正确处理Pin和Unpin的大部分麻烦。还有pin-project-lite，它避免了（目前）在过程宏机制上的相对较重的依赖，但牺牲了稍差的人性化。

###### ring

从用C编写的密码库BoringSSL中提取出优秀的部分，并通过快速、简单且难以误用的接口将它们带到Rust中。如果您的crate需要使用密码学，这是一个很好的起点。您很可能已经在rustls库中遇到过它，rustls使用ring提供了一个现代、默认安全的TLS堆栈。

###### slab

实现了一种高效的数据结构，用于替代HashMap<Token, T>，其中Token是仅用于区分映射中条目的不透明类型。在管理资源时经常遇到这种模式，其中当前资源集必须在中央管理，但也必须以某种方式访问各个资源。

###### static_assertions

提供静态断言，即在编译时评估并可能失败的断言。您可以使用它来断言诸如类型实现给定trait（如Send）或具有给定大小之类的事情。我强烈建议为那些保证可能很重要的代码添加这些类型的断言。

###### structopt

包装了众所周知的参数解析库clap，并提供了一种完全使用Rust类型系统（加上宏注解）来描述应用程序的命令行界面的方法。当解析应用程序的参数时，您会得到一个您定义的类型的值，因此您会获得所有类型检查的好处，如全面匹配和IDE自动完成。

###### thiserror

使编写自定义枚举错误类型（如第4章中讨论的类型）变得轻松愉快。它负责实现推荐的trait并遵循已建立的约定，只需定义与您的应用程序唯一相关的关键部分。

###### tower

有效地采用函数签名async fn(Request) -> Response，并在其上实现了一个完整的生态系统。其核心是Service trait，表示可以将请求转换为响应的类型（我怀疑这可能会成为标准库的一部分）。这是一个很好的抽象，用于构建任何看起来像服务的东西。

###### tracing

提供了跟踪应用程序执行所需的所有基础设施。关键是，它对您跟踪的事件类型和您想要对这些事件执行的操作是不可知的。该库可用于日志记录、指标收集、调试、性能分析和跟踪，所有这些都使用相同的机制和接口。

##### Rust工具链

Rust工具链有一些功能，您可能不知道要寻找。这些通常是针对非常特定的用例，但如果与您的用例匹配，它们可能会成为救命稻草！

###### Rustup

Rustup，Rust工具链安装程序，执行其工作非常高效，往往会被忽视和遗忘。您偶尔会使用它来更新工具链、设置目录覆盖或安装组件，但仅此而已。然而，Rustup支持一种非常方便的技巧，值得了解：工具链覆盖的简写。您可以将+toolchain作为Rustup管理的二进制文件的第一个参数传递，该二进制文件将按照您设置的工具链覆盖运行命令，然后将覆盖重置为之前的状态。因此，cargo +nightly miri将使用nightly工具链运行Miri，cargo +1.53.0 check将检查代码是否与Rust 1.53.0编译。后者对于检查您是否违反了最低支持的Rust版本合约非常有用。

- Rustup还有一个很棒的子命令doc，它在浏览器中打开当前版本Rust编译器的Rust标准库文档的本地副本。如果您在没有互联网连接的情况下进行开发，这是非常宝贵的！

###### Cargo

Cargo还有一些方便的功能，不一定容易发现。其中之一是cargo tree，这是一个内置在Cargo中的Cargo子命令，用于检查crate的依赖关系图。该命令的主要目的是将依赖关系图打印为树形结构。这本身就很有用，但是cargo tree真正出色的地方在于--invert选项：它接受一个crate标识符，并生成一个反转的树，显示从当前crate引入该依赖的所有依赖路径。因此，例如，cargo tree -i rand将打印当前crate依赖于rand的所有方式，包括通过传递依赖关系。如果您想消除一个依赖项或特定版本的依赖项，并想知道为什么它仍然被引入，这是非常宝贵的。您还可以传递-e features选项，以包括有关启用了该crate的每个Cargo特性的信息。

- 谈到Cargo子命令，编写自己的子命令非常容易，无论是与他人共享还是仅用于本地开发。当使用不被识别的子命令调用Cargo时，它会检查是否存在名为cargo-$subcommand的程序。如果存在，Cargo将调用该程序，并将任何传递的参数传递给cargo-$subcommand。Cargo甚至会通过将cargo help foo转换为对cargo-foo --help的调用来将此命令与cargo help集成。

- 随着您在更多的Rust项目上工作，您可能会注意到Cargo（以及Rust更普遍地说）在磁盘空间方面并不宽容。每个项目都有自己的目标目录用于编译产物，随着时间的推移，您会积累几个相同的编译产物副本，用于常见的依赖项。将每个项目的产物保持分开是一个明智的选择，因为它们在项目之间不一定兼容（例如，如果一个项目使用不同的编译器标志）。但在大多数开发环境中，共享构建产物是完全合理的，并且在切换项目时可以节省大量编译时间。幸运的是，配置Cargo以共享构建产物非常简单：只需将~/.cargo/config.toml文件中的[build] target设置为您希望这些共享产物放置的目录，Cargo会处理其余的事情。不再看到目标目录！只需确保定期清理该目录，并注意cargo clean现在将清理所有项目的构建产物。

**注意** 使用共享的构建目录可能会对假定编译器产物始终位于target/子目录下的项目造成问题，因此请注意。还要注意，如果一个项目使用不同的编译器标志，每次进入或退出该项目时，您将重新编译受影响的依赖项。在这种情况下，最好将该项目的目标目录覆盖为一个不同的位置。

- 最后，如果您觉得Cargo构建crate的时间过长，可以使用当前不稳定的Cargo -Ztimings标志。使用该标志运行Cargo会输出有关处理每个crate所花费的时间、运行构建脚本所花费的时间、哪些crate必须等待其他crate完成编译以及大量其他有用的指标的信息。这可能会突出显示一个特别慢的依赖链，您可以通过消除它来提高构建速度，或者揭示一个编译从头开始编译本机依赖项的构建脚本，您可以改为使用系统库。如果您想更深入地了解，还有rustc -Ztime-passes，它会为每个crate发出有关编译器内部花费时间的信息，但是该信息只有在您希望为编译器本身做出贡献时才有用。

###### rustc

Rust编译器还有一些较少为人知的功能，对于有企图心的开发者来说可能非常有用。首先是当前不稳定的-Zprint-type-sizes参数，它会打印出当前crate中所有类型的大小。对于除了最小的crate之外的所有crate，这会产生大量信息，但在尝试确定memcpy调用的时间消耗源或找到减少分配特定类型的对象的内存使用的方法时，它非常有价值。-Zprint-type-sizes参数还会显示每个类型的计算对齐和布局，这可能会指向将usize转换为u32等操作对类型的内存表示产生重大影响的地方。在调试特定类型的大小、对齐和布局之后，我建议添加静态断言，以确保它们随时间不会退化。您可能还对variant_size_differences lint感兴趣，它会发出警告，如果一个crate包含的enum类型的变体在大小上有显著差异。

**注意** 要使用特定的标志调用rustc，您有几个选项：您可以将它们设置在RUSTFLAGS环境变量中，或者在.cargo/config.toml中的[build] rustflags中设置，以使它们适用于Cargo调用rustc的每个调用，或者您可以使用cargo rustc，它将仅将您提供的任何参数传递给当前crate的rustc调用。

- 如果您的性能分析样本看起来很奇怪，堆栈帧被重新排序或完全丢失，您还可以尝试-Cforce-frame-pointers = yes。帧指针提供了一种更可靠的堆栈展开方式，这在性能分析期间会频繁发生，但代价是使用额外的寄存器进行函数调用。即使堆栈展开应该在仅启用常规调试符号的情况下正常工作（记得在使用发布配置时设置debug = true），但并非总是如此，帧指针可能会解决您遇到的任何问题。

###### 标准库

与其他编程语言相比，Rust标准库通常被认为较小，但它在深度上弥补了广度的不足；在Rust的标准库中，您不会找到一个Web服务器实现或一个X.509证书解析器，但您会发现超过40种不同的Option类型方法以及超过20种trait实现。对于它包含的类型，Rust尽力提供任何相关的功能，以显著改善人机交互性，因此您可以避免那些容易产生冗长样板代码的情况。在本节中，我将介绍一些标准库中的类型、宏、函数和方法，您可能之前没有遇到过，但它们通常可以简化或改进（或两者兼有）您的代码。

###### 宏和函数

让我们从一些独立的实用工具开始。首先是write!宏，它允许您使用格式字符串将内容写入文件、网络套接字或任何实现了Write的对象中。您可能已经熟悉它，但write!的一个鲜为人知的功能是它可以与std::io::Write和std::fmt::Write两者一起使用，这意味着您可以直接将格式化文本写入String中。也就是说，您可以编写use std::fmt::Write; write!(&mut s, "{}+1={}", x, x + 1);将格式化文本附加到字符串s中！

- iter::once函数接受任何值并生成一个只产生该值一次的迭代器。当调用需要迭代器的函数时，如果您不想分配内存，或者与Iterator::chain结合使用以将单个项附加到现有迭代器上，这非常有用。
- 我们在第1章简要介绍了mem::replace，但如果您错过了它，它值得再次提及。该函数接受对T的独占引用和一个拥有的T，交换两者，使得引用现在是拥有的T，并返回先前引用的所有权。当您需要在只有独占引用的情况下获取值的所有权时，这非常有用，例如在Drop的实现中。另请参阅当T: Default时的mem::take。

###### 类型

接下来，让我们看一些方便的标准库类型。BufReader和BufWriter类型对于对底层I/O资源发出许多小的读取或写入调用的I/O操作是必不可少的。这些类型包装了相应的底层Read或Write，并实现了自己的Read和Write，但它们还将操作缓冲到I/O资源，以便许多小的读取只进行一次大的读取，许多小的写入只进行一次大的写入。这可以显著提高性能，因为您不必经常跨越系统调用边界进入操作系统。

- Cow类型在第3章中提到过，当您希望灵活地持有哪些类型或需要在返回时灵活地持有哪些类型时非常有用。您很少会将Cow用作函数参数（请记住，如果需要，应该让调用者分配），但作为返回类型，它非常有价值，因为它允许您准确地表示可能分配或可能不分配的函数的返回类型。它也非常适合用于可以用作输入或输出的类型，例如RPC-like API中的核心类型。假设我们有一个名为EntityIdentifier的类型，就像在Listing 13-1中一样，它在RPC服务接口中使用。

```rust
struct EntityIdentifier {
namespace: String,
name: String,
}
```

第13-1节：需要分配的组合输入/输出类型的表示

现在想象一下有两个方法：get_entity接受一个EntityIdentifier作为参数，而find_by根据一些搜索参数返回一个EntityIdentifier。get_entity方法只需要一个引用，因为标识符（可能）在发送到服务器之前被序列化。但是对于find_by，实体将从服务器响应中反序列化，因此必须表示为拥有的值。如果我们让get_entity接受&EntityIdentifier，这意味着调用者仍然必须分配拥有的字符串来调用get_entity，即使接口并不需要，因为在构造EntityIdentifier之前就需要它！我们可以为get_entity引入一个单独的类型EntityIdenifierRef，它只包含&str类型，但这样我们就需要两种类型来表示同一件事情。Cow来拯救！第13-2节展示了一个EntityIdentifier，它在内部使用Cows来保存数据。

```rust
struct EntityIdentifier<'a> {
namespace: Cow<'a, str>,
name: Cow<'a str>,
}
```

第13-2节：不需要分配的组合输入/输出类型的表示

- 使用这种构造，get_entity可以接受任何EntityIdentifier<'_>，这允许调用者只使用引用来调用该方法。而find_by可以返回EntityIdentifier<'static>，其中所有字段都是Cow::Owned。一个类型在两个接口之间共享，没有不必要的分配要求！

**注意** 如果您以这种方式实现类型，我建议您还提供一个into_owned方法，该方法通过在所有字段上调用Cow::into_owned将<'a>实例转换为<'static>实例。否则，当用户只有<'a>时，他们将无法对您的类型进行更长时间的克隆。

- std::sync::Once类型是一种同步原语，它允许您在初始化时仅运行给定的代码一次。这对于作为FFI的一部分的初始化非常有用，其中FFI边界的另一侧的库要求仅执行一次初始化。
- VecDeque类型是std::collections中经常被忽视的成员，但我发现自己经常使用它-基本上，每当我需要一个堆栈或队列时。它的接口类似于Vec，就像Vec一样，它的内存表示是一个单一的内存块。不同之处在于VecDeque同时跟踪实际数据的开始和结束，这允许从VecDeque的任一侧进行常数时间的推入和弹出，这意味着它可以用作堆栈、队列，甚至同时用作两者。您需要付出的代价是值不再必须在内存中连续（它们可能已经环绕），这意味着VecDeque<T>不实现AsRef<[T]>。

###### 方法

让我们快速浏览一些不错的方法。首先是Arc::make_mut，它接受一个&mut Arc<T>并给出一个&mut T。如果Arc是存在的最后一个，它会给出Arc后面的T；否则，它会分配一个新的Arc<T>，其中包含T的克隆，将其交换到当前引用的Arc中，然后给出新单例Arc中的T的&mut。

- Clone::clone_from方法是.clone()的另一种形式，它允许您重用克隆的类型实例而不是分配一个新的实例。换句话说，如果您已经有一个x: T，您可以使用x.clone_from(y)而不是x = y.clone()，这样您可能会节省一些分配。
- std::fmt::Formatter::debug_*是实现Debug的最简单的方法，如果#[derive(Debug)]对您的用例不起作用，比如如果您只想包含一些字段或公开类型字段的Debug实现中没有公开的信息。在实现Debug的fmt方法时，只需调用传入的Formatter上的适当的debug_*方法（例如debug_struct或debug_map），调用结果类型上的包含的方法来填充有关类型的详细信息（例如field添加字段或entries添加键/值条目），然后调用finish。
- Instant::elapsed返回自创建Instant以来的Duration。这比常见的方法更简洁，常见的方法是创建一个新的Instant并减去较早的实例。
- Option::as_deref接受一个Option<P>，其中P: Deref，并返回Option<&P::Target>（还有一个as_deref_mut方法）。这个简单的操作可以通过避免晦涩的.as_ref().map(|r| &*_r)来使在Option上操作的函数式转换链更加清晰。
- Ord::clamp允许您获取任何实现Ord的类型，并将其夹在给定范围的两个其他值之间。也就是说，给定下限min和上限max，x.clamp(min, max)如果x小于min，则返回min，如果x大于max，则返回max，否则返回x。
- Result::transpose及其对应的Option::transpose反转嵌套Result和Option的类型。也就是说，将Result<Option<T>, E>转置为Option<Result<T, E>>，反之亦然。与?结合使用时，在处理具有Iterator::next和类似方法的可能失败的上下文中，此操作可以使代码更清晰。
- Vec::swap_remove是Vec::remove的更快版本。Vec::remove保留向量的顺序，这意味着要删除中间的元素，必须将向量中的所有后续元素向下移动一个位置。对于大型向量，这可能非常慢。另一方面，Vec::swap_remove将要删除的元素与最后一个元素交换，然后将向量的长度减少一，这是一个常数时间的操作。但请注意，它会重新排列您的向量，从而使旧索引无效！

#### 实际应用中的模式

当您开始探索不属于自己的代码库时，您可能会遇到一些常见的Rust模式，我们在本书中尚未讨论。了解这些模式将使您更容易识别它们，并因此理解它们的目的。您甚至可能会在自己的代码库中找到它们的用途！

##### 索引指针

索引指针允许您在数据结构中存储对数据的多个引用，而不会违反借用检查器。例如，如果您想存储一组数据，以便可以通过不同的方式高效地访问它，例如通过保持一个以一种字段为键的HashMap和一个以不同字段为键的HashMap，您不希望多次存储底层数据。您可以使用Arc或Rc，但它们使用动态引用计数，引入了不必要的开销，并且额外的管理需要您存储每个条目的附加字节。您可以使用引用，但是如果数据和引用存储在同一个数据结构中（如第8章中讨论的自引用数据结构），则生命周期变得困难，甚至不可能管理。您可以使用与Pin结合使用的原始指针来确保指针保持有效，但这也引入了很多复杂性以及您需要仔细考虑的不安全性。

- 大多数crate使用索引指针，或者我喜欢称之为indeferences。这个想法很简单：将每个数据条目存储在某个可索引的数据结构（如Vec）中，然后在派生的数据结构中仅存储索引。然后，要执行操作，首先使用派生的数据结构高效地找到数据索引，然后使用索引从中检索引用的数据。不需要生命周期-如果您希望，甚至可以在派生数据表示中具有循环！

- indexmap crate是一个很好的例子，它提供了一个HashMap实现，其中迭代顺序与映射插入顺序相匹配。实现必须在两个位置存储键，一个是键到值的映射，另一个是所有键的列表，但显然不希望在键类型本身很大的情况下保留两个副本。所以，它使用索引指针。具体来说，它将所有键值对都保存在一个单独的Vec中，然后将键哈希映射到Vec索引。要遍历映射的所有元素，只需遍历Vec。要查找给定的键，它会对该键进行哈希处理，查找映射中的哈希，这会产生Vec中键的索引（索引指针），然后使用该索引从Vec中获取键的值。

- petgraph crate实现了图数据结构和算法，也使用了这种模式。crate将所有节点值存储在一个Vec中，将所有边值存储在另一个Vec中，并且只使用这些Vec中的索引来引用节点或边。因此，例如，与边关联的两个节点仅在该边中存储为两个u32，而不是作为引用或引用计数值。

- 诀窍在于如何支持删除。要删除数据条目，首先需要在所有派生的数据结构中搜索其索引并删除相应的条目，然后需要从根数据存储中删除数据。如果根数据存储是Vec，则删除条目还会更改另一个数据条目的索引（使用swap_remove时），因此您需要更新所有派生的数据结构以反映移动的条目的新索引。

##### Drop Guards

Drop guards提供了一种简单但可靠的方式来确保在发生panic时仍然运行一些代码，这在不安全代码中通常是必不可少的。一个例子是一个函数，它接受一个闭包f: FnOnce，并使用原子操作在互斥下执行它。假设该函数使用compare_exchange（在第10章中讨论）将一个布尔值从false设置为true，调用f，然后将布尔值重新设置为false以结束互斥。但是考虑一下如果f发生panic会发生什么-函数将永远无法运行其清理代码，并且没有其他调用将能够再次进入互斥部分。

- 使用catch_unwind可以解决这个问题，但是drop guards提供了一种通常更符合人体工程学的替代方法。在我们当前的示例中，列表13-3显示了如何使用drop guard来确保布尔值始终被重置。

```rust
fn mutex(lock: &AtomicBool, f: impl FnOnce()) {
// .. while lock.compare_exchange(false, true).is_err() ..
struct DropGuard<'a>(&'a AtomicBool);
impl Drop for DropGuard<'_> {
fn drop(&mut self) {
lock.store(true, Ordering::Release);
}
}
let _guard = DropGuard(lock);
f();
}
```

清单13-3：使用drop guard确保在取消展开的panic后运行代码

我们引入了本地类型DropGuard，它实现了Drop，并将清理代码放在其Drop::drop的实现中。任何必要的状态都可以通过DropGuard的字段传递进来。然后，在调用可能引发panic的函数之前，即f在这里，我们构造了一个guard类型的实例。当f返回时，无论是由于panic还是正常返回，guard都会被丢弃，其析构函数运行，锁被释放，一切都很好。

- 重要的是，guard被分配给一个在作用域结束时被丢弃的变量。这意味着即使我们再也不引用guard的变量，它也需要被赋予一个名称，因为let _ = DropGuard(lock)会立即丢弃guard，而不会在用户提供的代码运行之前！

**注意** 像catch_unwind一样，drop guard仅在panic取消展开时起作用。如果代码使用panic=abort编译，那么在panic后不会运行任何代码。

- 这种模式通常与线程局部变量一起使用，当库代码可能希望设置线程局部状态，以便仅在闭包执行期间有效，并且在之后需要清除时。例如，在撰写本文时，Tokio使用此模式为像TcpStream这样的叶资源提供有关调用Future::poll的执行器的信息，而无需通过对用户可见的函数签名传播该信息。如果线程局部状态在Future::poll由于panic返回后仍然指示特定执行器线程处于活动状态，那将是不好的，因此Tokio使用drop guard确保线程局部状态被重置。

**注意** 您经常会看到在线程局部变量中使用Cell或Rc<RefCell>。这是因为线程局部变量仅通过共享引用访问，因为线程可能再次访问它已经在调用堆栈中的某个更高位置引用的线程局部变量。这两种类型提供了内部可变性，而不会产生太多开销，因为它们仅用于单线程使用，因此非常适合此用例。

##### 扩展特性

扩展特性允许crate为实现来自不同crate的trait的类型提供附加功能。例如，itertools crate为Iterator提供了一个扩展特性，其中添加了许多方便的常用（和不常用）迭代器操作。作为另一个例子，tower提供了ServiceExt，它为tower-service中的Service trait添加了几个更符合人体工程学的操作。

- 扩展特性通常在您无法控制基本trait的情况下非常有用，就像Iterator一样，或者当基本trait位于自己的crate中时，因此很少发生破坏性发布，从而不会导致不必要的生态系统分裂，就像Service一样。
- 扩展特性扩展了它所扩展的基本trait（trait ServiceExt: Service），仅由提供的方法组成。它还提供了对任何实现基本trait的T的全局实现（impl<T> ServiceExt for T where T: Service {}）。这些条件共同确保扩展特性的方法在任何实现基本trait的内容上都可用。

##### Crate预导入

在第12章中，我们讨论了标准库预导入，它使得一些类型和特性在没有编写任何use语句的情况下自动可用。类似地，导出多个类型、特性或函数并经常一起使用的crate有时会定义自己的预导入形式，即一个名为prelude的模块，该模块重新导出了其中一些特定常见子集的类型、特性和函数。这个模块名称没有任何神奇之处，也不会自动使用，但它向用户发出信号，他们可能希望在想要使用相关crate的文件中添加use somecrate::prelude::_。*是一个全局导入，告诉Rust使用指定模块中的所有公共可用项。当crate有许多通常需要命名的项时，这可以节省很多输入。

**注意** 通过*使用的项的优先级低于通过名称显式使用的项。这使您可以在自己的crate中定义与标准库预导入重叠的项，而无需指定要使用的项。

- 预导入对于导出许多扩展特性的crate也非常有用，因为只有在特性的trait方法在作用域中时，才能调用这些方法。例如，提供对关系数据库的人性化访问的diesel crate广泛使用扩展特性，因此您可以编写如下的代码：

```rust

posts.filter(published.eq(true)).limit(5).load::<Post>(&connection)
```

只有当所有正确的trait在作用域内时，这行代码才能正常工作，而预导入则负责此事。

- 一般来说，向代码添加全局导入时需要小心，因为它们可能将对指定模块的添加转变为不兼容的更改。例如，如果有人向您从中进行全局导入的模块添加了一个新的trait，并且该新的trait使得已经存在其他foo方法的类型上的foo方法可用，那么调用该类型上的foo方法的代码将无法编译，因为对foo的调用现在是模棱两可的。有趣的是，尽管全局导入的存在使得任何模块的添加在技术上都是破坏性的更改，但是Rust关于API演进的RFC（RFC 1105；参见<https://rust-lang.github.io/rfcs/1105-api-evolution.html>）并不要求库为这种更改发布一个新的主要版本。该RFC详细介绍了为什么，我建议您阅读一下，但要点是，次要版本允许对依赖项进行最小侵入性的更改，例如在边缘情况下需要添加类型注释，否则，尽管这些更改非常不可能实际上会破坏任何消费者，但会要求发布新的主要版本。
- 特别是在预导入的情况下，当供应crate建议使用全局导入时，通常是可以的，因为其维护者知道用户将使用预导入模块的全局导入，并且在决定更改是否需要主要版本升级时会考虑到这一点。

#### 保持更新

Rust作为一门年轻的语言，正在快速发展。语言本身、标准库、工具链和更广泛的生态系统都还处于初级阶段，每天都会有新的发展。虽然跟上所有变化是不可行的，但花时间了解重大发展是值得的，这样您就可以在项目中充分利用最新和最好的功能。

- 要监控Rust本身的改进，包括新的语言特性、标准库的添加和核心工具的升级，官方的Rust博客<https://blog.rust-lang.org/>是一个好的、低频的起点。它主要发布每个新的Rust版本的公告。我建议您养成阅读这些公告的习惯，因为它们往往包含有趣的细节，这些细节会逐渐加深您对语言的了解。为了深入了解一些内容，我强烈建议阅读Rust和Cargo的详细变更日志（链接通常可以在每个发布公告的底部找到）。变更日志会展示那些在发布说明中没有被列为段落的变更，但可能正是您在两周后所需要的。对于更新频率较低的新闻来源，请查看Edition Guide<https://doc.rust-lang.org/edition-guide/>，其中概述了每个Rust版本中的新内容。Rust版本通常每三年发布一次。

**注意** Clippy通常可以告诉您何时可以利用新的语言或标准库功能-始终启用Clippy！

- 如果您对Rust本身的开发感兴趣，您可能还想订阅Inside Rust博客<https://blog.rust-lang.org/inside-rust/>。它包括来自各种Rust团队的更新，以及事故报告、较大的变更提案、版本规划信息等等。要参与Rust的开发——我非常鼓励您这样做，因为这是一种有趣的学习经历——您可以查看各种Rust工作组<https://www.rust-lang.org/governance/>，每个工作组都致力于改进Rust的特定方面。找到一个吸引您的工作组，与该组会面并询问您如何能够提供帮助。您还可以加入Rust内部讨论社区<https://internals.rust-lang.org/>；这是了解Rust设计和开发的每个部分背后思想的另一种绝佳方式。
- 对于大多数编程语言来说，Rust的价值很大程度上来自于其社区。Rust社区的成员不仅不断开发新的节省工作的crate，发现新的Rust特定技术和设计模式，而且还共同不断帮助彼此理解、记录和解释如何最好地利用Rust语言。我在本书中涵盖的所有内容，以及更多内容，已经在社区的成千上万个评论线程、博客文章和Twitter、Discord的对话中讨论过。即使只是偶尔参与这些讨论，几乎可以保证向您展示关于语言特性、技术或crate的新东西，这些您之前不知道的东西。
- Rust社区存在于许多地方，但一些好的起点是用户论坛<https://users.rust-lang.org/>、Rust subreddit<https://www.reddit.com/r/rust/>、Rust Community Discord<https://discord.gg/rust-lang-community>和Rust Twitter账号<https://twitter.com/rustlang>。您不必与所有这些或一直参与其中——选择一个您喜欢的氛围，并偶尔查看一下！
- 一个了解正在进行的发展的绝佳单一位置是This Week in Rust博客<https://this-week-in-rust.org/>，它是一个“[Rust的]进展和社区的每周摘要”。它链接到官方公告和变更日志，以及受欢迎的社区讨论和资源、有趣的新crate、贡献机会、即将举行的Rust活动和Rust工作机会。它甚至列出了有趣的语言RFC和编译器PR，所以这个网站真的应有尽有！辨别哪些信息对您有价值，哪些不是可能有点令人生畏，但即使只是浏览并偶尔点击看起来有趣的链接，也是让新的Rust知识源源不断地涌入您的大脑的好方法。
**注意** 想要查找特定功能何时在稳定版中引入？Can I Use...(<https://caniuse.rs/>)可以帮到您。

#### 接下来做什么？

那么，您已经从头到尾阅读了本书，吸收了它所传授的所有知识，仍然渴望更多？太好了！还有许多其他优秀的资源可供您拓宽和深化对Rust的知识和理解，在这最后一节中，我将为您概述一些我最喜欢的资源，以便您可以继续学习。我根据不同人喜欢的学习方式将它们分成了几个小节，这样您就可以找到适合您的资源。

**注意** 在自学过程中，尤其是在开始阶段，一个挑战是进展难以察觉。即使是实现最简单的东西，当您不得不不断参考文档和其他资源、寻求帮助或进行调试以了解Rust的某个方面时，可能需要大量的时间。所有这些非编码工作可能会让您感觉自己在原地踏步，没有真正进步。但您正在学习，这本身就是进步——只是更难察觉和欣赏而已。

##### Learn by Watching

观看经验丰富的开发者编码实际上是解决独立学习初始阶段的一种生活技巧。它让您能够观察设计和构建过程，同时利用他人的经验。倾听经验丰富的开发者在遇到问题时表达他们的思考并解释棘手的概念或技术，可以是解决问题的绝佳替代方法。您还将学到各种辅助知识，如调试技巧、设计模式和最佳实践。最终，您将不得不坐下来自己动手做事——这是检查您是否真正理解所观察到的内容的唯一方式——但依赖他人的经验几乎肯定会使早期阶段更加愉快。如果这种经验是互动的，那就更好了！

- So, with that said, here are some Rust video channels that I recommend:
- - Perhaps unsurprisingly, my own channel: <https://www.youtube.com/c/>
JonGjengset/. I have a mix of long-form coding videos and short(er) code-
based theory/concept explanation videos, as well as occasional videos
that dive into interesting Rust coding stories.
- - The Awesome Rust Streaming listing: <https://github.com/jamesmunns/awesome-rust-streaming/>. This resource lists a wide variety of developers
who stream Rust coding or other Rust content.
- - The channel of Tim McNamara, the author of Rust in Action: https://
<www.youtube.com/c/timClicks/>. Tim’s channel, like mine, splits its time
between implementation and theory, though Tim has a particular
- - knack for creative visual projects, which makes for fun viewing.
Jonathan Turner’s Systems with JT channel: <https://www.youtube.com/c/>
SystemswithJT/. Jonathan’s videos document their work on Nushell, their take on a “new type of shell,” providing a great sense of what it’s
like to work on a nontrivial existing codebase.
- - Ryan Levick’s channel: <https://www.youtube.com/c/RyanLevicksVideos/>. Ryan mainly posts videos that tackle particular Rust concepts and walks
through them using concrete code examples, but he also occasionally
does implementation videos (like FFI for Microsoft Flight Simulator!)
and deep dives into how well-known crates work under the hood.
- Given that I make Rust videos, it should come as no surprise that I am
a fan of this approach to teaching. But this kind of receptive or interactive
learning doesn’t have to come in the form of videos. Another great avenue
for learning from experienced developers is pair programming. If you have
a colleague or friend with expertise in a particular aspect of Rust you’d like
to learn, ask if you can do a pair-programming session with them to solve a
problem together!

##### Learn by Doing

Since your ultimate goal is to get better at writing Rust, there’s no substitute
for programming experience. No matter what or how many resources you
learn from, you need to put that learning into practice. However, finding a
good place to start can be tricky, so here I’ll give some suggestions.

- Before I dive into the list, I want to provide some general guidance on
how to pick projects. First, choose a project that you care about, without
worrying too much whether others care about it. While there are plenty
of popular and established Rust projects out there that would love to have
you as a contributor, and it’s fun to be able to say “I contributed to the wellknown
library X,” your first priority must be your own interest. Without
concrete motivation, you’ll quickly lose steam and find contributing to be
a chore. The very best targets are projects that you use yourself and have
experienced problems with—go fix them! Nothing is more satisfying than
getting rid of a long-standing personal nuisance while also contributing
back to the community.
- Okay, so back to project suggestions. First and foremost, consider contributing
to the Rust compiler and its associated tools. It’s a high-quality
codebase with good documentation and an endless supply of issues (you
probably know of some yourself), and there are several great mentors who
can provide outlines for how to approach solving issues. If you look through
the issue tracker for issues marked E-easy or E-mentor, you’ll likely find a
good candidate quickly. As you gain more experience, you can keep leveling
up to contribute to trickier parts.
- If that’s not your cup of tea, I recommend finding something you use
frequently that’s written in another language and porting it to Rust—not
necessarily with the intention of replacing the original library or tool, but
just because the experience will allow you to focus on writing Rust without
having to spend too much time coming up with all the functionality yourself.
If it turns out well, the fact that it already exists suggests that someone
else also needed it, so there may be a wider audience for your port too! Data
structures and command-line tools often make for great porting subjects,
but find a niche that appeals to you.
- Should you be more of a “build it from scratch” kind of person, I recommend
looking back at your own development experience so far and thinking
about similar code you’ve ended up writing in multiple projects (whether
in Rust or in other languages). Such repetition tends to be a good signal
that something is reusable and could be turned into a library. If nothing
comes to mind, David Tolnay maintains a list of smaller utility crates that
other Rust developers have requested at <https://github.com/dtolnay/request-forimplementation/>
that may provide a source of inspiration. If you’re looking for
something more substantial and ambitious, there’s also the Not Yet Awesome
list at <https://github.com/not-yet-awesome-rust/not-yet-awesome-rust/> that lists
things that should exist in Rust but don’t (yet).

##### Learn by Reading

Although the state of affairs is constantly improving, finding good Rust
reading material beyond the beginner level can still be tricky. Here’s a collection
of pointers to some of my favorite resources that continue to teach
me new things or serve as good references when I have particularly niche or
nuanced questions.

- First, I recommend looking through the official virtual Rust books
linked from <https://www.rust-lang.org/learn/>. Some, like the Cargo book, are
more reference-like while others, like the Embedded book, are more guidelike,
but they’re all deep sources of solid technical information about their
respective topics. The Rustonomicon (<https://doc.rust-lang.org/nomicon/>), in particular,
is a lifesaver when you’re writing unsafe code.
- Two more books that are worth checking out are the Guide to rustc
Development (<https://rustc-dev-guide.rust-lang.org/>) and the Standard Library
Developers Guide (<https://std-dev-guide.rust-lang.org/>). These are fantastic
resources if you’re curious about how the Rust compiler does what it does
or how the standard library is designed, or if you want some pointers before
you try your hand at contributing to Rust itself. The official Rust guidelines
are also a treasure trove of information; I’ve already mentioned the Rust
API Guidelines (<https://rust-lang.github.io/api-guidelines/>) in the book, but a
Rust Unsafe Code Guidelines Reference is also available (<https://rust-lang.github>
.io/unsafe-code-guidelines/), and by the time you read this book there may
be more.

**NOTE** One of the resources listed at <https://www.rust-lang.org/learn/> is the Rust
Reference, which is essentially a full specification for the Rust language. While parts
of it are quite dry, like the exact grammar used for parsing or basics about the inmemory
representations of the primitive types, some of it is fascinating reading, like
the section on type layout and the enumeration of behavior considered undefined.

- There are also a number of unofficial virtual Rust books that are
enormously valuable collections of experience and knowledge. The Little
Book of Rust Macros (<https://veykril.github.io/tlborm/>), for example, is indispensable
if you want to write nontrivial declarative macros, and The Rust
Performance Book (<https://nnethercote.github.io/perf-book/>) is filled with tips and
tricks for improving the performance of Rust code both at the micro and
the macro level. Other great resources include the Rust Fuzz Book (https://
rust-fuzz.github.io/book/), which explores fuzz testing in more detail, and
the Rust Cookbook (<https://rust-lang-nursery.github.io/rust-cookbook/>), which suggests
idiomatic solutions to common programming tasks. There’s even a
resource for finding more books, The Little Book of Rust Books (<https://lborb>.
github.io/book/unofficial.html)!
- If you prefer more hands-on reading, the Tokio project has published
mini-redis (<https://github.com/tokio-rs/mini-redis/>), an incomplete but idiomatic
implementation of a Redis client and server that’s extremely well documented
and specifically written to serve as a guide to writing asynchronous
code. If you’re more of a data structures person, Learn Rust with Entirely Too
Many Linked Lists (<https://rust-unofficial.github.io/too-many-lists/>) is an enlightening
and fun read that gets into lots of gnarly details about ownership and
references. If you’re looking for something closer to the hardware, Philipp
Oppermann’s Writing an OS in Rust (<https://os.phil-opp.com/>) goes through
the whole operating system stack in great detail while teaching you good
Rust patterns in the process. I also highly recommend Amos’s collection of
articles (<https://fasterthanli.me/tags/rust/>) if you want a wide sampling of interesting
deep dives written in a conversational style.
- When you feel more confident in your Rust abilities and need more of
a quick reference than a long tutorial, I’ve found the Rust Language Cheat
Sheet (<https://cheats.rs/>) great for looking things up quickly. It also provides
very nice visual explanations for most topics, so even if you’re looking up
something you’re not intimately familiar with already, the explanations are
pretty approachable.
- And finally, if you want to put all of your Rust understanding to the
test, go give David Tolnay’s Rust Quiz (<https://dtolnay.github.io/rust-quiz/>) a try.
There are some real mind-benders in there, but each question comes with
a thorough explanation of what’s going on, so even if you get one wrong,
you’ll have learned from the experience!

##### Learn by Teaching

My experience has been that the best way to learn something well and
thoroughly, by far, is to try to teach it to others. I have learned an enormous
amount from writing this book, and I learn new things every time
I make a new Rust video or podcast episode. So, I wholeheartedly recommend
that you try your hand at teaching others about some of the things
you’ve learned from reading this book or that you learn from here on out.
It can take whatever form you prefer: in person, writing a blog post, tweeting,
making a video or podcast, or giving a talk. The important thing is
that you try to convey your newfound knowledge in your own words to
someone who doesn’t already understand the topic—in doing so, you also
give back to the community so that the next you that comes along has a
slightly easier time getting up to speed. Teaching is a humbling and deeply
educational experience, and I cannot recommend it highly enough.

**NOTE** Whether you’re looking to teach or be taught, make sure to visit Awesome Rust
Mentors (<https://rustbeginners.github.io/awesome-rust-mentors/>).
The Rust Ecosystem 243

#### Summary

In this chapter, we’ve covered Rust beyond what exists in your local workspace.
We surveyed useful tools, libraries, and Rust features; looked at how
to stay up to date as the ecosystem continues to evolve; and then discussed
how you can get your hands dirty and contribute back to the ecosystem
yourself. Finally, we discussed where you can go next to continue your Rust
journey now that this book has reached its end. And with that, there’s little
more to do than to declare:

```

}
```
